{
  "schemaVersion": "0.3",
  "description": "The **AWSSupport-SendLogBundleToS3Bucket** runbook uploads a log bundle generated by the EC2Rescue tool for [Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Windows-Server-EC2Rescue.html) or [Linux](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Linux-Server-EC2Rescue.html) from the target instance to the specified Amazon Simple Storage Service (Amazon S3). The runbook installs the platform specific version of EC2Rescue based on the instance's platform `Linux` or `Windows`. EC2Rescue is then used to collect the available operating system (OS) logs.\n\n### Prerequisites:\n> * Windows PowerShell 3.0 or later must be installed on Windows instances.\n> * [AWS Tools for PowerShell](https://aws.amazon.com/powershell/) must be installed on Windows instances.\n> * The AWS Command Line Interface (AWS CLI) installed and configured on Linux instances.\n> * Write access to the specified Amazon S3 bucket.\n> * The instance subnet must have outbound connectivity to Amazon S3.\n> * The instance requires a valid AWS Identity and Access Management (IAM) instance profile that provides permissions for Systems Manager and the Amazon S3 bucket.",
  "assumeRole": "{{ AutomationAssumeRole }}",
  "parameters": {
    "AutomationAssumeRole": {
      "type": "AWS::IAM::Role::Arn",
      "description": "(Optional) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf. If no role is specified, Systems Manager Automation uses the permissions of the user that starts this runbook.",
      "default": ""
    },
    "InstanceId": {
      "type": "AWS::EC2::Instance::Id",
      "description": "(Required) The ID of the Windows or Linux managed instance you want to collect logs from."
    },
    "S3BucketName": {
      "type": "AWS::S3::Bucket::Name",
      "description": "(Required) The Amazon S3 bucket to upload the logs to."
    },
    "S3Path": {
      "type": "String",
      "description": "(Optional) The Amazon S3 path for the collected logs. By default: `AWSSupport-SendLogBundleToS3Bucket/`.",
      "default": "AWSSupport-SendLogBundleToS3Bucket/",
      "allowedPattern": "^[a-zA-Z0-9][-./a-zA-Z0-9]{0,255}$"
    }
  },
  "mainSteps": [
    {
      "name": "assertInstanceIsManagedInstance",
      "action": "aws:assertAwsResourceProperty",
      "description": "Ensures the target EC2 instance is managed by AWS Systems Manager, otherwise the automation ends.",
      "onFailure": "Abort",
      "inputs": {
        "Service": "ssm",
        "Api": "DescribeInstanceInformation",
        "InstanceInformationFilterList": [
          {
            "key": "InstanceIds",
            "valueSet": [
              "{{ InstanceId }}"
            ]
          }
        ],
        "PropertySelector": "$.InstanceInformationList[0].PingStatus",
        "DesiredValues": [
          "Online"
        ]
      },
      "isCritical": true,
      "nextStep": "describeManagedInstance"
    },
    {
      "name": "describeManagedInstance",
      "action": "aws:executeAwsApi",
      "description": "Gets information about the operating system (OS) platform of the instance specified in the `InstanceId` parameter.",
      "onFailure": "Abort",
      "inputs": {
        "Service": "ssm",
        "Api": "DescribeInstanceInformation",
        "InstanceInformationFilterList": [
          {
            "key": "InstanceIds",
            "valueSet": [
              "{{ InstanceId }}"
            ]
          }
        ]
      },
      "outputs": [
        {
          "Name": "Platform",
          "Selector": "$.InstanceInformationList[0].PlatformType"
        }
      ],
      "isCritical": true,
      "nextStep": "branchOnManagedInstancePlatform"
    },
    {
      "name": "branchOnManagedInstancePlatform",
      "action": "aws:branch",
      "description": "Branches the automation based on the OS platform `Linux` or `Windows`.",
      "onFailure": "Abort",
      "inputs": {
        "Choices": [
          {
            "NextStep": "installEC2RescueForWindows",
            "Variable": "{{ describeManagedInstance.Platform }}",
            "StringEquals": "Windows"
          },
          {
            "NextStep": "installEC2RescueForLinux",
            "Variable": "{{ describeManagedInstance.Platform }}",
            "StringEquals": "Linux"
          }
        ]
      },
      "isCritical": true,
      "isEnd": true
    },
    {
      "name": "installEC2RescueForWindows",
      "action": "aws:runCommand",
      "description": "Installs EC2Rescue for Windows via `AWS-ConfigureAWSPackage`.",
      "onFailure": "Abort",
      "inputs": {
        "DocumentName": "AWS-ConfigureAWSPackage",
        "InstanceIds": [
          "{{ InstanceId }}"
        ],
        "Parameters": {
          "name": "AWSSupport-EC2Rescue",
          "action": "Install",
          "version": "latest"
        }
      },
      "isCritical": true,
      "nextStep": "collectAndUploadWindowsLogBundle"
    },
    {
      "name": "collectAndUploadWindowsLogBundle",
      "action": "aws:runCommand",
      "description": "Runs the PowerShell script to collect Windows troubleshooting logs with EC2Rescue and upload the logs to the Amazon S3 bucket.",
      "onFailure": "Abort",
      "inputs": {
        "DocumentName": "AWS-RunPowerShellScript",
        "InstanceIds": [
          "{{ InstanceId }}"
        ],
        "Parameters": {
          "commands": [
            "# Copyright 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.",
            "# SPDX-License-Identifier: LicenseRef-.amazon.com.-AmznSL-1.0",
            "# Licensed under the Amazon Software License http://aws.amazon.com/asl/",
            "",
            "# Set AWS Tools for PowerShell environment variables",
            "$Env:AWS_RETRY_MODE=\"standard\" # Specifies the retry mode for AWS API calls",
            "$Env:AWS_MAX_ATTEMPTS=10 # Specifies the maximum retry attempts",
            "$Env:AWS_DEFAULT_REGION=\"{{global:REGION}}\" # Sets default region",
            "",
            "try {",
            "    # Check if AWSPowershell module is available",
            "    if (Get-Module -ListAvailable -Name AWSPowershell) {",
            "        # Import necessary modules",
            "        Import-Module AWSPowershell, EC2Rescue",
            "",
            "        # Get S3 bucket details from template or environment variables",
            "        $s3BucketName = \"{{ S3BucketName }}\"",
            "        $s3Path = \"{{ S3Path }}\".TrimEnd(\"/\")",
            "        # Add \"/\" to the end of the {{ S3Path }}",
            "        $s3Path = \"{0}/\" -f $s3Path",
            "",
            "        # Determine the region of the current EC2 instance",
            "        $instanceRegion = \"{{ global:REGION }}\"",
            "        $accountId = \"{{ global:ACCOUNT_ID }}\"",
            "",
            "        # Get the region of the specified S3 bucket",
            "        $s3BucketRegion = (Get-S3BucketLocation -BucketName $s3BucketName -Region $instanceRegion -ExpectedBucketOwner $accountId).value",
            "",
            "        # If the S3 bucket region is empty, default to \"us-east-1\"",
            "        if ($s3BucketRegion -eq \"\") {",
            "            $s3BucketRegion = \"us-east-1\"",
            "        }",
            "",
            "        # Check if the specified S3 bucket exists",
            "        if (Test-S3Bucket -BucketName $s3BucketName -Region $s3BucketRegion) {",
            "            # Collect logs from the current Windows instance",
            "            Write-Output \"Collecting logs from the current Windows instance.\"",
            "            $logFile = Invoke-EC2RescueCollectLogBundle -Logs \"all\"",
            "",
            "            # Upload logs to the specified S3 bucket and path",
            "            Write-Output \"Log collection completed. Uploading logs to S3 bucket ${s3BucketName} under path ${s3Path}.\"",
            "            Copy-EC2RescueLogBundleToS3 -FilePath $logFile -S3BucketName $s3BucketName -S3Path $s3Path",
            "            Write-Output \"Log upload completed.\"",
            "        } else {",
            "            # Throw an exception if the specified S3 bucket is not found or access is denied",
            "            throw (\"No Amazon S3 bucket called \" + $s3BucketName + \" found in the current AWS account, or access denied. Please specify an Amazon S3 bucket you own, and that this instance has access to.\")",
            "        }",
            "    } else {",
            "        # Inform the user that AWS Tools for Windows PowerShell is not installed",
            "        Write-Output \"AWS Tools for Windows PowerShell not installed. Please install the latest version of the AWS Tools for Windows PowerShell and try again.\"",
            "        Write-Output \"Download location: https://aws.amazon.com/powershell/\"",
            "",
            "        # Exit with code 255 (indicating an error)",
            "        Exit 255",
            "    }",
            "} catch {",
            "    # Catch and handle any exceptions during execution",
            "    Write-Output $_.Exception.Message",
            "",
            "    # Exit with code 1 (indicating an error)",
            "    Exit 1",
            "}"
          ]
        }
      },
      "isCritical": true,
      "isEnd": true
    },
    {
      "name": "installEC2RescueForLinux",
      "action": "aws:runCommand",
      "description": "Installs EC2Rescue for Linux via `AWS-ConfigureAWSPackage`.",
      "onFailure": "Abort",
      "inputs": {
        "DocumentName": "AWS-ConfigureAWSPackage",
        "InstanceIds": [
          "{{ InstanceId }}"
        ],
        "Parameters": {
          "name": "AWSSupport-EC2Rescue",
          "action": "Install",
          "version": "latest"
        }
      },
      "isCritical": true,
      "nextStep": "collectAndUploadLinuxLogBundle"
    },
    {
      "name": "collectAndUploadLinuxLogBundle",
      "action": "aws:runCommand",
      "description": "Runs the bash script to collect Linux troubleshooting logs with EC2Rescue and upload the logs to the Amazon S3 bucket.",
      "onFailure": "Abort",
      "inputs": {
        "DocumentName": "AWS-RunShellScript",
        "InstanceIds": [
          "{{ InstanceId }}"
        ],
        "Parameters": {
          "commands": [
            "#!/bin/bash",
            "",
            "# Copyright 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.",
            "# SPDX-License-Identifier: LicenseRef-.amazon.com.-AmznSL-1.0",
            "# Licensed under the Amazon Software License  http://aws.amazon.com/asl/",
            "",
            "error_trap() {",
            "    if [[ -n \"$1\" ]]; then",
            "        printf \"Error: %s\\n\" \"$1\" >&2",
            "    fi",
            "    printf \"Error: The Execution did not complete successfully.\" >&2",
            "    exit 1",
            "}",
            "",
            "INSTANCE_ID=\"{{InstanceId}}\"",
            "BUCKET=\"{{S3BucketName}}\"",
            "EXECUTION_ID=\"{{automation:EXECUTION_ID}}\"",
            "# Get the Amazon S3 bucket path without the trailing /",
            "BUCKET_PATH=$(echo \"{{S3Path}}\" | sed 's#/\\+$##')",
            "ACCOUNT_ID=\"{{global:ACCOUNT_ID}}\"",
            "",
            "# Set AWS CLI environment variables",
            "export AWS_RETRY_MODE=\"standard\" # Specifies the retry mode for AWS API calls",
            "export AWS_MAX_ATTEMPTS=10 # Specifies the maximum retry attempts",
            "export AWS_DEFAULT_REGION=\"{{global:REGION}}\" # Sets default region",
            "",
            "# Get the Amazon S3 bucket location",
            "BUCKET_REGION=$(aws s3api get-bucket-location --bucket $BUCKET --query \"LocationConstraint\" --expected-bucket-owner \"$ACCOUNT_ID\" --output text) || error_trap \"Could not query the Amazon S3 bucket LocationConstraint.\"",
            "if [ -z \"$BUCKET_REGION\" ] || [ \"$BUCKET_REGION\" = \"None\" ]; then",
            "BUCKET_REGION=\"us-east-1\"",
            "fi",
            "",
            "# Create a unique tarball filename using EXECUTION_ID and INSTANCE_ID",
            "FILE_NAME=\"${EXECUTION_ID}_${INSTANCE_ID}.tgz\"",
            "",
            "# Make sure the bucket is accessible before running ec2rl",
            "aws s3api head-bucket --bucket \"$BUCKET\" --region \"$BUCKET_REGION\" --expected-bucket-owner \"$ACCOUNT_ID\" 1> /dev/null || error_trap \"No Amazon S3 bucket called $BUCKET found in the current AWS account or access denied. Please specify an Amazon S3 bucket you own and that this instance has access to.\"",
            "",
            "# Determine if the system is an instance",
            "NOT_AN_INSTANCE=\"--not-an-instance\"",
            "if ( [ -f /sys/hypervisor/uuid ] && grep -iE \"^ec2\" /sys/hypervisor/uuid >/dev/null ) \\",
            "|| ( [ -f /sys/devices/virtual/dmi/id/product_uuid ] && grep -iE \"^ec2\" /sys/devices/virtual/dmi/id/product_uuid >/dev/null ); then",
            "NOT_AN_INSTANCE=\"\"",
            "fi",
            "",
            "printf \"Running EC2 Rescue for Linux\\n\"",
            "printf \"The ec2rl run output directory will be uploaded to s3://%s/%s/%s\\n\" \"$BUCKET\" \"$BUCKET_PATH\" \"$FILE_NAME\"",
            "sudo ec2rl run ${NOT_AN_INSTANCE} --only-classes=collect,gather --times=3 --period=5 --domain=amazon.com --protocol=tcp --count=3 --destination=amazon.com --port=80 || error_trap \"The EC2Rescue execution did not complete successfully.\"",
            "",
            "# Find the most recently modified directory in /var/tmp/ec2rl",
            "LOG_DIR=\"$(basename \"$(find /var/tmp/ec2rl -maxdepth 1 -mindepth 1 -printf \"%T+ %p\\\\n\" | sort -r | head -n 1 | awk '{print $2}')\")\"",
            "",
            "printf \"Creating tarball %s.tgz of EC2RL log directory /var/tmp/ec2rl/%s\\n\" \"$EXECUTION_ID\" \"$LOG_DIR\"",
            "# Create a tarball of the ec2rl log directory",
            "tar -czf \"${FILE_NAME}\" -C /var/tmp/ec2rl \"${LOG_DIR}\" || error_trap \"Error compressing ${LOG_DIR}\"",
            "",
            "printf \"Uploading tarball to s3://%s/%s/%s\\n\" \"$BUCKET\" \"$BUCKET_PATH\" \"$FILE_NAME\"",
            "",
            "# Upload the tarball to the specified S3 bucket and path",
            "aws s3 cp \"$FILE_NAME\" \"s3://$BUCKET/$BUCKET_PATH/$FILE_NAME\" --region \"$BUCKET_REGION\" || error_trap \"Error uploading file to s3://$BUCKET/$BUCKET_PATH/$FILE_NAME\"",
            "printf \"Done\""
          ]
        }
      },
      "isCritical": true,
      "isEnd": true
    }
  ],
  "outputs": [
    "collectAndUploadWindowsLogBundle.Output",
    "collectAndUploadLinuxLogBundle.Output"
  ]
}
