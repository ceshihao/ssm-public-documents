{
  "description": "### Document name - AWSFIS-Run-Network-Packet-Loss-Sources\n\n## What does this document do?\nIt adds packet loss using the tool tc to outgoing or incoming traffic from a configurable list of sources (Supported: ALL, IPv4, IPv4/CIDR, Domain name, DYNAMODB|S3). If tc is not already installed on the instance, this SSM document will install it together with other dependencies listed below.\nThis SSM document supports Amazon Linux and Ubuntu operating systems only.\n\n## Dependencies installed by this SSM Document\n* atd\n* curl\n* dig\n* jq\n* kmod\n* lsof\n* pgrep\n* tc\nNote: This SSM document does not uninstall dependencies once installed. If you don't want this SSM document to install any dependencies, set InstallDependencies to False and bake the dependencies into your EC2 instance. For example, by using image-builder (https://aws.amazon.com/image-builder/).\nNote: Before you run this document, enable the kernel module sch_netem. To check if installed, run the following command on your instance - lsmod | grep sch_netem. On success, you will see sch_netem as output. If there is no output, run depmod -a to build a list of modules, and then run modprobe sch_netem. If you get an error, then the module is not available. If you are using Amazon Linux and the module is not available, verify that you are using the latest AMI and that you have installed the latest updates.\n\n## Input Parameters\n* Interface: The network interfaces, separated by commas. ALL and DEFAULT values are supported. The default is DEFAULT, which will target the primary network interface for the operating system.\n* FlowsPercent: The percentage of network flows that will be affected by the action. The default is 100%.\n* Sources: (Required) The sources, separated by commas, without spaces. The possible values are: an IPv4 address, an IPv4 CIDR block, a domain name, an AZ name (us-east-1a), an AZ ID (use1-az1), ALL, DYNAMODB, and S3. The default is ALL, which matches all IPv4 traffic.\n* TrafficType: Specify the type of traffic to delay (egress|ingress) (default: ingress).\n* LossPercent: The percent of packet loss. (default: 7).\n* DurationSeconds: (Required) The duration - in seconds - of the fault injection.\n* InstallDependencies: If set to True, Systems Manager installs the required dependencies on the target instances (default: True).\n\n## Output Parameters\nNone.",
  "schemaVersion": "2.2",
  "parameters": {
    "Interface": {
      "type": "String",
      "description": "The network interfaces, separated by commas. ALL and DEFAULT values are supported. The default is DEFAULT, which will target the primary network interface for the operating system.",
      "default": "DEFAULT",
      "allowedPattern": "^(ALL|DEFAULT|([0-9a-zA-Z\\-]{1,15},)*[0-9a-zA-Z\\-]{1,15})$"
    },
    "FlowsPercent": {
      "type": "String",
      "description": "The percentage of network flows that will be affected by the action. The default is 100%.",
      "default": "100",
      "allowedPattern": "^([1-9][0-9]?|100)$"
    },
    "Sources": {
      "type": "String",
      "description": "(Required) The sources, separated by commas, without spaces. The possible values are: an IPv4 address, an IPv4 CIDR block, a domain name, an AZ name (us-east-1a), an AZ ID (use1-az1), ALL, DYNAMODB, and S3. The default is ALL, which matches all IPv4 traffic.",
      "allowedPattern": "^[0-9a-zA-Z./,-]+$"
    },
    "TrafficType": {
      "type": "String",
      "description": "Specify the type of traffic to delay (egress|ingress) (default: ingress).",
      "default": "ingress",
      "allowedValues": [
        "egress",
        "ingress"
      ]
    },
    "LossPercent": {
      "type": "String",
      "description": "The percent of packet loss. (default: 7).",
      "default": "7",
      "allowedPattern": "^([1-9][0-9]?|100)$"
    },
    "DurationSeconds": {
      "type": "String",
      "description": "(Required) The duration - in seconds - of the fault injection.",
      "allowedPattern": "^[0-9]+$"
    },
    "InstallDependencies": {
      "type": "String",
      "description": "If set to True, Systems Manager installs the required dependencies on the target instances (default: True).",
      "default": "True",
      "allowedValues": [
        "True",
        "False"
      ]
    }
  },
  "mainSteps": [
    {
      "action": "aws:runShellScript",
      "name": "InstallDependencies",
      "precondition": {
        "StringEquals": [
          "platformType",
          "Linux"
        ]
      },
      "description": "## Parameter: InstallDependencies\nIf set to True, this step installs the required dependency via operating system's repository. It supports both\nDebian (apt) and CentOS (yum) based package managers.",
      "inputs": {
        "onFailure": "exit",
        "runCommand": [
          "#!/bin/bash\n\nset -o errexit\n\n#################################\n#       Dependency Logic        #\n#################################\n\nfunction install_sch_netem_module() {\n  ssm_working_dir=$(pwd)\n  # Work from a directory that Amazon SSM Agent creates\n  cd /etc/amazon/ssm/\n  current_working_dir=$(pwd)\n  kernel_version=$(uname -r)\n  # Default location of sch_netem module\n  sched_module_local_path=/lib/modules/\"$kernel_version\"/kernel/net/sched/\n  sch_netem_kernel_module_file=sch_netem.ko\n  # Check if there is no compressed and uncompressed version of the module\n  if [ ! -f \"${sched_module_local_path}$sch_netem_kernel_module_file\" ] && [ ! -f \"${sched_module_local_path}$sch_netem_kernel_module_file\".xz ]; then\n    echo \"sch_netem does not exist, installing\"\n    # We will download and install the sch_netem kernel module to avoid the need for a reboot, as\n    # would be required if we used `yum install kernel-modules-extra`.\n    temp_dir=kernel-lib\n    # If the yumdownloader comes back with no module available, then fail\n    if yumdownloader kernel-modules-extra-\"$kernel_version\" --destdir \"$temp_dir\" 2>&1 | grep \"No package kernel-modules-extra-$kernel_version available.\"; then\n      echo \"No sch_netem module for the kernel version $kernel_version\"\n      echo \"Exiting - Unable to install sch_netem. kernel module sch_netem must be installed for this document to run\"\n      rm -rf \"$temp_dir\"\n      exit 1\n    fi\n    # We need to CD into the temp_dir for cpio since it does not work with absolute or relative paths well\n    cd \"$temp_dir\"\n    # Unpacks the modules into lib/\n    # version is downloaded but will differ from $kernel_version, depending OS.\n    rpm2cpio kernel-modules-extra-\"$kernel_version\".rpm | cpio -id\n    # Move back to the working dir.\n    cd \"$current_working_dir\"\n    # if sch_netem exists in the rpm lib, move it to /etc/amazon/ssm\n    sch_netem_path=$(find \"$temp_dir\"/lib -name \"$sch_netem_kernel_module_file\".xz)\n    if [ -n \"${sch_netem_path}\" ]; then\n      echo \"Downloaded Kernel Modules, and sch_netem exists. Loading Module\"\n      mv \"${sch_netem_path}\" \"$current_working_dir\"\n      # Do not need the rest of the temp_dir\n      rm -rf \"$temp_dir\"\n      echo \"Unpacking sch_netem\"\n      xz -d \"$sch_netem_kernel_module_file\".xz\n      rm -f \"$sch_netem_kernel_module_file\".xz\n      # Create a symlink to the default location so that the module can be added to the list of available modules by depmod\n      ln -s \"$current_working_dir\"/$sch_netem_kernel_module_file /lib/modules/\"$kernel_version\"/\"$sch_netem_kernel_module_file\"\n      echo \"Loading sch_netem\"\n      # Refresh the list of available modules\n      depmod -a\n      modprobe sch_netem\n      # Check if loaded successfully\n      if lsmod | grep -wq \"sch_netem\"; then\n        echo \"$sch_netem_kernel_module_file module installed and loaded\"\n      else\n        echo \"Exiting - Error loading module, kernel module sch_netem.ko must be installed for this document to run\"\n        exit 1\n      fi\n    else\n      # make sure our temp file deleted.\n      rm -rf \"$temp_dir\"\n      echo \"Exiting - Unable to install sch_netem. kernel module sch_netem must be installed for this document to run\"\n      exit 1\n    fi\n  # Check if the module exists and enable it\n  elif [[ -f \"${sched_module_local_path}/$sch_netem_kernel_module_file\" ]]; then\n    if modinfo ${sched_module_local_path}/$sch_netem_kernel_module_file -F vermagic | awk '{print $1}' | grep -Fi \"$kernel_version\"; then\n      # Lets build an updated list of available modules first\n      depmod -a\n      # Insert module\n      modprobe sch_netem\n    fi\n  # if the compressed module exist, uncompress and enable\n  elif [[ -f \"${sched_module_local_path}$sch_netem_kernel_module_file\".xz ]] && [ ! -f \"${sched_module_local_path}$sch_netem_kernel_module_file\" ]; then\n    # Module exists, so we need to unpack it and insert the module in the kernel it\n    xz -d -k \"${sched_module_local_path}/$sch_netem_kernel_module_file\".xz\n    if modinfo ${sched_module_local_path}/$sch_netem_kernel_module_file -F vermagic | awk '{print $1}' | grep -Fi \"$kernel_version\"; then\n      # Lets build an updated list of available modules first\n      depmod -a\n      # Insert module\n      modprobe sch_netem\n    fi\n  fi\n  cd \"$ssm_working_dir\"\n}\n\nfunction check_and_install_netem() {\n  if ! lsmod | grep -wq \"sch_netem\"; then\n    # To avoid issues with SELinux we wrap everything in sudo.\n    # In order to call the install_sch_netem_module function wrapped with sudo,\n    # we need to pass it as a command rather than a function call.\n    SUDOINSTALL=$(declare -f install_sch_netem_module)\n    sudo bash -c \"$SUDOINSTALL; install_sch_netem_module\" 2>&1\n    # Check if loaded\n    if lsmod | grep -wq \"sch_netem\"; then\n      echo \"sch_netem.ko Module loaded\"\n    else\n      echo \"Exiting - Error loading module, kernel module sch_netem.ko must be installed for this document to run\"\n      exit 1\n    fi\n  fi\n}\n\n########################################################################################################################\n # This script builds a list of available modules and enables sch_netem                                                #\n # sch_netem kernel module is responsible for emulating traffic,                                                       #\n # FIS SSM Documents use this module when creating network faults, such as the packet loss fault and the latency fault #\n########################################################################################################################\n# Build a list of the available modules\nenable_netem() {\n  if ! command -v depmod &> /dev/null; then\n    echo \"WARN depmod is not available. Command could fail due to missing sch_netem\"\n    return 0\n  else\n    depmod -a || echo \"enable_netem() - WARN depmod -a failed, continuing anyway\"\n    # Enable the sch_netem module, if there is a failure, exit\n    if ! modprobe sch_netem; then\n      echo \"WARN Cannot enable sch_netem\"\n      echo \"WARN Command could fail due to missing sch_netem\"\n      return 0\n    fi\n  fi\n  return 0\n}\n\n# Configure ATD service if required\nconfigure_atd() {\n  if ! systemctl is-enabled atd || ! systemctl is-active atd; then\n    echo \"Enabling and starting atd\"\n    systemctl enable atd\n    systemctl start atd\n  fi\n}\n\n# Check if dependencies are already installed\ncheck_existing_dependencies() {\n  if [[ \"$( command -v atd 2>/dev/null )\" && \"$( command -v curl 2>/dev/null )\" && \"$( command -v dig 2>/dev/null )\" && \"$( command -v jq 2>/dev/null )\" && \"$( command -v kmod 2>/dev/null )\" && \"$( command -v lsof 2>/dev/null )\" && \"$( command -v pgrep 2>/dev/null )\" && \"$( command -v tc 2>/dev/null )\" ]]; then\n  \n    depmod -a || echo \"check_existing_dependencies() - WARN depmod -a failed, continuing anyway\"\n    if modprobe sch_netem; then\n      exit\n    fi\n  \n  fi\n}\n\nvalidate_installation_settings() {\n  if [[ \"{{ InstallDependencies }}\" == False ]]; then\n    echo \"Missing dependencies detected with InstallDependencies set to false. Please install dependencies [\"atd\", \"curl\", \"dig\", \"jq\", \"kmod\", \"lsof\", \"pgrep\", \"tc\"] or set InstallDependencies to true for supported operating systems.\" >&2\n    exit 1\n  fi\n}\n\n# Handle Amazon Linux installations\ninstall_amazon_linux() {\n  if ! grep -Fiq 'VERSION_ID=\"2023\"' /etc/os-release; then\n  \n    # Use amazon-linux-extras if available (Amazon Linux 2)\n    command -v amazon-linux-extras 2>/dev/null 1>&2 && amazon-linux-extras install testing\n  \n    yum -y install at bind-utils jq kmod lsof procps-ng tc\n  elif grep -Fiq 'ID=\"amzn\"' /etc/os-release && grep -Fiq 'VERSION_ID=\"2023\"' /etc/os-release; then\n      enable_netem\n  \n    yum -y install at curl-minimal bind-utils jq kmod lsof procps-ng iproute-tc\n  else\n    echo \"Exiting - This SSM document supports: Amazon Linux 2023, Amazon Linux 2, Ubuntu, CentOS 9 and RHEL (8, 9) operating systems\"\n    exit 1\n  fi\n}\n\n# Extract OS version information (used by RHEL/CentOS functions)\nget_os_version() {\n  os_version_number=$(grep -oP '(?<=^VERSION_ID=).+' /etc/os-release | tr -d '\"')\n  # if the version has a decimal, this line will remove it\n  os_major_version_number=${os_version_number%.*}\n}\n\n# Handle RHEL/CentOS installations\nscaffold_rhel_centos() {\n  get_os_version\n  # Replace with version number in the url if required\n  if ! rpm --quiet -q epel-release; then\n    epel_dl_url=\"https://dl.fedoraproject.org/pub/epel/epel-release-latest-VERSION.noarch.rpm\"\n    epel_with_version=\"${epel_dl_url/VERSION/$os_major_version_number}\"\n    yum -y install $epel_with_version\n  fi\n    check_and_install_netem\n}\n\n# Install packages for RHEL/CentOS with version-specific package name handling\ninstall_rhel_centos_packages() {\n  local packages=\"$1\"\n  get_os_version\n\n  # For centos/rhel 7 the package is iproute, so remove the suffix if iproute is there\n  # since this command is directly related to the use of sch_netem.\n  if [[ ${packages} == *iproute-tc* ]] && [ \"$os_major_version_number\" -eq \"7\" ]; then\n    packages=${packages/iproute-tc/iproute}\n  fi\n  yum -y install $packages\n}\n\n# Handle Ubuntu installations\ninstall_ubuntu() {\n  apt-get update -y\n  # when installing, sometimes ubuntu has stderr that are not breaking errors.\n  install_error=$(apt-get install -y at dnsutils jq kmod lsof procps iproute2 2>&1)\n  if [[ -n \"$install_error\" ]]; then\n    echo \"$install_error\"\n  fi\n\n  ubuntu_commands=( atd curl dig jq kmod lsof pgrep tc )\n  for dependency_command in \"${ubuntu_commands[@]}\"; do\n    if ! command -v $dependency_command >/dev/null 2>&1; then\n      echo \"Exiting - $dependency_command not installed\"\n      exit 1\n    fi\n  done\n}\n\n# Main function to orchestrate the installation process\nmain() {\n  check_existing_dependencies\n  validate_installation_settings\n\n  echo \"Installing required dependencies\"\n  trap 'status=$?; if [ $status -eq 1 ]; then echo \"Failed to install dependencies. Please retry or manually install dependencies [\"atd\", \"curl\", \"dig\", \"jq\", \"kmod\", \"lsof\", \"pgrep\", \"tc\"] and set InstallDependencies to false.\" >&2; fi' EXIT\n\n  if [ -f \"/etc/system-release\" ] && grep -i 'Amazon Linux' /etc/system-release; then\n    install_amazon_linux\n  elif grep -Fiq 'ID=\"centos\"' /etc/os-release; then\n    scaffold_rhel_centos\n    install_rhel_centos_packages \"at bind-utils jq kmod lsof procps iproute-tc\"\n  elif grep -Fiq 'ID=\"rhel\"' /etc/os-release; then\n    scaffold_rhel_centos\n    install_rhel_centos_packages \"at bind-utils jq kmod lsof procps iproute-tc\"\n  elif grep -i \"Ubuntu\" /etc/issue; then\n    install_ubuntu\n  else\n    echo \"Exiting - This SSM document supports: Amazon Linux 2023, Amazon Linux 2, Ubuntu, CentOS 9 and RHEL (8, 9) operating systems\"\n    exit 1\n  fi\n  configure_atd\n}\n\n# Execute main function\nmain\n"
        ]
      }
    },
    {
      "action": "aws:runShellScript",
      "name": "FaultInjection",
      "precondition": {
        "StringEquals": [
          "platformType",
          "Linux"
        ]
      },
      "description": "## Parameters: Sources, FlowsPercent, TrafficType, Interface, LossPercent, and DurationSeconds\nThis step starts by extracting the IP for all the `Sources` provided and adds a `LossPercent` (in percent) to `TrafficType` traffic on the `Interface` for the given `DurationSeconds`, affecting only `FlowsPercent` of network flows, using the `tc` (Traffic Control) command.\nThe script will inject packet loss on the `TrafficType` traffic for the `Sources`, and wait for the given duration to remove that. It has two rollback mechanisms in place:\n* It will listen for exit signals (SIGINT and SIGTERM), and will stop the packet loss injection if any of them is received.\n* It will periodically enqueue rollback checks into a queue (using `at` command). This way, if the command is stopped and the rollback\nwas not executed, the enqueued commands will try to stop it. (for example, if the command is stopped using kill -9). This is just\nan extra safety check to avoid having the packet loss remain injected after the script is no longer running.",
      "inputs": {
        "maxAttempts": 1,
        "timeoutSeconds": 43200,
        "runCommand": [
          "#!/bin/bash\nset -o errexit -o errtrace -o nounset -o pipefail\n\n########################\n# Fault-specific logic #\n########################\n\nINTERFACE={{ Interface }}\nLOSS={{ LossPercent }}\nDURATION={{ DurationSeconds }}\nSOURCES={{ Sources }}\nTRAFFIC_TYPE={{ TrafficType }}\nFLOWS_PCT={{ FlowsPercent }}\n\nvalidate_parameter_within_range() {\n  local parameter=$1\n  local value=$2\n  local min=$3\n  local max=$4\n\n  if (( value >= min && value <= max )); then\n    return 0\n  fi\n\n  echo \"Parameter $parameter must be between $min and $max, was: '$value'\" >&2\n  exit 1\n}\n\nvalidate_running_in_ssm_document() {\n  # Check if the script is running in an SSM document by verifying that AWS_SSM_REGION_NAME environment variable is set\n  if [[ -n \"${AWS_SSM_REGION_NAME-}\" ]]; then\n    return 0\n  fi\n\n  echo \"Environment variable AWS_SSM_REGION_NAME is not set. Run this script as part of an SSM document.\" >&2\n  exit 1\n}\n\nget_valid_interfaces() {\n  local -r interfaces=\"$1\"\n  local valid_interfaces=()\n\n  # Input validation\n  if [[ -z \"$interfaces\" ]]; then\n    echo \"Error: No interfaces specified\" >&2\n    exit 1\n  fi\n\n  # Helper function to validate interface exists\n  validate_interface() {\n    [[ -n \"$(ip a ls \"$1\" 2>/dev/null)\" ]]\n  }\n\n  if [[ \"$interfaces\" == \"DEFAULT\" ]]; then\n    # Get default route interface\n    local default_iface\n    default_iface=$(awk '$2 == \"00000000\" {print $1; exit}' /proc/net/route 2>/dev/null)\n    \n    # Fallback if primary method fails\n    if [[ -z \"$default_iface\" ]]; then\n      default_iface=$(ip route show default 2>/dev/null | awk '{print $5}' | head -1)\n    fi\n    \n    if [[ -z \"$default_iface\" ]]; then\n      echo \"Error: No default route interface found\" >&2\n      exit 1\n    fi\n    \n    if validate_interface \"$default_iface\"; then\n      valid_interfaces+=(\"$default_iface\")\n    else\n      echo \"Error: Default route interface '$default_iface' does not exist\" >&2\n      exit 1\n    fi\n    \n  elif [[ \"$interfaces\" == \"ALL\" ]]; then\n    # This will exclude:\n    # - lo*: loopback interface (e.g. lo0)\n    # - docker*: Docker bridge interfaces (e.g. docker0)\n    # - br*: Linux bridge interfaces (e.g. br-e19c6a403ba1)\n    # This will also extract the interface name before the @ symbol for veth (virtual Ethernet) interfaces (e.g. eth0@if7 => eth0)\n    local all_interfaces\n    all_interfaces=$(ip link show 2>/dev/null | \\\n      awk -F': ' '/^[0-9]+:/ {print $2}' | \\\n      grep -v -E '^(lo|docker|br)' | \\\n      cut -d'@' -f1 | \\\n      sort -u || true)\n\n    # Validate each interface\n    for interface in $all_interfaces; do\n      if validate_interface \"$interface\"; then\n        valid_interfaces+=(\"$interface\")\n      fi\n    done\n    \n    if [[ ${#valid_interfaces[@]} -eq 0 ]]; then\n      echo \"Error: No valid interfaces found for ALL option\" >&2\n      exit 1\n    fi\n    \n  else\n    # Handle comma-separated list\n    local IFS=','\n    for interface in $interfaces; do\n      if validate_interface \"$interface\"; then\n        valid_interfaces+=(\"$interface\")\n      fi\n    done\n    unset IFS\n\n    if [[ ${#valid_interfaces[@]} -eq 0 ]]; then\n      echo \"None of the specified interfaces exist: $interfaces\" >&2\n      exit 1\n    fi\n  fi\n\n  # Output sorted unique interfaces\n  printf '%s ' $(printf '%s\\n' \"${valid_interfaces[@]}\" | sort -u)\n}\nvalidate_network_ingress_fault_not_running() {\n  local -r traffic_type=\"$1\"\n\n  if [ \"$traffic_type\" = \"ingress\" ]; then\n    ip a ls ifb0 1>/dev/null 2>&1 && { echo \"Fault might be already running (Interface ifb0 already exists). Exiting...\" 1>&2 ; exit 1; }\n  fi\n\n  return 0\n}\n\nvalidate_protected_ips_not_in_target_ips() {\n  local -r ips=\"$1\"\n  local -r ssm_ips=\"$2\"\n  local restore_hosts_file=\"$3\"\n\n  # Converts space-separated strings to arrays\n  local -a ip_array\n  local -a ssm_ip_array\n  read -ra ip_array <<< \"$ips\"\n  read -ra ssm_ip_array <<< \"$ssm_ips\"\n\n  # Checks if any of the SSM endpoint IPs are in the sources and exiting if true\n  for e in \"${ip_array[@]}\"; do\n    for ip in \"${ssm_ip_array[@]}\"; do\n      [[ \"$e\" = \"$ip\" ]] &&\n        { \n          echo \"Sources contain protected SSM endpoint: ${e} - exiting\" >&2\n          eval \"$restore_hosts_file\"\n          exit 1\n        }\n    done\n  done\n\n  return 0\n}\n\nforce_dns() {\n  local -r hostname=\"$1\"    # Hostname is expected as first argument\n  local -ar ips=(\"${@:2}\")  # The rest will be the IPs\n\n  # Force any new DNS resolution for that host to the latest known IPs\n  for ip in \"${ips[@]}\"; do\n    echo \"$ip $hostname ${DELETE_MSG:-\"#delete-after-fault-injection\"}\" >> \"${HOSTS_FILE:-/etc/hosts}\"\n  done\n\n  return 0\n}\n\nget_ips_from_input() {\n  local -r input=\"$1\"\n  local -r regex=\"$2\"\n\n  # Echoes the input and returns 0 if the input is valid, otherwise returns 1\n  local -r validated_input=$(grep -E \"$regex\" <<< \"$input\")\n  [ -z \"$validated_input\" ] || { echo \"$validated_input\" ; return 0 ;}\n\n  return 1\n}\n\nget_ips_from_dns() {\n  local -r domain=\"$1\"\n  local -a resolved_ips=()\n\n  # Echoes IPs of the domain and forces DNS resolution to the IPs then returns 0, otherwise returns 1\n  # Since `dig` can return different IPs, we call it 10 times to maximize the chances of covering as many IPs as possible for the provided domain\n  for _ in {1..10}\n    do\n      local -a dig_output=( $(dig +short \"$domain\" | grep -v '[[:alpha:]]') )\n      [ ${#dig_output[@]} -eq 0 ] || resolved_ips+=(\"${dig_output[@]}\")\n    done\n\n  if [ ${#resolved_ips[@]} -gt 0 ]; then\n    local -ar unique_resolved_ips=( $(printf '%s\\n' \"${resolved_ips[@]}\" | sort -u) )\n    [ ${#unique_resolved_ips[@]} -eq 0 ] || { echo \"${unique_resolved_ips[@]}\" ; force_dns \"$domain\" \"${unique_resolved_ips[@]}\" ; return 0 ;}\n  fi\n\n  return 1\n}\n\nget_protected_ips_from_protected_endpoints() {\n  local get_ips=\"$1\"\n  local -ar endpoints=(\"${@:2}\")\n\n  for e in \"${endpoints[@]}\"; do\n    local ips_output\n    ips_output=$(eval \"get_ips \\\"$e\\\"\")\n    if [[ -n \"$ips_output\" ]]; then\n      local -a ips=()\n      read -ra ips <<< \"$ips_output\"\n      PROTECTED_IPS+=(\"${ips[@]}\")\n    fi\n  done\n\n  return 0\n}\n\nget_protected_ips_from_ssm_connections() {\n  local -r regex=\"$1\"\n\n  if pgrep ssm > /dev/null; then\n    local -r ssm_connections=( $(lsof -a -nPi4 -c /ssm/ -Fn | awk '$1 ~ /^n/' | awk -F'->' '{print $2}' | awk -F':' '{print $1}' | awk \"/$regex/\" | awk NF) )\n    [ ${#ssm_connections[@]} -eq 0 ] || PROTECTED_IPS+=(\"${ssm_connections[@]}\")\n  fi\n\n  return 0\n}\n\nget_sorted_unique_protected_ips() {\n  if [ ${#PROTECTED_IPS[@]} -gt 0 ]; then\n    PROTECTED_IPS=($(for ip in \"${PROTECTED_IPS[@]}\"; do echo \"${ip}\"; done | sort -u))\n  fi\n\n  return 0\n}\n\n# Get the REGION of the instance\nEC2_REGION=$AWS_SSM_REGION_NAME\n\nIP_CIDR_REGEX=\"^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/(3[0-2]|[1-2][0-9]|[0-9]))$\"\n\nIP_REGEX=\"^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$\"\n\nDELETE_MSG=\"#delete-after-fault-injection\"\n\n# Endpoints we want to preserve (SSM API)\nSSMMESSAGES_ENDPOINT=ssmmessages.$AWS_SSM_REGION_NAME.amazonaws.com\nSSM_ENDPOINT=ssm.$AWS_SSM_REGION_NAME.amazonaws.com\nEC2MESSAGES_ENDPOINT=ec2messages.$AWS_SSM_REGION_NAME.amazonaws.com\n\nPROTECTED_ENDPOINTS=(\n  \"${SSMMESSAGES_ENDPOINT}\"\n  \"${SSM_ENDPOINT}\"\n  \"${EC2MESSAGES_ENDPOINT}\"\n)\n\nget_target_ips_from_sources() {\n  local get_ips=\"$1\"\n  local sources=\"$2\"\n\n  # Check if ANY source is \"ALL\" - short circuit to target all traffic\n  for source in ${sources//,/ }; do\n    if [[ \"$source\" == \"ALL\" ]]; then\n      TARGET_IPS=(\"0.0.0.0/0\")\n      echo \"Target IPs and ranges: ${TARGET_IPS[*]} (targeting all traffic)\"\n      return 0\n    fi\n  done\n\n  # Prepares the sources and get IPs for all of them\n  local -a invalid_sources=()\n  for source in ${sources//,/ }; do\n    ips=$(eval \"get_ips \\\"$source\\\"\")\n    if [ -n \"$ips\" ]; then\n      for ip in ${ips[*]}; do\n        TARGET_IPS+=(\"${ip}\")\n      done\n    else\n      invalid_sources+=(\"${source}\")\n    fi\n  done\n\n  if [ ${#invalid_sources[@]} -gt 0 ]; then\n    echo \"Invalid sources (malformed service name, DNS or IP address): ${invalid_sources[*]}\" >&2\n    exit 1\n  fi\n\n  echo \"Target IPs and ranges: ${TARGET_IPS[*]}\"\n\n  return 0\n}\n\nget_ips_from_aws_service() {\n  local -r input=\"$1\"\n  local -r ip_range_url=\"$2\"\n  local -r ec2_region=\"$3\"\n\n  # Only accepting DYNAMODB and S3 from ip-range service\n  if [[ \"$input\" =~ ^(\"DYNAMODB\"|\"S3\")$ ]]; then\n    # Echoes IPs of the Service\n    curl -s \"${ip_range_url}\" --connect-timeout 5 | jq -r '.prefixes[] | select(.region==\"'$ec2_region'\") | select(.service==\"'$input'\") | .ip_prefix'\n  fi\n}\n\nadd_imds_ip_to_protected_endpoints() {\n  local -r instance_id=\"$1\"\n\n  # Only on EC2 instances add EC2 metadata. On-premise instances will be prefixed with \"mi-\"\n  if [[ \"$instance_id\" =~ ^i-.* ]]; then\n    echo \"Running on EC2 instance. Adding EC2 metadata IP to PROTECTED_ENDPOINTS\"\n    PROTECTED_ENDPOINTS+=(\"${IMDS_IP:-\"169.254.169.254\"}\") \n  fi\n\n  return 0\n}\n\n# Function to configure the qdisc layers\nconfigure_qdisc_layers() {\n  if [ $# -eq 0 ]; then\n    echo \"Error: Device parameter is required\" >&2\n    return 1\n  fi\n\n  local device=$1\n  echo \"Creating 1st layer...\"\n  tc qdisc add dev $device root handle 1: prio bands 3 priomap 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n\n  echo \"Creating 2nd layer...\"\n  tc qdisc add dev $device parent 1:1 handle 10: prio bands 10 priomap 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n\n  echo \"Creating 3rd layer...\"\n  # 3rd layer: Create 10-band prio under each of 10:1 to 10:a\n  for i in $(seq 1 10); do\n    handle=$((100 + i - 1))  # 100, 101, 102, ..., 109\n    if [ $i -eq 10 ]; then\n      parent_class=\"10:a\"  # 10th is 'a' in hexadecimal\n    else\n      parent_class=\"10:$i\"\n    fi\n    echo \"Adding child $handle: to parent $parent_class\"\n    tc qdisc add dev $device parent $parent_class handle $handle: prio bands 10 priomap 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n  done\n}\n\n#!/bin/bash\n\napply_packet_loss_rules() {\n    local device=$1\n    local flows_pct=$2\n    local loss=$3\n\n    echo \"Applying netem loss to each band in 3rd layer...\"\n    for ((k=0; k<$flows_pct && k<100; k++)); do\n        i=$((k/10))\n        j=$((k%10 + 1))\n        parent_handle=$((100 + i))\n        netem_handle=$((200 + i * 10 + j))\n        child_class=\"$parent_handle:${j/10/a}\"\n\n        echo \"Adding netem $netem_handle: to parent $child_class...\"\n        tc qdisc add dev $device parent $child_class handle $netem_handle: \\\n            netem loss \"${loss}%\"\n    done\n}\n# Function to set up filters\nsetup_hash_flows_filters() {\n  if [ $# -eq 0 ]; then\n    echo \"Error: Device parameter is required\" >&2\n    return 1\n  fi\n\n  local device=$1\n\n  tc filter add dev $device parent 10: handle 1 protocol ip prio 1 flow \\\n      hash keys src,dst,proto,proto-src,proto-dst divisor 10 baseclass 10:1\n\n  for i in $(seq 1 10); do\n      parent_handle=$((100 + i - 1))\n      baseclass=\"$parent_handle:1\"\n      echo \"Adding filter: parent $parent_handle: baseclass $baseclass\"\n      tc filter add dev $device parent $parent_handle: handle $i protocol ip prio 1 flow \\\n          hash keys src,dst,proto,proto-src,proto-dst divisor 10 baseclass $baseclass\n  done\n}\nrestore_hosts_file() {\n  local mutated_hosts_file\n  mutated_hosts_file=$(mktemp)\n\n  if ! cp \"${HOSTS_FILE:-/etc/hosts}\" \"$mutated_hosts_file\"; then\n    echo \"Failed to copy current hosts file - exiting without restoring hosts file\" >&2\n    rm -f \"$mutated_hosts_file\"\n    exit 1\n  fi\n\n  local restored_hosts_file\n  restored_hosts_file=$(mktemp)\n\n  sed \"/${DELETE_MSG:-\"#delete-after-fault-injection\"}/d\" \"${HOSTS_FILE:-/etc/hosts}\" > \"$restored_hosts_file\"\n\n  local actual_deleted_lines\n  actual_deleted_lines=$(grep --invert-match --line-regexp --fixed-strings --file=\"$restored_hosts_file\" \"$mutated_hosts_file\" || true)\n\n  local expected_deleted_lines\n  expected_deleted_lines=$(grep \"${DELETE_MSG:-\"#delete-after-fault-injection\"}\" \"$mutated_hosts_file\" || true)\n\n  if [ \"$actual_deleted_lines\" != \"$expected_deleted_lines\" ]; then\n    echo \"sed operation produced unexpected results - exiting without restoring hosts file\" >&2\n    echo \"Before sed operation:\" >&2\n    cat \"${mutated_hosts_file}\" >&2\n    echo \"After sed operation:\" >&2\n    cat \"${restored_hosts_file}\" >&2\n    rm -f \"$restored_hosts_file\" \"$mutated_hosts_file\"\n    exit 1\n  fi\n\n  if ! cat \"$restored_hosts_file\" > \"${HOSTS_FILE:-/etc/hosts}\"; then\n    echo \"Failed to write back to hosts file\" >&2\n    rm -f \"$restored_hosts_file\" \"$mutated_hosts_file\"\n    exit 1\n  fi\n\n  local final_deleted_lines\n  final_deleted_lines=$(grep --invert-match --line-regexp --fixed-strings --file=\"${HOSTS_FILE:-/etc/hosts}\" \"$mutated_hosts_file\" || true)\n\n  if [ \"$final_deleted_lines\" != \"$expected_deleted_lines\" ]; then\n    echo \"Hosts file restore verification failed after write-back to hosts file\" >&2\n    echo \"Mutated file content:\" >&2\n    cat \"${mutated_hosts_file}\" >&2\n    echo \"Before write-back operation:\" >&2\n    cat \"${restored_hosts_file}\" >&2\n    echo \"After write-back operation:\" >&2\n    cat \"${HOSTS_FILE:-/etc/hosts}\" >&2\n    rm -f \"$restored_hosts_file\" \"$mutated_hosts_file\"\n    exit 1\n  fi\n\n  rm -f \"$restored_hosts_file\" \"$mutated_hosts_file\"\n  echo \"Hosts file restore completed successfully\"\n}\n\n# Trap to ensure hosts file is restored on exit\ntrap 'restore_hosts_file' EXIT\n\nget_ips()\n{\n  local -r input=\"$1\"\n\n  get_ips_from_input \"$input\" \"$IP_CIDR_REGEX\" ||\n  get_ips_from_input \"$input\" \"$IP_REGEX\" ||\n  get_ips_from_dns \"$input\" ||\n  get_ips_from_aws_service \"$input\" \"$IP_RANGES_URL\" \"$EC2_REGION\"\n}\n\nVALID_INTERFACES=$(get_valid_interfaces \"$INTERFACE\")\nvalidate_network_ingress_fault_not_running \"$TRAFFIC_TYPE\"\nvalidate_parameter_within_range \"DurationSeconds\" $DURATION 1 43200\nvalidate_parameter_within_range \"FlowsPercent\" $FLOWS_PCT 1 100\nvalidate_parameter_within_range \"LossPercent\" $LOSS 0 100\nvalidate_running_in_ssm_document\n\nFAULT_NAME=\"Run-Network-Packet-Loss-Sources\"\n\nIP_RANGES_URL=\"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n\nIMDS_IP=169.254.169.254\n\nPROTECTED_IPS=()\nadd_imds_ip_to_protected_endpoints \"$AWS_SSM_INSTANCE_ID\"\nget_protected_ips_from_protected_endpoints get_ips \"${PROTECTED_ENDPOINTS[@]}\"\nget_protected_ips_from_ssm_connections \"$IP_REGEX\"\nget_sorted_unique_protected_ips\n\nTARGET_IPS=()\nget_target_ips_from_sources get_ips \"${SOURCES[@]}\"\n\nvalidate_protected_ips_not_in_target_ips \"${TARGET_IPS[*]}\" \"${PROTECTED_IPS[*]}\" restore_hosts_file\n\n# Function to enable fault for egress\nenable_fault_egress() {\n  # Exit if FIS network fault is already running\n  test_file_exit() {\n    if [ \"$(ls $1 2>/dev/null | wc -l)\" -ge \"2\" ]; then { echo \"Fault might be already running (Found flag file matching \"$1\"). Exiting...\" 1>&2 ; exit 1; } ; fi;\n  }\n  test_file_exit \"/var/lib/amazon/ssm/Run-Network-*.flag\"\n\n  echo \"Injecting fault...\"\n  for interface in $VALID_INTERFACES; do\n    echo \"Configuring interface: $interface\"\n\n\t  configure_qdisc_layers \"$interface\"\n\n    apply_packet_loss_rules \"$interface\" \"$FLOWS_PCT\" \"$LOSS\"\n\n    for ip in ${PROTECTED_IPS[*]}; do\n      tc filter add dev $interface protocol ip parent 1:0 prio 1 u32 match ip dst $ip flowid 1:3\n    done\n\n    for ip in ${TARGET_IPS[*]}; do\n      tc filter add dev $interface protocol ip parent 1:0 prio 2 u32 match ip dst $ip flowid 1:1\n      echo \"Added filter for IP: $ip\"\n    done\n\n    setup_hash_flows_filters \"$interface\"\n  done\n}\n\n# Function to disable fault for egress\ndisable_fault_egress() {\n  echo \"Rolling back...\"\n  for interface in $VALID_INTERFACES; do\n    tc qdisc del dev $interface parent 1:1 handle 10: 2>/dev/null || true\n    tc qdisc del dev $interface root handle 1: prio 2>/dev/null || true\n  done\n  restore_hosts_file\n}\n\n# Function to enable fault for ingress\nenable_fault_ingress() {\n  # Exit if FIS network fault is already running\n  test_file_exit() {\n    if [ \"$(ls $1 2>/dev/null | wc -l)\" -ge \"2\" ]; then { echo \"Fault might be already running (Found flag file matching \"$1\"). Exiting...\" 1>&2 ; exit 1; } ; fi;\n  }\n  test_file_exit \"/var/lib/amazon/ssm/Run-Network-*.flag\"\n\n  echo \"Injecting fault...\"\n  # tc can only add packet loss on egress traffic so we use an intermediate device ifb\n  # Loading the ifb module (Intermediate Functional Block device)\n\n  interface_count=$(echo \"$VALID_INTERFACES\" | wc -w)\n  modprobe ifb numifbs=$interface_count\n\n  # Configure each interface with its own IFB device\n  local interface_index=0\n  for interface in $VALID_INTERFACES; do\n    ifb_device=\"ifb${interface_index}\"\n\n    # Bring up the IFB interface\n    ip link set dev $ifb_device up\n\n    echo \"Configuring interface: $interface with $ifb_device\"\n    # Add an ingress queue to the interface\n    tc qdisc add dev $interface ingress\n\n    for k in ${PROTECTED_IPS[*]}; do\n      tc filter add dev $interface parent ffff: protocol ip prio 1 u32 match ip src $k flowid 1:1\n    done\n\n    configure_qdisc_layers $ifb_device\n\n    apply_packet_loss_rules \"$ifb_device\" \"$FLOWS_PCT\" \"$LOSS\"\n\n    setup_hash_flows_filters \"$ifb_device\"\n\n    for k in ${TARGET_IPS[*]}; do\n      # Redirect matching traffic to dedicated ifb device\n      tc filter add dev $interface parent ffff: protocol ip prio 2 u32 match ip src $k flowid 1:1 action mirred egress redirect dev $ifb_device\n\n      tc filter add dev $ifb_device protocol ip parent 1:0 prio 1 u32 match ip src $k flowid 1:1\n      echo \"Added filter for IP: $k\"\n    done\n\n    ((interface_index++)) || true\n  done\n}\n\ndisable_fault_ingress() {\n  echo \"Rolling back...\"\n  local interface_index=0\n  for interface in $VALID_INTERFACES; do\n    tc qdisc del dev $interface ingress 2>/dev/null || true\n    tc qdisc del dev \"ifb${interface_index}\" root 2>/dev/null || true\n    ((interface_index++)) || true\n  done\n  rmmod ifb\n  restore_hosts_file\n}\n\n#################################\n# General fault-execution logic #\n#################################\n\n# Function to generate the flag path\nget_flag_path() {\n  local fault_name=\"$1\"\n  local random_string=\"$2\"\n  echo \"/var/lib/amazon/ssm/$fault_name-$random_string.flag\"\n}\n\n# Function to generate the rollback path\nget_rollback_path() {\n  local fault_name=\"$1\"\n  local random_string=\"$2\"\n  echo \"/var/lib/amazon/ssm/$fault_name-$random_string-Rollback.sh\"\n}\n\nget_user_vars() {\n    # Define system variable patterns to exclude\n    local patterns=(\n        '^BASH_'\n        '^COMP_'\n        '^EUID$'\n        '^PPID$'\n        '^SHELLOPTS$'\n        '^UID$'\n        '^PWD$'\n        '^OLDPWD$'\n        '^SHLVL$'\n        '^_$'\n    )\n    \n    # Join patterns with |\n    local exclude_pattern=$(IFS='|'; echo \"${patterns[*]}\")\n    \n    # Get variables using set\n    set | grep \"^[A-Za-z][A-Za-z0-9_]*=\" | \n    grep -Ev \"$exclude_pattern\" | \n    grep -Ev \"^(patterns|exclude_pattern)=\"\n}\n\n# Function to create rollback script\ncreate_rollback_script() {\n  local FLAG_PATH=\"$1\"\n  local ROLLBACK_PATH=\"$2\"\n  local MAX_FLAG_AGE_SECONDS=\"$3\"\n  local ATTEMPT_ROLLBACK_AT_SECONDS=\"$4\"\n  local DISABLE_FAULT_COMMAND=\"$5\"\n  local ROLLBACK_LOG_FILE=\"/tmp/aws-fis-rollback-$(date -u +%Y-%m-%dT%H:%M:%SZ)-$$.log\"\n\n  # Validate that required functions exist before creating the script\n  if ! declare -f restore_hosts_file >/dev/null 2>&1; then\n    echo \"ERROR: restore_hosts_file function required but not found\" >&2\n    return 1\n  fi\n\n  # Creating a file with rollback check command to be executed by atd\n  cat << EOF > \"$ROLLBACK_PATH\"\n#!/bin/bash\n# Environment variables needed to run the rollback command\n$(get_user_vars)\n\n# Setup dual logging - redirect all output to both temp file and syslog\nexec 1> >(tee -a \"$ROLLBACK_LOG_FILE\" | while read line; do logger -t \"aws-fis-rollback\" -p \"local0.info\" \"[\\$(date -u '+%Y-%m-%dT%H:%M:%SZ')] \\$line\" 2>/dev/null || true; done)\nexec 2>&1\n\n# Dont sleep if run in terminal\nif ! [ -t 0 ] ; then\n  sleep $ATTEMPT_ROLLBACK_AT_SECONDS\nfi\n\n# Include the function definition and its dependencies\n$(declare -f restore_hosts_file)\n$(declare -f \"$DISABLE_FAULT_COMMAND\")\n\nif ! [ -f \"$FLAG_PATH\" ] || [ \"\\$(( \\$(date +%s) - \\$(stat -c \"%Y\" \"$FLAG_PATH\") ))\" -gt $MAX_FLAG_AGE_SECONDS ] || [ -t 0 ]; then\n  echo \"Starting rollback: $DISABLE_FAULT_COMMAND\"\n\n  $DISABLE_FAULT_COMMAND\n  rm -f \"$FLAG_PATH\"\n\n  # Dont delete rollback script if run in terminal\n  if ! [ -t 0 ] ; then\n    rm -f \"$ROLLBACK_PATH\"\n  fi\nfi\nEOF\n\n  echo \"Temporary rollback file created: $ROLLBACK_PATH (logs: $ROLLBACK_LOG_FILE)\"\n}\n\n# Function to schedule rollback attempt\nschedule_rollback_attempt() {\n  local ROLLBACK_PATH=\"$1\"\n  echo \"bash $ROLLBACK_PATH\" | at now 2>&1 | grep -v \"warning: commands will be executed using /bin/sh\"\n}\n\n# Function to perform rollback\nrollback() {\n  local DISABLE_FAULT_COMMAND=\"$1\"\n  local FLAG_PATH=\"$2\"\n  local ROLLBACK_PATH=\"$3\"\n\n  eval \"$DISABLE_FAULT_COMMAND\" ; local STATUS=$?\n  rm -f \"$FLAG_PATH\"\n  rm -f \"$ROLLBACK_PATH\"\n  echo \"Rollback done.\"\n  exit $STATUS\n}\n\n# Function to run fault injection loop\nrun_fault_injection_loop() {\n  local STOP_TIME=\"$1\"\n  local FLAG_PATH=\"$2\"\n  local ROLLBACK_PATH=\"$3\"\n  local INJECTION_LOOP_SLEEP_SECONDS=\"$4\"\n  local DISABLE_FAULT_COMMAND=\"$5\"\n  local REFRESH_FUNCTION=\"${6:-}\"\n\n  # For the duration of the injection, the flag file is updated, and a rollback check is enqueued\n  while [[ $(date +%s) -lt $STOP_TIME ]] ; do\n    # If the background rollback process fires, it will delete the script\n    # from disk containing the rollback logic. That should not happen while\n    # this script is running, but if it does, we immediately fail the script\n    # to prevent the script from continuing to run as if the fault were active.\n    if ! [ -f \"$ROLLBACK_PATH\" ]; then\n      echo \"Fault rollback script was deleted from disk prematurely, exiting...\" 1>&2\n      # though the rollback likely already happened, we attempt rollback again since\n      # the rollback script might have been deleted by some unanticipated mechanism\n      eval \"$DISABLE_FAULT_COMMAND\"\n      exit 1\n    fi\n    \n    # Execute refresh function if provided\n    if [[ -n \"$REFRESH_FUNCTION\" ]] && declare -f \"$REFRESH_FUNCTION\" >/dev/null 2>&1; then\n      \"$REFRESH_FUNCTION\"\n    fi\n\n    touch \"$FLAG_PATH\"\n    schedule_rollback_attempt \"$ROLLBACK_PATH\"\n    sleep \"$INJECTION_LOOP_SLEEP_SECONDS\"\n  done\n}\n\n# Function to handle post fault-execution logic\n# Parameters:\n# - FAULT_NAME: Name of the fault\n# - DURATION: Duration of the fault in seconds\n# - ENABLE_FAULT_COMMAND: Command to enable the fault\n# - DISABLE_FAULT_COMMAND: Command to disable the fault\n# - REFRESH_FUNCTION: Optional function to call during fault injection loop, useful to, e.g. keep including IPs when DNS\n# updates records or randomize resources by changing targets every iteration\n# Returns 0 if successful, 1 if failed\nrun_post_fault_injection() {\n  local FAULT_NAME=\"$1\"\n  local DURATION=\"$2\"\n  local ENABLE_FAULT_COMMAND=\"$3\"\n  local DISABLE_FAULT_COMMAND=\"$4\"\n  local REFRESH_FUNCTION=\"${5:-}\"\n\n  # Constants\n  local -r MAX_FLAG_AGE_SECONDS=10\n  local -r INJECTION_LOOP_SLEEP_SECONDS=5\n  local -r ATTEMPT_ROLLBACK_AT_SECONDS=20\n  local -r STOP_TIME=$(( $(date +%s) + DURATION ))\n  local -r RANDOM_STRING=$(LC_ALL=C cat /dev/urandom | LC_ALL=C tr -dc 'a-zA-Z0-9' | head -c 32)\n  \n  # Define paths\n  local -r FLAG_PATH=$(get_flag_path \"$FAULT_NAME\" \"$RANDOM_STRING\")\n  local -r ROLLBACK_PATH=$(get_rollback_path \"$FAULT_NAME\" \"$RANDOM_STRING\")\n\n  # Create rollback script\n  create_rollback_script \"$FLAG_PATH\" \"$ROLLBACK_PATH\" \"$MAX_FLAG_AGE_SECONDS\" \"$ATTEMPT_ROLLBACK_AT_SECONDS\" \"$DISABLE_FAULT_COMMAND\"\n\n  # Binding the rollback function to these exit signals\n  trap 'rollback \"$DISABLE_FAULT_COMMAND\" \"$FLAG_PATH\" \"$ROLLBACK_PATH\"' INT TERM\n\n  echo \"Making sure atd daemon is running\"\n  # atd must be running in order to use \"at\" later\n  atd || { echo \"Failed to run atd daemon, exiting...\" 1>&2 ; exit 1; }\n\n  echo \"Scheduling rollback\"\n  schedule_rollback_attempt \"$ROLLBACK_PATH\"\n\n  # Injecting fault\n  echo \"Enabling fault injection\"\n  touch \"$FLAG_PATH\"\n  eval \"$ENABLE_FAULT_COMMAND\"\n\n  # Run fault injection loop\n  run_fault_injection_loop \"$STOP_TIME\" \"$FLAG_PATH\" \"$ROLLBACK_PATH\" \"$INJECTION_LOOP_SLEEP_SECONDS\" \"$DISABLE_FAULT_COMMAND\" \"$REFRESH_FUNCTION\"\n\n  # After the desired duration, the fault injection is removed\n  rollback \"$DISABLE_FAULT_COMMAND\" \"$FLAG_PATH\" \"$ROLLBACK_PATH\"\n}\nif [ \"$TRAFFIC_TYPE\" = \"egress\" ]; then\n  run_post_fault_injection \"$FAULT_NAME\" \"$DURATION\" enable_fault_egress disable_fault_egress\nelse\n  run_post_fault_injection \"$FAULT_NAME\" \"$DURATION\" enable_fault_ingress disable_fault_ingress\nfi"
        ]
      }
    }
  ]
}
