{
  "description": " The **AWSSupport-AnalyzeEMRLogs** automation runbook detects specific predefined errors while running a job on an Amazon EMR Cluster. It provides you 3 options: To run the automation once; schedule an automation to run at a specific time interval; or remove and existing schedule. The remove schedule option allows you to remove any previously configured scheduled automation. When a scheduled automation is removed, log analysis runbook will not be automatically triggered.\nWhen executed once, or on a schedule, the runbook performs the following steps:\n - The runbook retrieves Amazon EMR cluster details. \n - Lists running instances in the provided Amazon EMR cluster. \n - Verifies nodes are Systems Manager managed instances. \n - Creates Amazon CloudWatch log group, metric filters and dashboard if selected in the inputs to the runbook. \n - Installs required packages on nodes.  \n - Detects and reports identified errors found in logs and outputs the findings.\n\n Important: This runbook will create resources in your account. To review the possible charges you may incur once you exceed the free tier, please review the following:\n - https://aws.amazon.com/cloudwatch/pricing/\n -  https://aws.amazon.com/eventbridge/pricing/",
  "schemaVersion": "0.3",
  "assumeRole": "{{ AutomationAssumeRole }}",
  "outputs": [
    "getClusterDetails.ClusterName",
    "getClusterDetails.ClusterState",
    "listClusterInstances.InstanceIDs",
    "createScheduleCloudFormationStack.StackStatus",
    "deleteScheduleCloudFormationStack.StackStatus",
    "checkLogGroupExistance.output",
    "findLogPatternOnEMRNode.CommandId"
  ],
  "parameters": {
    "ClusterID": {
      "type": "String",
      "description": "(Required) Amazon EMR cluster ID.",
      "allowedPattern": "^j-[A-Z0-9]{1,13}$"
    },
    "AutomationAssumeRole": {
      "type": "AWS::IAM::Role::Arn",
      "description": "(Optional) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf. If no role is specified, Systems Manager Automation uses the permissions of the user that starts this runbook.",
      "default": ""
    },
    "Operation": {
      "type": "String",
      "description": "(Required) Operation to perform on the Amazon EMR cluster.",
      "allowedValues": [
        "Schedule",
        "Run Once",
        "Remove Schedule"
      ]
    },
    "IntervalTime": {
      "type": "String",
      "description": "(Optional) Interval time represents the duration after which the execution of this automation document will be triggered regularly. Only applicable if `Schedule` is selected for `Operation`. The default value is `5 minutes`.",
      "allowedValues": [
        "5 minutes",
        "10 minutes",
        "15 minutes",
        "None"
      ],
      "default": "5 minutes"
    },
    "LogToCloudWatchLogs": {
      "type": "String",
      "description": "(Optional) This option, if set to `Yes` , will create an Amazon CloudWatch log group with the name specified in parameter `CloudWatchLogGroup` to store any matched log lines. The default value is `no`.",
      "default": "No",
      "allowedValues": [
        "Yes",
        "No"
      ]
    },
    "CloudWatchLogGroup": {
      "type": "String",
      "description": "(Optional) Amazon CloudWatch log group name to store any matched log lines. Only applicable if `LogToCloudWatchLogs` parameter is set to Yes. The default value is `AWSSupport-AnalyzeEMRLogs`.",
      "default": "AWSSupport-AnalyzeEMRLogs",
      "allowedPattern": "^(?!aws\\/)[0-9A-Za-z\\-\\_\\/#.]{1,512}$"
    },
    "CreateLogInsightsDashboard": {
      "type": "String",
      "description": "(Optional) This option, if set to `Yes`, will create logs that are pushed to the log group specified in parameter `CloudWatchLogGroup` and an Amazon CloudWatch dashboard will be created if it does not exist. The default value is `No`.",
      "default": "No",
      "allowedValues": [
        "Yes",
        "No"
      ]
    },
    "CreateMetricFilters": {
      "description": "(Optional) This option, if set to `Yes`, will create metric filters. Only applicable if `LogToCloudWatchLogs` parameter is set to `Yes`. The default value is `No`.",
      "type": "String",
      "default": "No",
      "allowedValues": [
        "Yes",
        "No"
      ]
    },
    "AllowResourceCreation": {
      "description": "(Required) Select `Yes` to acknowledge that resources (Amazon CloudWatch Logs, and/or Amazon CloudWatch Event Schedule) will be created in your account.",
      "type": "String",
      "allowedValues": [
        "Yes",
        "No"
      ]
    }
  },
  "mainSteps": [
    {
      "name": "branchOnAllowResourceCreation",
      "action": "aws:branch",
      "description": "Branches on explicit consent for creation of resources for scheduling executions.",
      "isCritical": true,
      "isEnd": true,
      "onFailure": "Abort",
      "inputs": {
        "Choices": [
          {
            "NextStep": "getClusterDetails",
            "Variable": "{{AllowResourceCreation}}",
            "StringEquals": "Yes"
          }
        ]
      }
    },
    {
      "name": "getClusterDetails",
      "description": "Fetches the Amazon EMR cluster name and state.",
      "onFailure": "Abort",
      "action": "aws:executeAwsApi",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Service": "emr",
        "Api": "DescribeCluster",
        "ClusterId": "{{ ClusterID }}"
      },
      "outputs": [
        {
          "Name": "ClusterName",
          "Selector": "$.Cluster.Name",
          "Type": "String"
        },
        {
          "Name": "ClusterState",
          "Selector": "$.Cluster.Status.State",
          "Type": "String"
        }
      ],
      "nextStep": "branchOnRemoveSchedule"
    },
    {
      "name": "checkClusterExistance",
      "action": "aws:assertAwsResourceProperty",
      "description": "Checks if the cluster exists in the desired state.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Service": "emr",
        "Api": "DescribeCluster",
        "ClusterId": "{{ ClusterID }}",
        "PropertySelector": "$.Cluster.Status.State",
        "DesiredValues": [
          "RUNNING",
          "WAITING"
        ]
      },
      "nextStep": "listClusterInstances"
    },
    {
      "name": "listClusterInstances",
      "action": "aws:executeAwsApi",
      "description": "Fetches the instances IDs of all running nodes in the Amazon EMR cluster.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Service": "emr",
        "Api": "ListInstances",
        "InstanceStates": [
          "RUNNING"
        ],
        "ClusterId": "{{ ClusterID }}"
      },
      "outputs": [
        {
          "Name": "InstanceIDs",
          "Selector": "$.Instances..Ec2InstanceId",
          "Type": "StringList"
        }
      ],
      "nextStep": "checkInstancesManagedBySSM"
    },
    {
      "name": "branchOnRemoveSchedule",
      "action": "aws:branch",
      "description": "Branches on decision to remove existing schedule based on the selected operation.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Choices": [
          {
            "NextStep": "checkStackExistance",
            "Variable": "{{Operation}}",
            "StringEquals": "Remove Schedule"
          }
        ],
        "Default": "checkClusterExistance"
      },
      "nextStep": "checkStackExistance"
    },
    {
      "name": "checkInstancesManagedBySSM",
      "action": "aws:assertAwsResourceProperty",
      "description": "Checks if Systems Manager Agent is running on nodes.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Service": "ssm",
        "Api": "DescribeInstanceInformation",
        "PropertySelector": "$.InstanceInformationList[0].PingStatus",
        "DesiredValues": [
          "Online"
        ],
        "InstanceInformationFilterList": [
          {
            "key": "InstanceIds",
            "valueSet": [
              "{{ listClusterInstances.InstanceIDs }}"
            ]
          }
        ]
      },
      "nextStep": "branchOnOperation"
    },
    {
      "name": "branchOnOperation",
      "action": "aws:branch",
      "description": "Branches on decision to execute automation document either once or on schedule.",
      "isCritical": true,
      "isEnd": true,
      "onFailure": "Abort",
      "inputs": {
        "Choices": [
          {
            "NextStep": "branchOnLogToCloudWatchLogsChoice",
            "Variable": "{{Operation}}",
            "StringEquals": "Run Once"
          },
          {
            "NextStep": "createScheduleCloudFormationStack",
            "Variable": "{{Operation}}",
            "StringEquals": "Schedule"
          }
        ]
      }
    },
    {
      "name": "branchOnLogToCloudWatchLogsChoice",
      "action": "aws:branch",
      "description": "Branches on the option to create a Amazon CloudWatch dashboard, based on the input provided in `CreateLogInsightsDashboard` parameter.",
      "isCritical": true,
      "isEnd": true,
      "onFailure": "Abort",
      "inputs": {
        "Choices": [
          {
            "NextStep": "checkLogGroupExistance",
            "Variable": "{{LogToCloudWatchLogs}}",
            "StringEquals": "Yes"
          },
          {
            "NextStep": "installRequiredPackages",
            "Variable": "{{LogToCloudWatchLogs}}",
            "StringEquals": "No"
          }
        ]
      }
    },
    {
      "name": "checkStackExistance",
      "action": "aws:executeAwsApi",
      "description": "Checks if there is an existing stack created for the the cluster ID provided by previous executions for the runbook.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "Api": "DescribeStacks",
        "Service": "cloudformation",
        "StackName": "AWSSupport-AnalyzeEMRLogs-{{ClusterID}}"
      },
      "outputs": [
        {
          "Name": "StackId",
          "Selector": "$.Stacks[0].StackId",
          "Type": "String"
        },
        {
          "Name": "StackName",
          "Selector": "$.Stacks[0].StackName",
          "Type": "String"
        }
      ],
      "nextStep": "deleteScheduleCloudFormationStack"
    },
    {
      "name": "deleteScheduleCloudFormationStack",
      "action": "aws:deleteStack",
      "description": "Stops scheduling by deleting CloudFormation stack resources, event rule, and IAM role that triggers the event.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "isEnd": true,
      "inputs": {
        "StackName": "AWSSupport-AnalyzeEMRLogs-{{ClusterID}}"
      },
      "outputs": [
        {
          "Name": "StackStatus",
          "Selector": "$",
          "Type": "String"
        }
      ]
    },
    {
      "name": "createScheduleCloudFormationStack",
      "action": "aws:createStack",
      "description": "Creates an AWS CloudFormation stack to create an EventBridge event with target this automation document and a role to trigger that event.",
      "maxAttempts": 1,
      "isCritical": true,
      "isEnd": true,
      "onFailure": "step:deleteScheduleCloudFormationStack",
      "inputs": {
        "StackName": "AWSSupport-AnalyzeEMRLogs-{{ClusterID}}",
        "ClientRequestToken": "AWSSupport-AnalyzeEMRLogs-{{ automation:EXECUTION_ID }}",
        "OnFailure": "DELETE",
        "Capabilities": [
          "CAPABILITY_IAM"
        ],
        "TimeoutInMinutes": 30,
        "Parameters": [
          {
            "ParameterKey": "ClusterId",
            "ParameterValue": "{{ClusterID}}"
          },
          {
            "ParameterKey": "AutomationAssumeRole",
            "ParameterValue": "{{AutomationAssumeRole}}"
          },
          {
            "ParameterKey": "LogToCloudWatchLogs",
            "ParameterValue": "{{LogToCloudWatchLogs}}"
          },
          {
            "ParameterKey": "IntervalTime",
            "ParameterValue": "{{IntervalTime}}"
          },
          {
            "ParameterKey": "CreateLogInsightsDashboard",
            "ParameterValue": "{{CreateLogInsightsDashboard}}"
          },
          {
            "ParameterKey": "CreateMetricFilters",
            "ParameterValue": "{{CreateMetricFilters}}"
          },
          {
            "ParameterKey": "CloudWatchLogGroup",
            "ParameterValue": "{{CloudWatchLogGroup}}"
          }
        ],
        "TemplateBody": "AWSTemplateFormatVersion: 2010-09-09\nParameters:\n  IntervalTime:\n    Type: String\n    Default: ''\n  ClusterId:\n    Type: String\n    Default: ''\n  AutomationAssumeRole:\n    Type: String\n    Default: ''\n  LogToCloudWatchLogs:\n    Type: String\n    Default: ''\n  CreateLogInsightsDashboard:\n    Type: String\n    Default: ''\n  CreateMetricFilters:\n    Type: String\n    Default: ''\n  CloudWatchLogGroup:\n    Type: String\n    Default: ''\nResources:\n  EMRSchedulingRuleCreatedbySSM: \n    Type: AWS::Events::Rule\n    Properties: \n      Description: \"Scheduling rule for AWSSupport-AnalyzeEMRLogs\"\n      ScheduleExpression: !Sub 'rate(${IntervalTime})'\n      Targets: \n        - Arn: !Sub 'arn:${AWS::Partition}:ssm:${AWS::Region}::automation-definition/AWSSupport-AnalyzeEMRLogs:$DEFAULT'\n          Id: !Sub \"AWSSupport-AnalyzeEMRLogs-${ClusterId}-Rule\"\n          RoleArn: !Sub 'arn:${AWS::Partition}:iam::${AWS::AccountId}:role/${RoletoTriggerAWSSupportAnalyzeEMRLogs}'\n          Input: !Sub \"{\\\"ClusterID\\\":[\\\"${ClusterId}\\\"],\\\"AutomationAssumeRole\\\":[\\\"${AutomationAssumeRole}\\\"],\\\"Operation\\\":[\\\"Run Once\\\"],\\\"IntervalTime\\\":[\\\"${IntervalTime}\\\"],\\\"LogToCloudWatchLogs\\\":[\\\"${LogToCloudWatchLogs}\\\"],\\\"CreateLogInsightsDashboard\\\":[\\\"${CreateLogInsightsDashboard}\\\"],\\\"CreateMetricFilters\\\":[\\\"${CreateMetricFilters}\\\"],\\\"CloudWatchLogGroup\\\":[\\\"${CloudWatchLogGroup}\\\"]}\"\n  RoletoTriggerAWSSupportAnalyzeEMRLogs:\n   Type: AWS::IAM::Role\n   Properties:\n     AssumeRolePolicyDocument:\n       Version: 2012-10-17\n       Statement:\n         - Effect: Allow\n           Principal:\n             Service:\n               - events.amazonaws.com\n           Action:\n             - sts:AssumeRole\n     Path: /\n     Policies:\n       - PolicyName: \"StartAutomationAndPassRole\"\n         PolicyDocument:\n           Version: '2012-10-17'\n           Statement:\n             - Effect: Allow\n               Action: ssm:StartAutomationExecution\n               Resource:\n                 - !Sub 'arn:${AWS::Partition}:ssm:${AWS::Region}::automation-definition/AWSSupport-AnalyzeEMRLogs:$DEFAULT'\n             - Effect: Allow\n               Action: \n                 - iam:PassRole\n               Resource: !Sub '${AutomationAssumeRole}'\n               Condition:\n                 StringLikeIfExists: \n                   iam:PassedToService: 'ssm.amazonaws.com'\n",
        "Tags": [
          {
            "Key": "Name",
            "Value": "AWSSupport-AnalyzeEMRLogs-{{ automation:EXECUTION_ID }}"
          },
          {
            "Key": "AWSSupport-AnalyzeEMRLogs-AutomationExecution",
            "Value": "{{ automation:EXECUTION_ID }}"
          }
        ]
      }
    },
    {
      "name": "checkLogGroupExistance",
      "action": "aws:executeScript",
      "description": "Checks if an Amazon CloudWatch log group with the name specified in parameter `CloudWatchLogGroup` exists.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "InputPayload": {
          "CloudWatchLogGroup": "{{CloudWatchLogGroup}}"
        },
        "Handler": "create_log_group.script_handler",
        "Runtime": "python3.11",
        "Attachment": "attachments.zip"
      },
      "outputs": [
        {
          "Name": "output",
          "Selector": "$.Payload.output",
          "Type": "String"
        }
      ],
      "nextStep": "branchOnMetricFilterChoice"
    },
    {
      "name": "branchOnMetricFilterChoice",
      "action": "aws:branch",
      "description": "Branches on the option to create Amazon CloudWatch log insight or not based on the input selected in `CreateMetricFilters`.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "isEnd": true,
      "inputs": {
        "Choices": [
          {
            "NextStep": "putMetricFilters",
            "Variable": "{{CreateMetricFilters}}",
            "StringEquals": "Yes"
          },
          {
            "NextStep": "branchOnCreateCloudWatchLogInsightsOrFindLogPattern",
            "Variable": "{{CreateMetricFilters}}",
            "StringEquals": "No"
          }
        ]
      }
    },
    {
      "name": "putMetricFilters",
      "action": "aws:executeScript",
      "description": "Creates metric filters in the specified log group.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "InputPayload": {
          "CloudWatchLogGroup": "{{CloudWatchLogGroup}}"
        },
        "Handler": "put_metric_filters.script_handler",
        "Runtime": "python3.11",
        "Attachment": "attachments.zip"
      },
      "nextStep": "branchOnCreateCloudWatchLogInsightsOrFindLogPattern"
    },
    {
      "name": "branchOnCreateCloudWatchLogInsightsOrFindLogPattern",
      "action": "aws:branch",
      "description": "Branches on the option to create an Amazon CloudWatch dashboard, or find log pattern on Amazon EMR node based on the input provided in `CreateLogInsightsDashboard` parameter.",
      "isCritical": true,
      "isEnd": true,
      "onFailure": "Abort",
      "inputs": {
        "Choices": [
          {
            "NextStep": "putDashboard",
            "Variable": "{{CreateLogInsightsDashboard}}",
            "StringEquals": "Yes"
          },
          {
            "NextStep": "installRequiredPackages",
            "Variable": "{{CreateLogInsightsDashboard}}",
            "StringEquals": "No"
          }
        ]
      }
    },
    {
      "name": "putDashboard",
      "action": "aws:executeAwsApi",
      "description": "Creates Amazon CloudWatch dashboard with the name provided in parameter `CloudWatchLogGroup`.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "nextStep": "installRequiredPackages",
      "inputs": {
        "Api": "PutDashboard",
        "Service": "cloudwatch",
        "DashboardName": "{{CloudWatchLogGroup}}",
        "DashboardBody": "{ \"widgets\": [ { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"us-east-1\", \"title\": \"us-east-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"us-east-2\", \"title\": \"us-east-2 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"us-west-1\", \"title\": \"us-west-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"us-west-2\", \"title\": \"us-west-2 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"af-south-1\", \"title\": \"af-south-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-east-1\", \"title\": \"ap-east-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-south-1\", \"title\": \"ap-south-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-northeast-3\", \"title\": \"ap-northeast-3 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-northeast-2\", \"title\": \"ap-northeast-2 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-northeast-1\", \"title\": \"ap-northeast-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-southeast-1\", \"title\": \"ap-southeast-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"ap-southeast-2\", \"title\": \"ap-southeast-2 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-west-1\", \"title\": \"eu-west-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-west-2\", \"title\": \"eu-west-2 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-south-1\", \"title\": \"eu-south-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-west-3\", \"title\": \"eu-west-3 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-north-1\", \"title\": \"eu-north-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"me-south-1\", \"title\": \"me-south-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"sa-east-1\", \"title\": \"sa-east-1 EMRMonolog Events\", \"view\": \"table\" } }, { \"height\": 5, \"width\": 24, \"y\": 0, \"x\": 0, \"type\": \"log\", \"properties\": { \"query\": \"SOURCE \\\"{{CloudWatchLogGroup}}\\\" | parse @message \\\"* *\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\\t*\\\" as EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link, log_message | DISPLAY  EventDate, event_time, cluster_id, instance_id, issue_name, issue_description, issue_link\", \"region\": \"eu-central-1\", \"title\": \"eu-central-1 EMRMonolog Events\", \"view\": \"table\" } } ] }"
      }
    },
    {
      "name": "installRequiredPackages",
      "action": "aws:runCommand",
      "description": "Installs the required packages, as a prerequisite to find log pattern on each Amazon EMR node.",
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "DocumentName": "AWS-RunShellScript",
        "Parameters": {
          "commands": [
            "sudo yum clean all",
            "sudo yum install python3 -y",
            "sudo yum install python3-boto3 -y"
          ]
        },
        "InstanceIds": "{{ listClusterInstances.InstanceIDs }}"
      },
      "nextStep": "findLogPatternOnEMRNode"
    },
    {
      "name": "findLogPatternOnEMRNode",
      "action": "aws:runCommand",
      "description": "Finds log pattern on each Amazon EMR node.",
      "isCritical": true,
      "onFailure": "Abort",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "isEnd": true,
      "inputs": {
        "DocumentName": "AWS-RunShellScript",
        "Parameters": {
          "commands": [
            "#!/usr/bin/env python3",
            "",
            "import ast",
            "import hashlib",
            "import importlib",
            "import io",
            "import json",
            "import logging",
            "import math",
            "import multiprocessing",
            "import os",
            "import re",
            "import sqlite3",
            "import subprocess",
            "import time",
            "from datetime import datetime",
            "",
            "import boto3",
            "from botocore.exceptions import ClientError",
            "",
            "logger = logging.getLogger()",
            "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s: %(levelname)s: %(message)s\")",
            "",
            "log_to_cwl = \"{{LogToCloudWatchLogs}}\"",
            "log_group = \"{{CloudWatchLogGroup}}\"",
            "",
            "",
            "def client_error_message(e: ClientError) -> None:",
            "    \"\"\"",
            "    Handle client error messages.",
            "",
            "    Args:",
            "        e (ClientError): The caught ClientError.",
            "",
            "    Raises:",
            "        RuntimeError: If any unexpected error occurs.",
            "    \"\"\"",
            "    try:",
            "        error_code = str(e.response[\"Error\"][\"Code\"])",
            "        error_message = e.response[\"Error\"][\"Message\"]",
            "        raise RuntimeError(f\"Error message is {error_message} With error code {error_code}\")",
            "    except RuntimeError as e:",
            "        raise RuntimeError(f\"Unexpected error: {str(e)}\")",
            "",
            "",
            "def run_cmd(cmd: str) -> list:",
            "    \"\"\"",
            "    Execute a command in the shell and return the output as a list of lines.",
            "",
            "    Args:",
            "        cmd (str): The command to execute.",
            "",
            "    Returns:",
            "        list: Output of the command as a list of lines.",
            "",
            "    Raises:",
            "        RuntimeError: If an error occurs while executing the command.",
            "    \"\"\"",
            "    try:",
            "        cmd_output = subprocess.Popen(",
            "            [cmd], shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE",
            "        ).stdout.readlines()",
            "    except Exception as e:",
            "        raise RuntimeError(f\"Error executing command: {cmd}. Error: {str(e)}\")",
            "    return cmd_output",
            "",
            "",
            "def get_token() -> str:",
            "    \"\"\"Gets a token from the EC2 instance metadata service.",
            "",
            "    Requests a token from the EC2 instance metadata service that can be used to request other instance metadata.",
            "    The token is valid for 6 hours (21600 seconds).",
            "",
            "    Args:",
            "        None",
            "",
            "    Returns:",
            "        str: The token string",
            "",
            "    Raises:",
            "        Exception: Any exceptions raised while running the curl command or decoding the output.",
            "    \"\"\"",
            "    token_cmd = 'curl -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\"'",
            "    try:",
            "        token_output = run_cmd(token_cmd)[0]",
            "        token = token_output.decode(\"utf-8\").strip()",
            "    except Exception as e:",
            "        logger.error(f\"Error getting token. Error: {str(e)}\")",
            "    return token",
            "",
            "",
            "def get_instance_region() -> str:",
            "    \"\"\"",
            "    Get the AWS region of the EC2 instance.",
            "",
            "    Returns:",
            "        str: The AWS region of the instance.",
            "",
            "    Raises:",
            "        RuntimeError: If an error occurs while retrieving the instance region.",
            "    \"\"\"",
            "",
            "    try:",
            "        token = get_token()",
            "        cmd = f\"curl -H 'X-aws-ec2-metadata-token: {token}' -v http://169.254.169.254/latest/dynamic/instance-identity/document  | jq .region -r\"",
            "        cmd_output = run_cmd(cmd)[0]",
            "        region = str(cmd_output.decode(\"utf-8\").strip())",
            "    except Exception as e:",
            "        raise RuntimeError(f\"Error getting instance region. Error: {str(e)}\")",
            "    return region",
            "",
            "",
            "def post_logs_cwl(log_group: str, log_stream: str, event_time: int, event: str) -> None:",
            "    \"\"\"",
            "    Describe and create CloudWatch log group, log stream and put log events into it.",
            "",
            "    Args:",
            "        log_group (str): Name of the log group.",
            "        log_stream (str): Name of the log stream.",
            "        event_time (int): Timestamp of the event.",
            "        event (str): Log event message.",
            "",
            "    Raises:",
            "        RuntimeError: If an error occurs while describing or creating CloudWatchlog group, log stream or while putting log events into it.",
            "    \"\"\"",
            "    try:",
            "        region = get_instance_region()",
            "        cw_logs_client = boto3.client(\"logs\", region_name=region)",
            "        current_time_stamp = int(round(time.time() * 1000))",
            "        log_group_finder = cw_logs_client.describe_log_groups(logGroupNamePrefix=log_group, limit=10)",
            "        if len(log_group_finder[\"logGroups\"]) == 0:",
            "            cw_logs_client.create_log_group(logGroupName=log_group)",
            "        log_stream_finder = cw_logs_client.describe_log_streams(",
            "            logGroupName=log_group,",
            "            logStreamNamePrefix=log_stream,",
            "            orderBy=\"LogStreamName\",",
            "            descending=True,",
            "        )",
            "        if len(log_stream_finder[\"logStreams\"]) == 0:",
            "            cw_logs_client.create_log_stream(logGroupName=log_group, logStreamName=log_stream)",
            "            cw_logs_client.put_log_events(",
            "                logGroupName=log_group,",
            "                logStreamName=log_stream,",
            "                logEvents=[{\"timestamp\": current_time_stamp, \"message\": event}],",
            "            )",
            "        if len(log_stream_finder[\"logStreams\"]) == 1:",
            "            token = log_stream_finder[\"logStreams\"][0][\"uploadSequenceToken\"]",
            "            cw_logs_client.put_log_events(",
            "                logGroupName=log_group,",
            "                logStreamName=log_stream,",
            "                logEvents=[{\"timestamp\": current_time_stamp, \"message\": event}],",
            "                sequenceToken=token,",
            "            )",
            "    except Exception as e:",
            "        raise RuntimeError(f\"Error posting logs to CloudWatch Logs. Error: {str(e)}\")",
            "",
            "",
            "def run_grep(filename_pattern: str, regex_type: str, search_string: str, grep_arg: str, post_cmd: str) -> list:",
            "    \"\"\"",
            "    Run grep command on files matching the pattern.",
            "",
            "    Args:",
            "        filename_pattern (str): Pattern to match files.",
            "        regex_type (str): Type of regex.",
            "        search_string (str): String to search for.",
            "        grep_arg (str): Additional arguments for grep command.",
            "        post_cmd (str): Command to execute after grep.",
            "",
            "    Returns:",
            "        list: Output of the grep command.",
            "",
            "    Raises:",
            "        RuntimeError: If an error occurs while running the grep command.",
            "    \"\"\"",
            "    try:",
            "        if regex_type == \"\":",
            "            dir_name = filename_pattern[0 : filename_pattern.rfind(\"/\") + 1]",
            "            file_name = '\"' + filename_pattern[filename_pattern.rfind(\"/\") + 1 :] + '\"'",
            "            cmd_str = \"\".join([\"find \", dir_name, \" -name \", file_name, \" -print0\"])",
            "        else:",
            "            cmd_str = \"\".join([\"find\", filename_pattern + \" -regextype posix-extended -regex \", regex_type, \" -print0\"])",
            "        if grep_arg == \"\":",
            "            cmd_str = \"\".join([cmd_str, \" | xargs -0 -n1 -P2 zgrep \", search_string, \" \", post_cmd])",
            "        else:",
            "            cmd_str = \"\".join([cmd_str, \" | xargs -0 -n1 -P2 zgrep \", grep_arg, \" \", search_string, \" \", post_cmd])",
            "        cmd_output = run_cmd(cmd_str)",
            "        return cmd_output",
            "    except Exception as e:",
            "        raise RuntimeError(f\"Error running grep command. Error: {str(e)}\")",
            "",
            "",
            "def output_events(id_to_fetch):",
            "    c.execute(",
            "        \"SELECT metricdata FROM events WHERE id = ?\",",
            "        (id_to_fetch,),",
            "    )",
            "    event_data = \"\"",
            "    results = c.fetchall()",
            "    if len(results) > 0:",
            "        for line in results:",
            "            event_data = event_data + line[0] + \"\\n\"",
            "            print(event_data)",
            "",
            "",
            "def create_postcommand(check_name: str, log_file: str, log_sig: str) -> list:",
            "    \"\"\"",
            "    Create post command based on the check name.",
            "",
            "    Args:",
            "        check_name (str): Name of the check.",
            "        log_file (str): Path to the log file.",
            "        log_sig (str): Log signature.",
            "",
            "    Returns:",
            "        list: Result of the post command.",
            "",
            "    Raises:",
            "        RuntimeError: If an error occurs during execution.",
            "    \"\"\"",
            "    try:",
            "        if check_name == \"node_state_change\":",
            "            post_cmd = '| tr \"\\\\n\" \" \" | sed \"s/slaveRecords/\\\\nslaveRecords/g\" | grep \"slaveRecords\" | grep -v \"state: RUNNING\"'",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"-A7\", post_cmd)",
            "        elif check_name == \"step_failure\":",
            "            post_cmd = (",
            "                '| tr \"\\\\n\" \" \" | sed \"s/stepRecord/\\\\nstepRecord/g\" | grep \"state: FAILED\" | grep -v \"state: RUNNING\"'",
            "            )",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"-A9\", post_cmd)",
            "        elif check_name == \"no_core_nodes_running\":",
            "            post_cmd = '| tr \"\\\\n\" \" \" | sed \"s/--/\\\\n/g\" | grep \"Present Capacity: 0\" | tail -n1'",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"-A8\", post_cmd)",
            "        elif check_name == \"hdfs_missing_blocks\":",
            "            post_cmd = '| grep -v \"Failed to update HDFS app monitor \" | grep -v \"Return code of \" | tr \"\\\\n\" \" \" | sed \"s/--/\\\\n/g\" | grep -v \"Missing blocks: 0\" | tail -n1'",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"-A8\", post_cmd)",
            "        elif check_name == \"hdfs_high_util\":",
            "            post_cmd = '| tr \"\\\\n\" \" \" | sed \"s/--/\\\\n/g\" | grep -e \"DFS Used%: 9[0-9]\\.\" | tail -n1'",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"-A8\", post_cmd)",
            "        elif check_name == \"instance_controller_restart\":",
            "            post_cmd = \"| tail -n1\"",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"\", post_cmd)",
            "        elif check_name == \"instance_controller_restart_legacy\":",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"\", \"\")",
            "            if len(cur_result) > 1:",
            "                cur_result = [cur_result[len(cur_result) - 1]]",
            "        elif check_name == \"high_load\":",
            "            cmd = \"cat \" + log_file + ' | cut -d\" \" -f1'",
            "            load_avg = run_cmd(cmd)[0]",
            "            if load_avg:",
            "                load_avg = float(load_avg)",
            "                num_vcores = multiprocessing.cpu_count()",
            "                cpu_util = math.ceil(load_avg / float(num_vcores) * 100)",
            "                if float(cpu_util) > 95.0:",
            "                    cur_result = [",
            "                        (",
            "                            datetime.now().isoformat(\" \")",
            "                            + \" 5-Minute Load Average: \"",
            "                            + str(load_avg)",
            "                            + \", Num vCores: \"",
            "                            + str(num_vcores)",
            "                            + \", Effective CPU Utilization: \"",
            "                            + str(cpu_util)",
            "                            + \"%\"",
            "                        )",
            "                    ]",
            "                else:",
            "                    cur_result = []",
            "            else:",
            "                cur_result = []",
            "        else:",
            "            cur_result = run_grep(log_file, \"\", log_sig, \"\", \"\")",
            "        return cur_result",
            "    except Exception as e:",
            "        raise RuntimeError(f\"Error creating post command: {str(e)}\")",
            "",
            "",
            "def read_file(file_name: str) -> dict:",
            "    \"\"\"",
            "    Read a file and parse its contents as JSON.",
            "",
            "    Args:",
            "        file_name (str): Name of the file to read.",
            "",
            "    Returns:",
            "        dict: Parsed contents of the file as a dictionary.",
            "",
            "    Raises:",
            "        Exception: If the file is not found or an error occurs during parsing.",
            "    \"\"\"",
            "    try:",
            "        with io.open(file_name, \"r\", encoding=\"utf-8\") as file_obj:",
            "            file_data = ast.literal_eval(file_obj.read())",
            "    except FileNotFoundError as e:",
            "        raise Exception(f\"File {file_name} not found: {str(e)}\")",
            "    except Exception as e:",
            "        raise Exception(f\"Error reading file {file_name}: {str(e)}\")",
            "    return file_data",
            "",
            "",
            "def get_node_info() -> tuple:",
            "    \"\"\"",
            "    Get node information including instance ID and job flow ID.",
            "",
            "    Returns:",
            "        tuple: A tuple containing instance ID and job flow ID.",
            "",
            "    Raises:",
            "        Exception: If an error occurs during execution.",
            "    \"\"\"",
            "    try:",
            "        instance_id = \"\"",
            "        jobflow_id = \"\"",
            "        file_path = \"/emr/instance-controller/lib/info/job-flow.json\"",
            "        token = get_token()",
            "        cmd = f\"curl -H 'X-aws-ec2-metadata-token: {token}' -v http://169.254.169.254/latest/meta-data/instance-id\"",
            "        if os.environ.get(\"AWS_SSM_INSTANCE_ID\").startswith(\"i-\"):",
            "            cmd_output = run_cmd(cmd)[0]",
            "            instance_id = str(cmd_output.decode(\"utf-8\").strip())",
            "        else:",
            "            raise Exception(f\"Unexpected error: command {cmd} isn't made against an EC2 instance.\")",
            "        jobflow_json = read_file(file_path)",
            "        jobflow_id = jobflow_json[\"jobFlowId\"]",
            "        return instance_id, jobflow_id",
            "    except indexError as e:",
            "        raise Exception(f\"Error getting Job Flow ID: {str(e)}\")",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    run_start_time = datetime.now()",
            "    cwd = os.path.dirname(os.path.abspath(__file__))",
            "    pwd = \"/mnt\" + cwd",
            "    bisect = \"orchestration\"",
            "    db_path = pwd.partition(bisect)[0]",
            "    log_defs = {",
            "        \"log_items\": [",
            "            {",
            "                \"name\": \"container_out_of_memory\",",
            "                \"location\": \"/var/log/hadoop-yarn/*-yarn-nodemanager-*.log\",",
            "                \"signature\": '-e \"is running beyond physical memory limits\" -e \"Exit code from container .* is : 137$\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"YARN container ran out of memory, running job may fail\",",
            "                \"kb_link\": \"https://aws.amazon.com/premiumsupport/knowledge-center/emr-spark-yarn-memory-limit/\",",
            "            },",
            "            {",
            "                \"name\": \"yarn_nodemanager_health\",",
            "                \"location\": \"/var/log/hadoop-yarn/*-yarn-nodemanager-*.log\",",
            "                \"signature\": '\"Most of the disks failed\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"CORE or TASK node is running low on disk space and will not be able to run tasks\",",
            "                \"kb_link\": \"https://aws.amazon.com/premiumsupport/knowledge-center/core-node-emr-cluster-disk-space/\",",
            "            },",
            "            {",
            "                \"name\": \"node_state_change\",",
            "                \"location\": \"/emr/instance-controller/lib/info/job-flow-state.txt\",",
            "                \"signature\": '\"slaveRecords\"',",
            "                \"timestamp_format\": \"lastStateChangeTime: (\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d)\",",
            "                \"description\": \"CORE or TASK node is unreachable by the MASTER node\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-error-resource.html\",",
            "            },",
            "            {",
            "                \"name\": \"step_failure\",",
            "                \"location\": \"/emr/instance-controller/lib/info/job-flow-state.txt\",",
            "                \"signature\": '\"stepRecord\"',",
            "                \"timestamp_format\": \"endInstant: (\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d)\",",
            "                \"description\": \"An EMR Step has failed\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-failed-4.html\",",
            "            },",
            "            {",
            "                \"name\": \"no_core_nodes_running\",",
            "                \"location\": \"/emr/instance-controller/log/instance-controller.log\",",
            "                \"signature\": '\"hdfs dfsadmin -report\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"No CORE nodes are currently running, cluster is unhealthy\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-cluster-NO_SLAVE_LEFT-FAILED_BY_MASTER.html\",",
            "            },",
            "            {",
            "                \"name\": \"hdfs_missing_blocks\",",
            "                \"location\": \"/emr/instance-controller/log/instance-controller.log\",",
            "                \"signature\": '\"hdfs dfsadmin -report\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"There are missing HDFS blocks which could lead to dataloss\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/enough-hdfs-space.html\",",
            "            },",
            "            {",
            "                \"name\": \"hdfs_high_util\",",
            "                \"location\": \"/emr/instance-controller/log/instance-controller.log\",",
            "                \"signature\": '\"hdfs dfsadmin -report\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"HDFS Utilization is high, which may affect jobs and cluster health\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-error-resource-2.html\",",
            "            },",
            "            {",
            "                \"name\": \"instance_controller_restart\",",
            "                \"location\": \"/emr/instance-controller/log/monitor.log\",",
            "                \"signature\": '\"MonitorReactionExecutor failed\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"Instance-Controller process has restarted. This process is essential for cluster health\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-process-restart-stop-view.html\",",
            "            },",
            "            {",
            "                \"name\": \"instance_controller_restart_legacy\",",
            "                \"location\": \"/emr/service-nanny/log/service-nanny-*\",",
            "                \"signature\": '\"starting instance-controller\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\s\",",
            "                \"description\": \"Instance-Controller process has restarted. This process is essential for cluster health\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-process-restart-stop-view.html\",",
            "            },",
            "            {",
            "                \"name\": \"high_load\",",
            "                \"location\": \"/proc/loadavg\",",
            "                \"signature\": '\"\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\",",
            "                \"description\": \"High Load Average detected, may affect node health reporting or result in timeouts or slowdowns\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-slow-4.html\",",
            "            },",
            "            {",
            "                \"name\": \"yarn_node_blacklisted\",",
            "                \"location\": \"/var/log/hadoop-yarn/*-yarn-resourcemanager-*.log\",",
            "                \"signature\": '\"blacklist are updated in Scheduler.blacklistAdditions\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"CORE or TASK node has been blacklisted by YARN from running tasks\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-process-restart-stop-view.html\",",
            "            },",
            "            {",
            "                \"name\": \"yarn_node_lost\",",
            "                \"location\": \"/var/log/hadoop-yarn/*-yarn-resourcemanager-*.log\",",
            "                \"signature\": '\"Node Transitioned from RUNNING to LOST\"',",
            "                \"timestamp_format\": \"(\\\\d\\\\d\\\\d\\\\d\\\\-\\\\d\\\\d\\\\-\\\\d\\\\d\\\\s\\\\d\\\\d\\\\:\\\\d\\\\d\\\\:\\\\d\\\\d)\\\\,\\\\d\\\\d\\\\d\",",
            "                \"description\": \"CORE or TASK node has been marked as LOST by YARN, possible connectivity issues\",",
            "                \"kb_link\": \"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-process-restart-stop-view.html\",",
            "            },",
            "        ]",
            "    }",
            "    conn = sqlite3.connect(db_path + \"metric_records.db\")",
            "    c = conn.cursor()",
            "    c.execute(\"CREATE TABLE IF NOT EXISTS events (id text PRIMARY KEY, metricdata text)\")",
            "    instance_id, jobflow_id = get_node_info()",
            "    result_lines = []",
            "    counter = 0",
            "    for log_item in log_defs[\"log_items\"]:",
            "        check_name = log_item[\"name\"]",
            "        log_file = log_item[\"location\"]",
            "        log_sig = log_item[\"signature\"]",
            "        description = log_item[\"description\"]",
            "        kb_link = log_item[\"kb_link\"]",
            "        timestamp_format = log_item[\"timestamp_format\"]",
            "        timestamp_regx = re.compile(timestamp_format)",
            "        cmd_result = create_postcommand(check_name, log_file, log_sig)",
            "        if len(cmd_result) > 0:",
            "            for line in cmd_result:",
            "                result_line = \"\"",
            "                if isinstance(line, bytes):",
            "                    line = str(line.decode(\"utf-8\").strip())",
            "                timestamp_match = timestamp_regx.search(line)",
            "                if timestamp_match:",
            "                    if (check_name == \"node_state_change\") or (check_name == \"step_failure\"):",
            "                        epoch_seconds = int(timestamp_match.group(1)) / 1000",
            "                        parsed_timestamp = datetime.fromtimestamp(epoch_seconds).strftime(\"%Y-%m-%d %H:%M:%S\")",
            "                    else:",
            "                        parsed_timestamp = timestamp_match.group(1)",
            "                    result_line = (",
            "                        parsed_timestamp",
            "                        + \"\\t\"",
            "                        + jobflow_id",
            "                        + \"\\t\"",
            "                        + instance_id",
            "                        + \"\\t\"",
            "                        + check_name",
            "                        + \"\\t[\"",
            "                        + description",
            "                        + \"]\\t\"",
            "                        + kb_link",
            "                        + \"\\t\"",
            "                        + line",
            "                    )",
            "                    result_lines.append(result_line)",
            "                    logline_id = hashlib.md5(str(result_line).encode()).hexdigest()",
            "                uni = str(logline_id)",
            "                already_exists = c.execute(",
            "                    \"SELECT id FROM events WHERE id = ?\",",
            "                    (uni,),",
            "                ).fetchall()",
            "                if len(already_exists) == 0:",
            "                    counter += 1",
            "                    c.execute(\"INSERT OR IGNORE INTO events values (?, ?)\", (uni, str(result_line)))",
            "                    output_events(uni)",
            "                    if \"{{LogToCloudWatchLogs}}\" == \"Yes\":",
            "                        post_logs_cwl(log_group, instance_id, parsed_timestamp, result_line)",
            "    conn.commit()",
            "    c.close()",
            "    conn.close()"
          ]
        },
        "InstanceIds": "{{ listClusterInstances.InstanceIDs }}"
      }
    }
  ],
  "files": {
    "attachments.zip": {
      "checksums": {
        "SHA256": "0e11412e5eddf857e77754453b63b4398f7c7363144b9e539e87a3dea3926b24"
      }
    }
  }
}
