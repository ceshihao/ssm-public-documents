{
  "description": "The **AWSSupport-AnalyzeSESMessageSendingStatus** automation runbook summarizes the email delivery status of undelivered email messages and gives you advice to solve why the emails were undelivered. The runbook retrieves Amazon Simple Email Service (SES) email sending events stored in an Amazon CloudWatch log group. For Amazon SES event publishing details, please refer to https://docs.aws.amazon.com/ses/latest/dg/monitor-using-event-publishing.html. The runbook also provides a summary and the timeline of the email deliveries as well as recommendations which can potentially affect undelivered email messages. You can find those messages in the output section of each executions. Please note that this runbook can only troubleshoot the events after the event store deployment.",
  "schemaVersion": "0.3",
  "assumeRole": "{{ AutomationAssumeRole }}",
  "parameters": {
    "AutomationAssumeRole": {
      "type": "AWS::IAM::Role::Arn",
      "description": "(Optional) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf. If no role is specified, Systems Manager Automation uses the permissions of the user that starts this runbook.",
      "default": ""
    },
    "MessageIds": {
      "type": "StringList",
      "description": "(Required) Comma separated Amazon SES message IDs of the Amazon SES events that you would like to analyze.",
      "allowedPattern": "^[0-9a-fA-F]{16}-[0-9a-fA-F]{8}-([0-9a-fA-F]{4}-){3}[0-9a-fA-F]{12}-[0-9]{6}$"
    },
    "CloudWatchLogsGroup": {
      "type": "String",
      "description": "(Optional) The Amazon CloudWatch Logs group which stores Amazon SES events. The default log group name is `/ses/sending_event_logs`. If you would like to utilize another log group than the default log group, please enter your log group name in this field.",
      "default": "/ses/sending_event_logs",
      "allowedPattern": "^$|[\\.\\-_/#A-Za-z0-9]{1,512}"
    },
    "QueryStartTime": {
      "type": "String",
      "description": "(Optional) The start time of the time range for the event analysis. The valid time format is ISO8601 (e.g. `yyyy-MM-ddTHH:mm:ss`, `1970-01-01T00:00:00`). The default date time is 30 days ago.",
      "default": "",
      "allowedPattern": "^$|^([\\+-]?\\d{4}(?!\\d{2}\\b))((-?)((0[1-9]|1[0-2])(\\3([12]\\d|0[1-9]|3[01]))?|(00[1-9]|0[1-9]\\d|[12]\\d{2}|3([0-5]\\d|6[1-6])))([T\\s]((([01]\\d|2[0-3])((:?)[0-5]\\d)?)([\\.,]\\d+(?!:))?)?(\\15[0-5]\\d([\\.,]\\d+)?)?([zZ]|([\\+-])([01]\\d|2[0-3]):?([0-5]\\d)?)?)?)?$"
    },
    "QueryEndTime": {
      "type": "String",
      "description": "(Optional) The end time of the time range for the event analyasis. The valid time format is ISO8601 (e.g. `yyyy-MM-ddTHH:mm:ss`, `1970-01-01T00:00:00`). The default date time is the current time.",
      "default": "",
      "allowedPattern": "^$|^([\\+-]?\\d{4}(?!\\d{2}\\b))((-?)((0[1-9]|1[0-2])(\\3([12]\\d|0[1-9]|3[01]))?|(00[1-9]|0[1-9]\\d|[12]\\d{2}|3([0-5]\\d|6[1-6])))([T\\s]((([01]\\d|2[0-3])((:?)[0-5]\\d)?)([\\.,]\\d+(?!:))?)?(\\15[0-5]\\d([\\.,]\\d+)?)?([zZ]|([\\+-])([01]\\d|2[0-3]):?([0-5]\\d)?)?)?)?$"
    }
  },
  "mainSteps": [
    {
      "name": "CheckConcurrency",
      "action": "aws:executeScript",
      "description": "Ensures there is only one execution of this runbook targeting the specified Amazon CloudWatch log group. If the runbook finds another in progress execution targeting the same log group, it returns an error and ends.",
      "timeoutSeconds": 600,
      "onFailure": "Abort",
      "inputs": {
        "InputPayload": {
          "TargetResourceId": "{{ CloudWatchLogsGroup }}",
          "ParameterName": "CloudWatchLogsGroup"
        },
        "Script": "from datetime import datetime, timedelta, timezone\n\nfrom boto3 import client as boto3_client\nfrom botocore.exceptions import ClientError\n\nSSM_CLIENT = boto3_client(\"ssm\")\nerror_msg = \"There is another execution of this document already in progress for {resource} with id {execution_id}\"\n\n\ndef check_concurrency_handler(events, context):\n    try:\n        # Get the current execution details\n        current_execution = SSM_CLIENT.describe_automation_executions(\n            Filters=[{\"Key\": \"ExecutionId\", \"Values\": [context[\"automation:EXECUTION_ID\"]]}]\n        )[\"AutomationExecutionMetadataList\"][0]\n\n        # Check for other previous/older running automations for the same current document that are not in a final status\n        current_execution_start_time = datetime.fromtimestamp(\n            current_execution[\"ExecutionStartTime\"].timestamp(), timezone.utc\n        )\n\n        # Add 5 seconds to 'StartTimeBefore' to capture executions that started exactly at the same time\n        current_execution_start_time += timedelta(seconds=5)\n\n        # Describe executions that are not in terminal status\n        document_executions = SSM_CLIENT.describe_automation_executions(\n            Filters=[\n                {\"Key\": \"DocumentNamePrefix\", \"Values\": [current_execution[\"DocumentName\"]]},\n                {\"Key\": \"ExecutionStatus\", \"Values\": [\"InProgress\", \"Pending\", \"Cancelling\", \"Waiting\"]},\n                {\"Key\": \"StartTimeBefore\", \"Values\": [current_execution_start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")]},\n            ]\n        )[\"AutomationExecutionMetadataList\"]\n\n        # Check for other previous executions targeting the same resource ID. If any, return an error\n        for execution in document_executions:\n            execution_id = execution[\"AutomationExecutionId\"]\n            if execution_id != current_execution[\"AutomationExecutionId\"]:\n                if execution.get(\"Target\", \"\") == events.get(\"TargetResourceId\"):\n                    raise RuntimeError(\n                        error_msg.format(\n                            resource=events.get(\"TargetResourceId\"), execution_id=events.get(\"AutomationExecutionId\")\n                        )\n                    ) from None\n\n                execution_details = (\n                    SSM_CLIENT.get_automation_execution(AutomationExecutionId=execution_id)[\"AutomationExecution\"]\n                    .get(\"Parameters\", [])\n                    .get(events.get(\"ParameterName\"), [])\n                )\n                execution_resource_id = next(iter(execution_details), \"\")\n                if execution_resource_id == events.get(\"TargetResourceId\"):\n                    raise RuntimeError(\n                        error_msg.format(\n                            resource=events.get(\"TargetResourceId\"), execution_id=events.get(\"AutomationExecutionId\")\n                        )\n                    ) from None\n\n    except ClientError as e:\n        c = e.response[\"Error\"][\"Code\"]\n        m = e.response[\"Error\"][\"Message\"]\n        raise RuntimeError(f\"An error occurred when checking concurrent executions: {c}:{m}\") from None\n\n    return {\n        \"NoExecutionFound\": f\"No Automation executions were found in progress for {current_execution.get('DocumentName')} runbook targeting {events.get('TargetResourceId')}\"\n    }\n",
        "Handler": "check_concurrency_handler",
        "Runtime": "python3.11"
      },
      "outputs": [
        {
          "Name": "NoExecutionFound",
          "Selector": "$.Payload.NoExecutionFound",
          "Type": "String"
        }
      ],
      "nextStep": "AnalyzeSesEvents"
    },
    {
      "name": "AnalyzeSesEvents",
      "action": "aws:executeScript",
      "description": "Analyze Amazon SES events stored in the Amazon CloudWatch Logs group specified by the automation parameter.",
      "timeoutSeconds": 600,
      "isCritical": false,
      "isEnd": true,
      "onFailure": "step:OutputFailureReason",
      "inputs": {
        "Runtime": "python3.11",
        "Handler": "script_handler",
        "InputPayload": {
          "MessageIds": "{{MessageIds}}",
          "CloudWatchLogsGroup": "{{ CloudWatchLogsGroup }}",
          "QueryStartTime": "{{ QueryStartTime }}",
          "QueryEndTime": "{{ QueryEndTime }}"
        },
        "Script": "import json\nimport re\nfrom bisect import bisect_right\nfrom collections import defaultdict\nfrom datetime import datetime, timedelta, timezone\nfrom ipaddress import ip_address\nfrom math import floor\nfrom secrets import token_bytes\nfrom socket import AF_INET, AF_INET6, SOCK_DGRAM, socket\nfrom time import sleep\nfrom typing import List\n\nfrom boto3 import client as boto3_client\nfrom dateutil.parser import ParserError  # type: ignore\nfrom dateutil.parser import parse as parse_datetime  # type: ignore\n\n\ndef retry(tries=3):\n    def _retry(f):\n        def _wrapper(*args, **kwargs):\n            for try_count in range(tries):\n                try:\n                    return f(*args, **kwargs)\n                except Exception as e:\n                    if try_count == tries - 1:\n                        raise e from None\n\n        return _wrapper\n\n    return _retry\n\n\nclass SesEvent:\n    EVENT_TYPES_ORDER = [\n        \"SendSesEvent\",\n        \"DeliveryDelaySesEvent\",\n        \"DeliverySesEvent\",\n        \"BounceSesEvent\",\n        \"ComplaintSesEvent\",\n    ]\n\n    def __init__(self, message_id, event_type, event_time, source_arn, header_from_domain):\n        self._message_id = message_id\n        self._event_type = event_type\n        self._event_time = event_time\n        self._source_arn = source_arn\n        self._header_from_domain = header_from_domain\n\n    @property\n    def message_id(self):\n        return self._message_id\n\n    @property\n    def event_type(self):\n        return self._event_type\n\n    @property\n    def event_time(self):\n        return self._event_time\n\n    @property\n    def source_arn(self):\n        return self._source_arn\n\n    @property\n    def header_from_domain(self):\n        return self._header_from_domain\n\n    def __str__(self):\n        return f\"MessageId = {self._message_id} eventType = {self.event_type}\"\n\n    def to_timeline_message(self):\n        return f\"[{self.event_time}] {self.to_message()}\"\n\n    def _mask_local_part(self, local_part):\n        if len(local_part) < 3:\n            return \"*\" * len(local_part)\n\n        return local_part[0] + \"*\" * (len(local_part) - 2) + local_part[-1]\n\n    def _mask_email_address(self, email_address):\n        try:\n            local_part, domain_part = email_address.split(\"@\")\n\n            return f\"{self._mask_local_part(local_part)}@{domain_part}\"\n        except ValueError:\n            return self._mask_local_part(email_address)\n\n    def to_message(self):\n        return str(self)\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__)\n            and self.message_id == other.message_id\n            and self.event_type == other.event_type\n        )\n\n    def __lt__(self, other):\n        return self.EVENT_TYPES_ORDER.index(self.__class__.__name__) < self.EVENT_TYPES_ORDER.index(\n            other.__class__.__name__\n        ) or (isinstance(other, self.__class__) and self.event_time < other.event_time)\n\n    @classmethod\n    def make_constructor_arguments(cls, ses_event):\n        message_id, event_type = ses_event[\"mail\"][\"messageId\"], ses_event[\"eventType\"]\n        event_time = datetime.strptime(ses_event[\"mail\"][\"timestamp\"], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n        source_arn = ses_event[\"mail\"][\"sourceArn\"]\n        header_from_domain = ses_event[\"mail\"][\"commonHeaders\"][\"from\"][0].split(\"@\")[1]\n\n        return [message_id, event_type, event_time, source_arn, header_from_domain]\n\n    @classmethod\n    def from_notification_message(cls, ses_event):\n        event_type = ses_event[\"eventType\"]\n        event_name = event_type + \"SesEvent\"\n        klass = globals().get(event_name, SesEvent)\n\n        return klass(*klass.make_constructor_arguments(ses_event))\n\n\nclass SendSesEvent(SesEvent):\n    def to_message(self):\n        return \"Your email message was sent from SES.\"\n\n\nclass DeliverySesEvent(SesEvent):\n    def __init__(\n        self,\n        message_id,\n        event_type,\n        event_time,\n        source_arn,\n        header_from_domain,\n        reporting_mta,\n        recipients,\n        smtp_response,\n        outgoing_ip,\n    ):\n        super().__init__(message_id, event_type, event_time, source_arn, header_from_domain)\n        self._reporting_mta = reporting_mta\n        self._recipients = recipients\n        self._smtp_response = smtp_response\n        self._outgoing_ip = outgoing_ip\n\n    def to_message(self):\n        return f'The message to {str([self._mask_email_address(recipient) for recipient in self._recipients])} was accepted by the remote MTA {self._reporting_mta} with smtp response \"{self._smtp_response}\". The outgoing IP address of SES is {self._outgoing_ip[0]}'\n\n    @property\n    def recipients(self):\n        return self._recipients\n\n    @property\n    def reporting_mta(self):\n        return self._reporting_mta\n\n    def __eq__(self, other):\n        return super().__eq__(other) and self.reporting_mta == other.reporting_mta\n\n    @classmethod\n    def make_constructor_arguments(cls, ses_event):\n        reporting_mta = ses_event[\"delivery\"][\"reportingMTA\"]\n        smtp_response = ses_event[\"delivery\"][\"smtpResponse\"]\n        recipients = ses_event[\"delivery\"][\"recipients\"]\n        outgoing_ip = ses_event[\"mail\"][\"tags\"][\"ses:outgoing-ip\"]\n\n        return super().make_constructor_arguments(ses_event) + [reporting_mta, recipients, smtp_response, outgoing_ip]\n\n\nclass DelayedRecipient:\n    def __init__(self, email_address, diagnostic_code):\n        self._email_address = email_address\n        self._diagnostic_code = diagnostic_code\n\n    @property\n    def email_address(self):\n        return self._email_address\n\n    @property\n    def diagnostic_code(self):\n        return self._diagnostic_code\n\n    def __eq__(self, other):\n        return self.email_address == other.email_address and self.diagnostic_code == other.diagnostic_code\n\n    def __hash__(self):\n        return hash(self._email_address + self._diagnostic_code)\n\n\nclass DeliveryDelaySesEvent(SesEvent):\n    def __init__(\n        self,\n        message_id,\n        event_type,\n        event_time,\n        source_arn,\n        header_from_domain,\n        delay_type,\n        delayed_recipients,\n        expiration_time,\n    ):\n        super().__init__(message_id, event_type, event_time, source_arn, header_from_domain)\n        self._delay_type = delay_type\n        self._delayed_recipients = delayed_recipients\n        self._expiration_time = expiration_time\n\n    @property\n    def delay_type(self):\n        return self._delay_type\n\n    @property\n    def delayed_recipients(self):\n        return self._delayed_recipients\n\n    def to_message(self):\n        message = (\n            f\"The deliveries to {[self._mask_email_address(recipient.email_address) for recipient in self.delayed_recipients]} \"\n            + f\"were delayed due to {self._delay_type}.\"\n        )\n\n        return message\n\n    def __eq__(self, other):\n        return (\n            super().__eq__(other)\n            and self.delay_type == other.delay_type\n            and len(set(self.delayed_recipients) - set(other.delayed_recipients)) == 0\n        )\n\n    @classmethod\n    def make_constructor_arguments(cls, ses_event):\n        delay_type = ses_event[\"deliveryDelay\"][\"delayType\"]\n        delayed_recipients = [\n            DelayedRecipient(recipient[\"emailAddress\"], recipient[\"diagnosticCode\"])\n            for recipient in ses_event[\"deliveryDelay\"][\"delayedRecipients\"]\n        ]\n        expiration_time = ses_event[\"deliveryDelay\"][\"expirationTime\"]\n\n        return super().make_constructor_arguments(ses_event) + [delay_type, delayed_recipients, expiration_time]\n\n\nclass BounceRecipient:\n    def __init__(self, email_address, diagnostic_code):\n        self._email_address = email_address\n        self._diagnostic_code = diagnostic_code\n\n    @property\n    def email_address(self):\n        return self._email_address\n\n    @property\n    def diagnostic_code(self):\n        return self._diagnostic_code\n\n    def __eq__(self, other):\n        return self.email_address == other.email_address and self.diagnostic_code == other.diagnostic_code\n\n    def __hash__(self):\n        return hash(self._email_address + self._diagnostic_code)\n\n\nclass BounceSesEvent(SesEvent):\n    def __init__(\n        self,\n        message_id,\n        event_type,\n        event_time,\n        source_arn,\n        header_from_domain,\n        feedback_id,\n        reporting_mta,\n        bounce_type,\n        bounce_subtype,\n        bounced_recipients,\n    ):\n        super().__init__(message_id, event_type, event_time, source_arn, header_from_domain)\n        self._feedback_id = feedback_id\n        self._reporting_mta = reporting_mta\n        self._bounce_type = bounce_type\n        self._bounce_subtype = bounce_subtype\n        self._bounced_recipients = bounced_recipients\n\n    def to_message(self):\n        message = (\n            f\"SES received a bounce from {self._reporting_mta}.\\n\"\n            + f\"  Bounce type: {self._bounce_type}({self._bounce_subtype})\\n\"\n            + \"  Bounce sources:\\n\"\n            + \"\\n\".join(\n                [\n                    f'    - email address: {self._mask_email_address(recipient.email_address)}  diagnostic code: \"{recipient.diagnostic_code}\"'\n                    for recipient in self.bounced_recipients\n                ]\n            )\n        )\n\n        return message\n\n    @property\n    def reporting_mta(self):\n        return self._reporting_mta\n\n    @property\n    def bounced_recipients(self):\n        return self._bounced_recipients\n\n    def __eq__(self, other):\n        return (\n            super().__eq__(other)\n            and self.reporting_mta == other.reporting_mta\n            and len(set(self.bounced_recipients) - set(other.bounced_recipients)) == 0\n        )\n\n    @classmethod\n    def make_constructor_arguments(cls, ses_event):\n        feedback_id = ses_event[\"bounce\"][\"feedbackId\"]\n        bounce_type = ses_event[\"bounce\"][\"bounceType\"]\n        bounce_subtype = ses_event[\"bounce\"][\"bounceSubType\"]\n        reporting_mta = ses_event[\"bounce\"][\"reportingMTA\"]\n        bounced_recipients = [\n            BounceRecipient(recipient[\"emailAddress\"], recipient[\"diagnosticCode\"])\n            for recipient in ses_event[\"bounce\"][\"bouncedRecipients\"]\n        ]\n\n        return super().make_constructor_arguments(ses_event) + [\n            feedback_id,\n            reporting_mta,\n            bounce_type,\n            bounce_subtype,\n            bounced_recipients,\n        ]\n\n\nclass ComplaintSesEvent(SesEvent):\n    def __init__(\n        self,\n        message_id,\n        event_type,\n        event_time,\n        source_arn,\n        header_from_domain,\n        feedback_id,\n        complaint_subtype,\n        feedback_type,\n        complained_recipients,\n    ):\n        super().__init__(message_id, event_type, event_time, source_arn, header_from_domain)\n        self._feedback_id = feedback_id\n        self._complaint_subtype = complaint_subtype\n        self._feedback_type = feedback_type\n        self._complained_recipients = complained_recipients\n\n    @property\n    def complained_recipients(self):\n        return self._complained_recipients\n\n    def to_message(self):\n        message = (\n            \"SES received complaints from below email recipients.\\n\"\n            + f\"  Complaint feedback type: {self._feedback_type}\\n\"\n            + \"  Complaint sources:\\n\"\n            + \"\\n\".join([f\"    - {self._mask_email_address(recipient)}\" for recipient in self.complained_recipients])\n        )\n\n        return message\n\n    def __eq__(self, other):\n        return super().__eq__(other) and len(set(self.complained_recipients) - set(other.complained_recipients)) == 0\n\n    @classmethod\n    def make_constructor_arguments(cls, ses_event):\n        feedback_id = ses_event[\"complaint\"][\"feedbackId\"]\n        complaint_subtype = ses_event[\"complaint\"][\"complaintSubType\"]\n        feedback_type = ses_event[\"complaint\"][\"complaintFeedbackType\"]\n        complained_recipients = [\n            recipient[\"emailAddress\"] for recipient in ses_event[\"complaint\"][\"complainedRecipients\"]\n        ]\n\n        return super().make_constructor_arguments(ses_event) + [\n            feedback_id,\n            complaint_subtype,\n            feedback_type,\n            complained_recipients,\n        ]\n\n\nclass CloudWatchSesEventPuller:\n    DEFAULT_LOG_GROUP_NAME = \"/ses/sending_event_logs\"\n    QUERY_ERROR_MESSAGE_TIMEOUT = \"Please reduce the query time range and run this document again.\"\n    QUERY_ERROR_MESSAGE_OTHER_CAUSES = \"Please run this document again for the transient errors.\"\n\n    def __init__(self, log_group=None):\n        self._client = boto3_client(\"logs\")\n        self._log_group = log_group or self.DEFAULT_LOG_GROUP_NAME\n        self._listeners = {}\n\n    def add_event_listener(self, listener):\n        self._listeners[listener.message_id] = listener\n\n    def _create_logs_insights_query(self):\n        return (\n            \"filter mail.commonHeaders.messageId in [\"\n            + \",\".join([f'\"{message_id}\"' for message_id in self._listeners.keys()])\n            + \"]\"\n        )\n\n    @retry()\n    def _start_job(self, query_start_timestamp, query_end_timestamp):\n        response = self._client.start_query(\n            logGroupName=self._log_group,\n            startTime=query_start_timestamp,\n            endTime=query_end_timestamp,\n            queryString=self._create_logs_insights_query(),\n        )\n\n        return response[\"queryId\"]\n\n    def _convert_query_response_to_ses_events(self, response):\n        message_id_to_events_map = defaultdict(list)\n        events = [\n            SesEvent.from_notification_message(json.loads(field[\"value\"]))\n            for result in response[\"results\"]\n            for field in result\n            if field[\"field\"] == \"@message\"\n        ]\n\n        for event in events:\n            message_id_to_events_map[event.message_id].append(event)\n\n        return message_id_to_events_map\n\n    def _create_invalid_job_status_error_message(self, job_status):\n        message_prefix = (\n            f'We got an invalid CloudWatch Logs Insights query result of \"{job_status}\" while retrieving SES events. '\n        )\n        action_message = (\n            self.QUERY_ERROR_MESSAGE_TIMEOUT if job_status == \"Timeout\" else self.QUERY_ERROR_MESSAGE_OTHER_CAUSES\n        )\n\n        return message_prefix + action_message\n\n    @retry()\n    def pull(self, query_start_timestamp, query_end_timestamp):\n        if not any(self._listeners):\n            return\n\n        query_id = self._start_job(query_start_timestamp, query_end_timestamp)\n        while True:\n            response = self._client.get_query_results(queryId=query_id)\n            job_status = response[\"status\"]\n            if job_status not in [\"Scheduled\", \"Running\"]:\n                break\n            sleep(5)\n\n        if job_status != \"Complete\":\n            raise RuntimeError(self._create_invalid_job_status_error_message(job_status)) from None\n\n        events = self._convert_query_response_to_ses_events(response)\n\n        # To trigger transitions of event managers to the final status,\n        # we kick the listeners even if we didn't receive new events for the event managers.\n        for message_id, listener in self._listeners.items():\n            events_of_message_id = events.get(message_id, [])\n            listener.add_ses_events(events_of_message_id)\n\n\nclass EventStatus:\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 30\n    TRANSITION_TRIGGER_EVENT_TYPES: List[str] = []\n    EVENT_TYPES_TO_STATES = {\n        BounceSesEvent: \"FeedbackReceivedStatus\",\n        ComplaintSesEvent: \"FeedbackReceivedStatus\",\n        DeliverySesEvent: \"DeliveredStatus\",\n        DeliveryDelaySesEvent: \"DelayedStatus\",\n        SendSesEvent: \"SentStatus\",\n        None: \"FinalStatus\",\n    }\n\n    def __init__(self, event=None):\n        self._first_event_took_place_at = event.event_time if event else datetime.now(timezone.utc)\n        self._transitioned_at = datetime.now(timezone.utc)\n\n    def max_allowed_time_to_stay(self):\n        return self._first_event_took_place_at + timedelta(seconds=self.MAX_ALLOWED_TIME_TO_STAY_SEC)\n\n    def should_switch_to_next_state(self, event):\n        return (\n            event.__class__.__name__ in self.TRANSITION_TRIGGER_EVENT_TYPES\n            or self.max_allowed_time_to_stay() < datetime.now(timezone.utc)\n        )\n\n    def is_completed(self):\n        return False\n\n    @classmethod\n    def subsidiary_state(cls, event, event_manager):\n        return None\n\n    @classmethod\n    def next_state(cls, event, event_manager):\n        state_class_candidate = globals()[cls.EVENT_TYPES_TO_STATES[event.__class__]]\n        state_class = state_class_candidate.subsidiary_state(event, event_manager) or state_class_candidate\n\n        return state_class(event)\n\n\nclass InitialStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\"SendSesEvent\"]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 30\n\n    def max_allowed_time_to_stay(self):\n        return self._transitioned_at + timedelta(seconds=self.MAX_ALLOWED_TIME_TO_STAY_SEC)\n\n\nclass SentStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\n        \"DeliverySesEvent\",\n        \"DeliveryDelaySesEvent\",\n        \"BounceSesEvent\",\n        \"ComplaintSesEvent\",\n    ]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 60\n\n\nclass DelayedStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\"DeliverySesEvent\", \"BounceSesEvent\", \"ComplaintSesEvent\"]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 300\n\n\nclass DeliveredAfterDelayedStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\"BounceSesEvent\", \"ComplaintSesEvent\"]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 120\n\n\nclass DeliveredStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\"BounceSesEvent\", \"ComplaintSesEvent\"]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 120\n\n    @classmethod\n    def _do_delivered_recipients_contain_delayed_recipients(cls, event, delivered_recipients):\n        number_of_delivered_recipients = len(delivered_recipients)\n        delayed_recipients = set([delayed_recipient.email_address for delayed_recipient in event.delayed_recipients])\n        delivered_recipients -= delayed_recipients\n\n        return len(delivered_recipients) != number_of_delivered_recipients\n\n    @classmethod\n    def subsidiary_state(cls, event, event_manager):\n        delivered_recipients = set(event.recipients)\n\n        for event in event_manager.event_store:\n            if event.__class__ != DeliveryDelaySesEvent:\n                continue\n\n            if cls._do_delivered_recipients_contain_delayed_recipients(event, delivered_recipients):\n                return DeliveredAfterDelayedStatus\n\n        return None\n\n\nclass FeedbackReceivedStatus(EventStatus):\n    TRANSITION_TRIGGER_EVENT_TYPES = [\"BounceSesEvent\", \"ComplaintSesEvent\"]\n    MAX_ALLOWED_TIME_TO_STAY_SEC = 120\n\n\nclass FinalStatus(EventStatus):\n    def max_allowed_time_to_stay(self):\n        return self._transitioned_at + timedelta(days=30)\n\n    def should_switch_to_next_state(self, event):\n        return False\n\n    def is_completed(self):\n        return True\n\n\nclass SesEventManager:\n    def __init__(self, message_id):\n        self._event_store = []\n        self._previous_state = None\n        self._head_index = -1\n        self._current_state = InitialStatus()  # type: EventStatus\n        self._message_id = message_id\n\n    @property\n    def current_state(self):\n        return self._current_state\n\n    @property\n    def previous_state(self):\n        return self._previous_state\n\n    @property\n    def message_id(self):\n        return self._message_id\n\n    @property\n    def event_store(self):\n        return self._event_store\n\n    def _is_event_already_in_event_store(self, event, index):\n        return self._event_store and self._event_store[index - 1] == event\n\n    def _is_unsupported_event_type(self, event):\n        return event.__class__.__name__ not in SesEvent.EVENT_TYPES_ORDER\n\n    def _insert_event_to_event_store(self, event):\n        if self._is_unsupported_event_type(event):\n            return\n\n        index = bisect_right(self._event_store, event)\n        if event.message_id != self._message_id or self._is_event_already_in_event_store(event, index):\n            return\n        self._event_store.insert(index, event)\n        if index < self._head_index:\n            self._head_index += 1\n\n    def add_ses_events(self, events):\n        for event in events:\n            self._insert_event_to_event_store(event)\n        self._process_new_events()\n\n    def _exceeds_time_limit(self):\n        return self.current_state.max_allowed_time_to_stay() < datetime.now(timezone.utc)\n\n    def _reached_event_store_tail(self):\n        return not self._event_store or self._head_index == len(self._event_store) - 1\n\n    def _will_stay_in_initial_status(self):\n        return self._head_index == -1 and not self._event_store\n\n    def _do_process_new_events(self):\n        if self._will_stay_in_initial_status():\n            return 0\n\n        original_head_index = self._head_index\n        for i in range(self._head_index, len(self._event_store)):\n            event = self._event_store[i]\n            if self.current_state.should_switch_to_next_state(event):\n                self._previous_state = self._current_state\n                self._current_state = self._current_state.next_state(event, self)\n                self._head_index = i\n\n        processed_event_count = self._head_index - original_head_index\n        return processed_event_count\n\n    def _switch_to_next_state(self):\n        self._previous_state = self._current_state\n        if self._reached_event_store_tail():\n            self._current_state = FinalStatus()\n        else:\n            self._head_index += 1\n            event = self._event_store[self._head_index]\n            self._current_state = self._current_state.next_state(event, self)\n\n    def _process_new_events(self):\n        new_event_count = self._do_process_new_events()\n        if new_event_count == 0 and self._exceeds_time_limit():\n            self._switch_to_next_state()\n\n\nclass SesDeliveryStatusMessageGenerator:\n    STATUS_TO_RESULT_MESSAGE = {\n        InitialStatus: \"We could not find SES events in the provided query time range.\",\n        SentStatus: \"SES sent messages to the destinations, but we could not find responses from the destination email servers in the event store with the provided query time range.\",\n        DelayedStatus: \"The delivery was delayed.\",\n        DeliveredStatus: \"The message was successfully delivered to the destination mail servers.\",\n        DeliveredAfterDelayedStatus: \"The message was successfully delivered to the destination mail servers with delays.\",\n        FeedbackReceivedStatus: \"SES received bounces or complaints.\",\n    }\n\n    STATUS_TO_NEXT_ACTION_MESSAGE = {\n        InitialStatus: \"Please adjust the time range of the query with parameters QueryStartTime and QueryEndTime and run this runbook again.\",\n        SentStatus: \"Please adjust the time range of the query with parameters QueryStartTime and QueryEndTime and run this runbook again.\",\n        DelayedStatus: \"Please refer to the Timeline section for the details of the delay\",\n        DeliveredStatus: \"Please contact to the administrators of the receiving mail server if your message was not delivered to the destination email addresses.\",\n        DeliveredAfterDelayedStatus: \"Please refer to the Timeline section for the details of the delay\",\n        FeedbackReceivedStatus: \"Please fix the issues described in the delivery error messages returned from the destination email servers in the Timeline section. In the case you received suppression list bounces, please check your account level suppression list in this region.\",\n    }\n\n    def _summary_message(self, event_manager):\n        message = f\"==== Delivery summary of the message ID {event_manager.message_id} ====\\n\"\n        message += \" \" + self.STATUS_TO_RESULT_MESSAGE[event_manager.previous_state.__class__] + \"\\n\"\n\n        return message\n\n    def _timeline_message(self, event_manager):\n        message = f\"==== Timeline of {event_manager.message_id} =====\\n\"\n        events = sorted(\n            filter(lambda event: not isinstance(event, SesEvent), event_manager.event_store),\n            key=lambda event: event.event_time,\n        )\n        message += \"\\n\".join([\" \" + event.to_timeline_message() for event in events])\n\n        return message\n\n    def _next_action_message(self, event_manager):\n        message = \"==== Next Action ====\\n\"\n        message += \" \" + self.STATUS_TO_NEXT_ACTION_MESSAGE[event_manager.previous_state.__class__] + \"\\n\"\n\n        return message\n\n    def to_message(self, event_manager):\n        message = self._summary_message(event_manager)\n        if event_manager.event_store:\n            message += \"\\n\" + self._timeline_message(event_manager) + \"\\n\"\n        message += \"\\n\" + self._next_action_message(event_manager)\n\n        return message\n\n\nclass SimpleDnsResolver:\n    DEFAULT_RESOLVE_CONF_PATH = \"/etc/resolv.conf\"\n    MAX_RESPONSE_SIZE = 4096\n    IP_ADDRESS_PATTERN = r\"^\\s*nameserver\\s+([0-9a-zA-Z.:]+)(\\s|$)\"\n    IP_VERSION_TO_ADDRESS_FAMILY = {4: AF_INET, 6: AF_INET6}\n    QTYPE_A_RECORD = 1\n    QTYPE_NS_RECORD = 2\n    QTYPE_CNAME_RECORD = 5\n    QTYPE_SOA_RECORD = 6\n    QTYPE_WKS_RECORD = 11\n    QTYPE_PTR_RECORD = 12\n    QTYPE_HINFO_RECORD = 13\n    QTYPE_MINFO_RECORD = 14\n    QTYPE_MX_RECORD = 15\n    QTYPE_TXT_RECORD = 16\n\n    def __init__(self):\n        self._resolver_ip_addresses = self._get_resolver_ip_addresses_from_resolve_conf()\n\n    @property\n    def resolver_ip_addresses(self):\n        return self._resolver_ip_addresses\n\n    def _eliminate_comment(self, line):\n        return line.split(\"#\", 1)[0].rstrip()\n\n    def _get_resolver_ip_addresses_from_resolve_conf(self):\n        with open(self.DEFAULT_RESOLVE_CONF_PATH, \"r\") as resolve_conf:\n            ip_addresses = []\n            for line in resolve_conf.readlines():\n                _line = self._eliminate_comment(line)\n                found = re.search(self.IP_ADDRESS_PATTERN, _line)\n                if found:\n                    ip_addresses.append(found.group(1))\n            return ip_addresses\n\n    def _encode_label(self, label):\n        return int.to_bytes(len(label), length=1, byteorder=\"big\") + label.encode()\n\n    def _create_qname_from_domain(self, domain):\n        return b\"\".join([self._encode_label(label) for label in domain.rstrip(\".\").split(\".\")]) + b\"\\0\"\n\n    def _build_query_header(self):\n        query_id = token_bytes(2)\n\n        flags = b\"\\1\\0\"  # only RD (Recursion Desired) is set\n        questions = b\"\\0\\1\"  # one question\n        answer_rrs = b\"\\0\\0\"  # No Answer RRs\n        authority_rrs = b\"\\0\\0\"  # No Authority RRs\n        additional_rrs = b\"\\0\\0\"  # No Additional RRs\n\n        return query_id, query_id + flags + questions + answer_rrs + authority_rrs + additional_rrs\n\n    def _build_query(self, domain, qtype_num):\n        query_id, header = self._build_query_header()\n        qname = self._create_qname_from_domain(domain)\n        qtype = int.to_bytes(qtype_num, length=2, byteorder=\"big\")\n        qclass = b\"\\0\\1\"\n        question = qname + qtype + qclass\n\n        return query_id, header + question\n\n    def _get_resolver_address(self, resolver_index):\n        resolver_ip_address_string = self._resolver_ip_addresses[resolver_index]\n        try:\n            resolver_ip_address = ip_address(resolver_ip_address_string)\n            return resolver_ip_address_string, self.IP_VERSION_TO_ADDRESS_FAMILY[resolver_ip_address.version]\n        except ValueError:\n            raise ValueError(f\"Invalid IP address specified in resolv.conf: {resolver_ip_address_string}\") from None\n\n    def _assert_response(self, response, query_id):\n        is_response_for_our_query = response[:2] == query_id\n        flags = response[2]\n        is_response_bit_set = flags & 128\n        is_query_supported = not flags & 4\n\n        return is_response_for_our_query and is_response_bit_set and is_query_supported\n\n    def _parse_int(self, current_position, offset_in_bytes):\n        return int.from_bytes(current_position[:offset_in_bytes], \"big\"), current_position[offset_in_bytes:]\n\n    def _is_message_compressed(self, current_position):\n        return (current_position[0] >> 6) == 3\n\n    def _parse_qname(self, current_position, response):\n        labels = []\n        if not current_position:\n            return \"\", current_position\n\n        if self._is_message_compressed(current_position):\n            offset, current_position = self._parse_int(current_position, 2)\n            offset &= 0x3FFF\n            label, _ = self._parse_qname(response[offset:], response)\n            if label:\n                labels.append(label)\n        else:\n            size, current_position = self._parse_int(current_position, 1)\n            if size != 0:\n                label, current_position = current_position[:size], current_position[size:]\n                labels.append(label.decode())\n                _labels, current_position = self._parse_qname(current_position, response)\n                if _labels:\n                    labels.append(_labels)\n        return \".\".join(labels), current_position\n\n    def _parse_txt_records(self, current_position, rdlength):\n        txt_resource_records = []\n        offset = 0\n        while offset < rdlength:\n            txt_length, current_position = self._parse_int(current_position, 1)\n            txt_resource_records.append(current_position[:txt_length].decode())\n            current_position = current_position[:txt_length]\n            offset += 1 + txt_length\n        return txt_resource_records, current_position\n\n    def _parse_questions(self, current_position, response):\n        qdcount = int.from_bytes(response[4:6], \"big\")\n\n        for _ in range(qdcount):\n            qname, current_position = self._parse_qname(current_position, response)\n            qtype, current_position = self._parse_int(current_position, 2)\n            qclass, current_position = self._parse_int(current_position, 2)\n\n        return current_position\n\n    def _is_hostname_answered(self, qtype):\n        return qtype in [self.QTYPE_NS_RECORD, self.QTYPE_CNAME_RECORD, self.QTYPE_PTR_RECORD, self.QTYPE_MX_RECORD]\n\n    def _parse_each_answer(self, current_position, response):\n        domain, current_position = self._parse_qname(current_position, response)\n        qtype, current_position = self._parse_int(current_position, 2)\n        qclass, current_position = self._parse_int(current_position, 2)\n        ttl, current_position = self._parse_int(current_position, 4)\n        rdlength, current_position = self._parse_int(current_position, 2)\n        rdata, current_position = current_position[:rdlength], current_position[rdlength:]\n\n        additional_data = None\n        if qtype == self.QTYPE_A_RECORD:\n            rdata = \".\".join(str(x) for x in rdata)\n        elif qtype == self.QTYPE_MX_RECORD:\n            preference, rdata = self._parse_int(rdata, 2)\n            additional_data = preference\n        elif qtype == self.QTYPE_TXT_RECORD:\n            rdata, _ = self._parse_txt_records(rdata, rdlength)\n\n        if self._is_hostname_answered(qtype):\n            rdata, _ = self._parse_qname(rdata, response)\n\n        return {\n            \"qtype\": qtype,\n            \"domain\": domain,\n            \"ttl\": ttl,\n            \"rdata\": rdata,\n            \"additional_data\": additional_data,\n        }, current_position\n\n    def _parse_answers(self, current_position, response):\n        ancount = int.from_bytes(response[6:8], \"big\")\n\n        answers = []\n        for _ in range(ancount):\n            answer, current_position = self._parse_each_answer(current_position, response)\n            answers.append(answer)\n\n        return answers\n\n    def parse_response(self, response, query_id):\n        if not self._assert_response(response, query_id):\n            return None\n\n        response_code = response[3] & 0xF\n        current_position = self._parse_questions(response[12:], response)\n        answers = self._parse_answers(current_position, response)\n\n        return response_code, answers\n\n    def _do_query(self, query_id, query):\n        for resolver_index in range(len(self._resolver_ip_addresses)):\n            try:\n                resolver_ip_address, address_family = self._get_resolver_address(resolver_index)\n                with socket(address_family, SOCK_DGRAM) as s:\n                    s.sendto(query, (resolver_ip_address, 53))\n                    response, _ = s.recvfrom(self.MAX_RESPONSE_SIZE)\n                    response_code, answers = self.parse_response(response, query_id)\n\n                    if response_code != 0:\n                        continue\n\n                    return answers\n            except Exception as e:\n                if resolver_index == len(self._resolver_ip_addresses) - 1:\n                    raise e from None\n\n        return []\n\n    def _query_record(self, domain, qtype):\n        query_id, query = self._build_query(domain, qtype)\n\n        return self._do_query(query_id, query)\n\n    def query_a_record(self, domain):\n        return self._query_record(domain, self.QTYPE_A_RECORD)\n\n    def query_ptr_record(self, domain):\n        return self._query_record(domain, self.QTYPE_PTR_RECORD)\n\n    def query_txt_record(self, domain):\n        return self._query_record(domain, self.QTYPE_TXT_RECORD)\n\n    def query_mx_record(self, domain):\n        return self._query_record(domain, self.QTYPE_MX_RECORD)\n\n\nclass DnsBasedPublicSuffixProvider:\n    QUERY_PUBLIC_SUFFIX_ZONE_DOMAIN = \"query.publicsuffix.zone\"\n\n    def __init__(self, dns_resolver=None):\n        self._dns_resolver = dns_resolver if dns_resolver else SimpleDnsResolver()\n\n    def get_public_suffix(self, domain):\n        public_suffix_zone_query_domain = domain + \".\" + self.QUERY_PUBLIC_SUFFIX_ZONE_DOMAIN\n        try:\n            response = list(\n                filter(\n                    lambda record: record[\"qtype\"] == self._dns_resolver.QTYPE_PTR_RECORD,\n                    self._dns_resolver.query_ptr_record(public_suffix_zone_query_domain),\n                )\n            )\n        except (OSError, TimeoutError, ValueError):\n            return None\n\n        return response[0][\"rdata\"] if response else None\n\n\nclass CustomerEnvironmentEvaluator:\n    SES_IDENTITY_ARN_PATTERN = r\"^arn:(?:aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ses:[a-z\\-\\d]+:\\d{12}:identity/((\\S{1,64}@)?((?!-)[^\\.\\s]{0,62}(?<!-)\\.)+[^\\.\\s]{2,63})$\"\n    DNS_RECORD_TYPE_TO_RECORD_PREFIX = {\n        \"spf\": \"v=spf1\",\n        \"dmarc\": \"v=DMARC1\",\n    }\n    ORGANIZATIONAL_DOMAIN_PATTERN_TEMPLATE = r\"\\.([^\\.]+?\\.{})\"\n\n    def __init__(self):\n        self._dns_resolver = SimpleDnsResolver()\n        self._public_suffix_provider = DnsBasedPublicSuffixProvider(self._dns_resolver)\n        self._ses_client = boto3_client(\"ses\")\n\n    @property\n    def ses_client(self):\n        return self._ses_client\n\n    @property\n    def dns_resolver(self):\n        return self._dns_resolver\n\n    @dns_resolver.setter\n    def dns_resolver(self, dns_resolver):\n        self._dns_resolver = dns_resolver\n\n    @retry()\n    def _is_ses_account_in_production_mode(self):\n        response = self._ses_client.get_send_quota()\n\n        return response[\"Max24HourSend\"] != 200.0 or response[\"MaxSendRate\"] != 1.0\n\n    def _get_identity_name_from_arn(self, arn):\n        found = re.search(self.SES_IDENTITY_ARN_PATTERN, arn)\n        if not found:\n            raise ValueError(f\"Invalid ARN in the input of get_identity_name_from_arn: {arn}\") from None\n\n        return found.group(1)\n\n    def _is_valid_custom_mail_from_domain_configured(self, mail_from_domain_attribute):\n        return (\n            \"MailFromDomain\" in mail_from_domain_attribute\n            and mail_from_domain_attribute[\"MailFromDomainStatus\"] == \"Success\"\n        )\n\n    @retry()\n    def _get_custom_mail_from_domain(self, identity_name):\n        response = self._ses_client.get_identity_mail_from_domain_attributes(Identities=[identity_name])\n        if identity_name not in response[\"MailFromDomainAttributes\"]:\n            return None\n\n        mail_from_domain_attribute = response[\"MailFromDomainAttributes\"][identity_name]\n\n        return (\n            mail_from_domain_attribute[\"MailFromDomain\"]\n            if self._is_valid_custom_mail_from_domain_configured(mail_from_domain_attribute)\n            else None\n        )\n\n    def _is_dns_authentication_record_declared(self, domain, record_type):\n        if record_type not in self.DNS_RECORD_TYPE_TO_RECORD_PREFIX:\n            raise ValueError(\n                f\"Invalid TXT record type specified in is_dns_authentication_record_declared: {record_type}\"\n            ) from None\n\n        try:\n            response = self._dns_resolver.query_txt_record(domain)\n        except (OSError, TimeoutError, ValueError):\n            return True\n\n        txt_records: List[str] = sum([record[\"rdata\"] for record in response], [])\n\n        for txt_record in txt_records:\n            if txt_record.startswith(self.DNS_RECORD_TYPE_TO_RECORD_PREFIX[record_type]):\n                return True\n\n        return False\n\n    def _get_organizational_domain(self, domain):\n        public_suffix = self._public_suffix_provider.get_public_suffix(domain)\n        if not public_suffix:\n            return None\n\n        pattern = self.ORGANIZATIONAL_DOMAIN_PATTERN_TEMPLATE.format(public_suffix)\n        found = re.search(pattern, domain)\n        if not found:\n            return None\n\n        return found.group(1)\n\n    def _is_spf_record_declared(self, domain):\n        return self._is_dns_authentication_record_declared(domain, \"spf\")\n\n    def _is_dmarc_record_declared(self, domain):\n        _domain = \"_dmarc.\" + domain\n\n        return self._is_dns_authentication_record_declared(_domain, \"dmarc\")\n\n    def _is_dmarc_record_declared_on_organizational_domain(self, domain):\n        organizational_domain = self._get_organizational_domain(domain)\n        if not organizational_domain or organizational_domain == domain:\n            return False\n\n        return self._is_dmarc_record_declared(organizational_domain)\n\n    def _is_mx_record_declared(self, domain):\n        try:\n            response = self._dns_resolver.query_mx_record(domain)\n        except (OSError, TimeoutError, ValueError):\n            return True\n        mx_records = [record[\"rdata\"] for record in response]\n\n        return bool(mx_records)\n\n    def _get_header_from_domain_from_identity_name(self, identity_name):\n        try:\n            index = identity_name.index(\"@\")\n            return identity_name[index + 1 :]\n        except ValueError:\n            return identity_name\n\n    def evaluate(self, source_identity_arn, header_from_domain):\n        identity_name = self._get_identity_name_from_arn(source_identity_arn)\n        custom_mail_from_domain = self._get_custom_mail_from_domain(identity_name)\n\n        has_spf_record = False if not custom_mail_from_domain else self._is_spf_record_declared(custom_mail_from_domain)\n        has_dmarc_record = self._is_dmarc_record_declared(\n            header_from_domain\n        ) or self._is_dmarc_record_declared_on_organizational_domain(header_from_domain)\n        has_mx_record = self._is_mx_record_declared(header_from_domain)\n        is_production = self._is_ses_account_in_production_mode()\n\n        return {\n            \"IsAccountInProductionMode\": is_production,\n            \"CustomMailFromDomain\": custom_mail_from_domain,\n            \"HasSpfRecord\": has_spf_record,\n            \"HasDmarcRecord\": has_dmarc_record,\n            \"HasMxRecord\": has_mx_record,\n        }\n\n\ndef are_analyses_completed(event_managers):\n    return all([event_manager.current_state.is_completed() for event_manager in event_managers])\n\n\ndef filter_event_managers_in_feedback_received_status(event_managers):\n    return list(\n        filter(lambda event_manager: isinstance(event_manager.previous_state, FeedbackReceivedStatus), event_managers)\n    )\n\n\ndef are_feedbacks_received(event_managers):\n    return bool(filter_event_managers_in_feedback_received_status(event_managers))\n\n\ndef retrieve_email_sources(event_manager):\n    ses_event = event_manager.event_store[0]\n\n    return (ses_event.source_arn, ses_event.header_from_domain)\n\n\ndef get_email_sources_of_feedback_received_events(event_managers):\n    feedback_received_event_managers = filter_event_managers_in_feedback_received_status(event_managers)\n\n    return list(set([retrieve_email_sources(event_manager) for event_manager in feedback_received_event_managers]))\n\n\ndef create_recommendation_message_from_evaluation(source_arn, evaluation):\n    message_prefix = f\"===== Recommendations for {source_arn} =====\"\n    message = \"\"\n    if not evaluation[\"IsAccountInProductionMode\"]:\n        message += \"\\n- The SES account in this region seems to be in the sandbox environment. If you haven't requested the production access, please consider to move out of the sandbox environment. More information can be found on https://docs.aws.amazon.com/ses/latest/dg/request-production-access.html\"\n    if evaluation[\"CustomMailFromDomain\"] and not evaluation[\"HasSpfRecord\"]:\n        message += f\"\\n- The custom mail from domain {evaluation['CustomMailFromDomain']} does not have an SPF record. Please refer to the below document to setup your custom MAIL FROM domain. https://docs.aws.amazon.com/ses/latest/dg/mail-from.html#mail-from-set\"\n    if not evaluation[\"HasDmarcRecord\"]:\n        message += \"\\n- The header from domain does not have a DMARC record. Please setup a DMARC record if you would like to comply with DMARC. https://docs.aws.amazon.com/ses/latest/dg/send-email-authentication-dmarc.html\"\n    if not evaluation[\"HasMxRecord\"]:\n        message += \"\\n- The header from domain does not have an MX record.\"\n\n    return \"\" if not message else message_prefix + message\n\n\ndef create_recommendations_message(event_managers):\n    email_sources = get_email_sources_of_feedback_received_events(event_managers)\n    customer_environment_evaluator = CustomerEnvironmentEvaluator()\n\n    return \"\\n\\n\".join(\n        list(\n            filter(\n                lambda message: message != \"\",\n                [\n                    create_recommendation_message_from_evaluation(\n                        email_source[0], customer_environment_evaluator.evaluate(*email_source)\n                    )\n                    for email_source in email_sources\n                ],\n            )\n        )\n    )\n\n\ndef create_query_date_range_from_now():\n    now = datetime.now(timezone.utc)\n    now_timestamp = floor(now.timestamp())\n    thirty_days_ago_timestamp = floor((now - timedelta(days=30)).timestamp())\n\n    return thirty_days_ago_timestamp, now_timestamp\n\n\ndef create_query_date_range_from_parameters(query_start_time_string, query_end_time_string):\n    try:\n        query_start_time = floor(parse_datetime(query_start_time_string).timestamp())\n        query_end_time = floor(parse_datetime(query_end_time_string).timestamp())\n\n        return query_start_time, query_end_time\n    except (ParserError, OverflowError):\n        raise ValueError(\n            \"Invalid time format in the parameters: The valid time format is ISO8601 (e.g. yyyy-MM-ddTHH:mm:ss, 1970-01-01T00:00:00)\"\n        ) from None\n\n\ndef determine_query_date_range_from_events(events):\n    query_start_time_string, query_end_time_string = events[\"QueryStartTime\"], events[\"QueryEndTime\"]\n\n    if query_start_time_string == \"\" or query_end_time_string == \"\":\n        return create_query_date_range_from_now()\n    else:\n        return create_query_date_range_from_parameters(query_start_time_string, query_end_time_string)\n\n\ndef script_handler(events, context):\n    log_group = events[\"CloudWatchLogsGroup\"] if events[\"CloudWatchLogsGroup\"] != \"\" else None\n    event_puller = CloudWatchSesEventPuller(log_group)\n    event_managers = [SesEventManager(message_id) for message_id in events[\"MessageIds\"]]\n    for event_manager in event_managers:\n        event_puller.add_event_listener(event_manager)\n\n    while not are_analyses_completed(event_managers):\n        event_puller.pull(*determine_query_date_range_from_events(events))\n\n    message_generator = SesDeliveryStatusMessageGenerator()\n    message = \"\\n\\n\\n\".join([message_generator.to_message(event_manager) for event_manager in event_managers])\n    if are_feedbacks_received(event_managers):\n        message += \"\\n\\n\" + create_recommendations_message(event_managers)\n\n    return {\"ResultMessage\": message}\n"
      },
      "outputs": [
        {
          "Name": "ResultMessage",
          "Selector": "$.Payload.ResultMessage",
          "Type": "String"
        }
      ]
    },
    {
      "name": "OutputFailureReason",
      "description": "Output execution step failure messages when the AnalyzeSESMessageSendingStatus step failed.",
      "action": "aws:executeScript",
      "isEnd": true,
      "onFailure": "Abort",
      "inputs": {
        "Runtime": "python3.11",
        "Handler": "script_handler",
        "Script": "from boto3 import client as boto3_client\n\nSTEP_NAME = \"AnalyzeSesEvents\"\nSCRIPT_EXECUTION_TIMEOUT_ERROR = \"Script execution times out\"\nNEXT_ACTION_MESSAGE_TIMEOUT = \"Please reduce the query time range with the automation parameters QueryStartTime and QueryEndTime, and run this runbook again.\"\nNEXT_ACTION_MESSAGE_OTHER_REASONS = \"Please run this runbook again.\"\n\n\ndef filter_step_execution_result_by_step_name(execution_result, step_name):\n    step_executions = execution_result[\"AutomationExecution\"][\"StepExecutions\"]\n\n    return list(filter(lambda step_execution: step_execution[\"StepName\"] == step_name, step_executions))\n\n\ndef get_step_failure_details(automation_execution_id, step_name):\n    ssm_client = boto3_client(\"ssm\")\n    try:\n        execution_result = ssm_client.get_automation_execution(AutomationExecutionId=automation_execution_id)\n    except (ssm_client.exceptions.AutomationExecutionNotFoundException, ssm_client.exceptions.InternalServerError):\n        return \"Unknown error\"\n\n    step_execution_results = filter_step_execution_result_by_step_name(execution_result, step_name)\n    if not step_execution_results or step_execution_results[0][\"StepStatus\"] != \"Failed\":\n        return \"Unknown error\"\n\n    return step_execution_results[0][\"FailureDetails\"][\"Details\"][\"VerificationErrorMessage\"][0]\n\n\ndef create_error_message(step_failure_detail_message, step_name, automation_execution_id):\n    message_prefix = f'We received an error(\"{step_failure_detail_message}\") at the execution step {step_name}. '\n    if step_failure_detail_message == SCRIPT_EXECUTION_TIMEOUT_ERROR:\n        next_action_message = NEXT_ACTION_MESSAGE_TIMEOUT\n    elif step_failure_detail_message == \"Unknown error\":\n        next_action_message = f\"Please check the automation execution {automation_execution_id} for the further detail.\"\n    else:\n        next_action_message = NEXT_ACTION_MESSAGE_OTHER_REASONS\n\n    return f\"{message_prefix} {next_action_message}\"\n\n\ndef script_handler(events, context):\n    automation_execution_id = context[\"automation:EXECUTION_ID\"]\n    failure_details = get_step_failure_details(automation_execution_id, STEP_NAME)\n\n    return {\"FailureReason\": create_error_message(failure_details, STEP_NAME, automation_execution_id)}\n"
      },
      "outputs": [
        {
          "Type": "String",
          "Name": "FailureReason",
          "Selector": "$.Payload.FailureReason"
        }
      ]
    }
  ],
  "outputs": [
    "AnalyzeSesEvents.ResultMessage",
    "OutputFailureReason.FailureReason"
  ]
}
