{
  "description": "The **AWSSupport-TroubleshootOpenSearchRedYellowCluster** runbook helps troubleshoot Amazon OpenSearch [red cluster](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/handling-errors.html#handling-errors-red-cluster-status) and [yellow cluster](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/handling-errors.html#handling-errors-yellow-cluster-status) status issues.\nThe runbook performs the following steps:\n\n> * Calls the [`DescribeDomain`](https://docs.aws.amazon.com/opensearch-service/latest/APIReference/API_DescribeDomain.html) API against the target OpenSearch Service domain to get the cluster configuration.\n> * Checks whether the domain is public or virtual private cloud (VPC) based.\n> * Creates a public or [VPC based](https://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html) AWS Lambda function using an AWS CloudFormation stack. If the domain is VPC-based, the AWS Lambda is created in the OpenSearch VPC to allow network connectivity. The AWS Lambda function will contain the troubleshooting code that executes the `GET Elasticsearch/OpenSearch` APIs against the cluster to try to determine why the cluster is in yellow or red state.\n> * Deletes the AWS CloudFormation stack used to create the AWS Lambda function.\n> * Displays the checks performed and the recommended steps to resolve the red or yellow cluster issue.\n\n## This runbook performs the following checks:\n> * **Cluster Connectivity:** Checks for successful connection to the cluster (2xx response).\n> * **Cluster Health:** Checks the current cluster health status.\n> * **Resource utilization:** Checks the cluster CPU and JVM memory pressure utilization.\n> * **Storage Space:** Checks if there is sufficient storage space in the cluster.\n> * **Allocation Explain:** Checks the reason for allocation is failing.\n\n## Elasticsearch/OpenSearch APIs used in this runbook:\n- [`GET _cluster/health`](https://opensearch.org/docs/latest/opensearch/rest-api/cluster-health/)\n- [`GET _cat/allocation`](https://opensearch.org/docs/latest/opensearch/rest-api/cat/cat-allocation/)\n- [`GET _cluster/allocation/explain`](https://opensearch.org/docs/latest/opensearch/rest-api/cluster-allocation/)\n- [`GET _cat/indices`](https://opensearch.org/docs/latest/api-reference/cat/cat-indices/)\n\n#### Important:\n> * This runbook creates an AWS Lambda function in your account to call the Elasticsearch/OpenSearch APIs. See [AWS Lambda Pricing](https://aws.amazon.com/lambda/pricing/) for pricing information.\n> * The `LambdaExecutionRole` Lambda execution role requires the `es:ESHttpGet` IAM permission in order to access the OpenSearch HTTP methods. For more information see [Identity and Access Management in Amazon OpenSearch Service](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ac.html)\n> * If the OpenSearch cluster is VPC-based, the `LambdaExecutionRole` Lambda execution role also requires the `ec2:DescribeNetworkInterfaces`, `ec2:CreateNetworkInterface`, and `ec2:DeleteNetworkInterface` IAM permissions in order to create and manage the VPC network interfaces. For more information see [Connecting outbound networking to resources in a VPC](https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-permissions) and [Lambda execution role](https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html).",
  "schemaVersion": "0.3",
  "assumeRole": "{{ AutomationAssumeRole }}",
  "parameters": {
    "AutomationAssumeRole": {
      "type": "AWS::IAM::Role::Arn",
      "description": "(Optional) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf. If no role is specified, Systems Manager Automation uses the permissions of the user that starts this runbook.",
      "default": ""
    },
    "LambdaExecutionRole": {
      "type": "AWS::IAM::Role::Arn",
      "description": "(Required) The ARN of the IAM role that the AWS Lambda function will use to sign requests to your Amazon OpenSearch Service cluster."
    },
    "DomainName": {
      "type": "String",
      "description": "(Required) The name of the Amazon OpenSearch Service domain is red or yellow status.",
      "allowedPattern": "^[a-z]{1}[a-z0-9-]{2,28}$",
      "maxChars": 29
    },
    "UtilizationThreshold": {
      "type": "Integer",
      "description": "(Optional) The utilization threshold in percentage used to compare the `CPUUtilization` and `JVMMemoryPressure` metrics. Default value is `80`.",
      "allowedPattern": "^[1-9]?[0-9]$",
      "default": 80
    }
  },
  "mainSteps": [
    {
      "name": "GetClusterConfiguration",
      "action": "aws:executeScript",
      "description": "Gets the Amazon OpenSearch service cluster configuration.",
      "timeoutSeconds": 600,
      "inputs": {
        "Handler": "get_cluster_config.fetch_cluster_config",
        "InputPayload": {
          "DomainName": "{{ DomainName }}"
        },
        "Attachment": "artifact.zip",
        "Runtime": "python3.11"
      },
      "outputs": [
        {
          "Name": "SubnetIds",
          "Selector": "$.Payload.SubnetIds",
          "Type": "String"
        },
        {
          "Name": "SecurityGroupIds",
          "Selector": "$.Payload.SecurityGroupIds",
          "Type": "String"
        },
        {
          "Name": "VpcId",
          "Selector": "$.Payload.VpcId",
          "Type": "String"
        },
        {
          "Name": "DescribeOutput",
          "Selector": "$.Payload",
          "Type": "StringMap"
        }
      ],
      "nextStep": "CreateAWSLambdaFunctionStack",
      "onFailure": "Abort"
    },
    {
      "name": "CreateAWSLambdaFunctionStack",
      "action": "aws:createStack",
      "description": "Creates a temporary AWS Lambda function in your account using AWS CloudFormation. The Lambda function is used to execute the `GET Elasticsearch/OpenSearch` APIs.",
      "maxAttempts": 1,
      "inputs": {
        "StackName": "AWSSupport-TroubleshootOpenSearchRedYellowCluster-{{ automation:EXECUTION_ID }}",
        "TemplateBody": "AWSTemplateFormatVersion: 2010-09-09\nDescription: CloudFormation Stack to create an AWS Lambda function.\nParameters:\n  LambdaName:\n    Description: Name of the Lambda function\n    Type: String\n    Default: AWSSupport-Automation-RedYellowCluster\n  VpcId:\n    Description: VPC Id of the OpenSearch cluster\n    Type: String\n  SubnetIds:\n    Description: Comma separated list of subnet Ids.\n    Type: CommaDelimitedList\n  SecurityGroupIds:\n    Description: Comma seperated list of Security Group Ids.\n    Type: CommaDelimitedList\n  LambdaExecutionRole:\n    Description: Lambda Execution Role to be assumed by Lambda to run the code.\n    Type: String\nConditions:\n  UseVpc: !Not\n  - !Equals\n    - !Ref VpcId\n    - ''\nResources:\n  Function:\n    Type: AWS::Lambda::Function\n    Properties:\n      FunctionName: !Ref LambdaName\n      Handler: index.main\n      Role: !Ref LambdaExecutionRole\n      Code:\n        ZipFile: \"import http.client\\n\\nimport json\\n\\nimport os\\n\\nfrom urllib.parse\\\n          \\ import urlparse\\n\\n\\n\\nimport botocore.session\\n\\nfrom botocore.auth import\\\n          \\ SigV4Auth\\n\\nfrom botocore.awsrequest import AWSRequest\\n\\nfrom botocore.exceptions\\\n          \\ import ClientError\\n\\n\\n\\nsession = botocore.session.Session()\\n\\n\\n\\n\\\n          \\n\\ndef request_opensearch(domain_endpoint, region, path=\\\"\\\", filters=\\\"\\\n          \\\"):\\n\\n    sigv4 = SigV4Auth(session.get_credentials(), \\\"es\\\", region)\\n\\\n          \\n    endpoint = domain_endpoint + path + filters\\n\\n    request = AWSRequest(method=\\\"\\\n          GET\\\", url=endpoint)\\n\\n    sigv4.add_auth(request)\\n\\n    prepped = request.prepare()\\n\\\n          \\n\\n\\n    url_parse = urlparse(endpoint)\\n\\n    path_and_query = url_parse.path\\\n          \\ if url_parse.query is None else url_parse.path + \\\"?\\\" + url_parse.query\\n\\\n          \\n    connection = http.client.HTTPSConnection(url_parse.hostname, timeout=5)\\\n          \\  # nosec B309\\n\\n    connection.request(prepped.method, path_and_query,\\\n          \\ headers=prepped.headers)\\n\\n    response = connection.getresponse()\\n\\n\\\n          \\    return {\\\"status_code\\\": response.status, \\\"response_text\\\": json.loads(response.read().decode())}\\n\\\n          \\n\\n\\n\\n\\ndef check_cluster_connectivity(\\n\\n    domain_endpoint,\\n\\n  \\\n          \\  region,\\n\\n    domain_es_version,\\n\\n    domain_name,\\n\\n    desired_data_node_count,\\n\\\n          \\n    resource_utilisation,\\n\\n    cw_agent_healthy,\\n\\n    lambda_execution_role,\\n\\\n          \\n):\\n\\n    \\\"\\\"\\\"This function is used to establish connection with the\\\n          \\ cluster\\\"\\\"\\\"\\n\\n    try:\\n\\n        response = request_opensearch(domain_endpoint=domain_endpoint,\\\n          \\ region=region)\\n\\n        if response.get(\\\"status_code\\\") == 200:\\n\\n\\\n          \\            return get_cluster_health(\\n\\n                domain_endpoint=domain_endpoint,\\n\\\n          \\n                region=region,\\n\\n                domain_es_version=domain_es_version,\\n\\\n          \\n                domain_name=domain_name,\\n\\n                desired_data_node_count=desired_data_node_count,\\n\\\n          \\n                resource_utilisation=resource_utilisation,\\n\\n       \\\n          \\         cw_agent_healthy=cw_agent_healthy,\\n\\n            )\\n\\n      \\\n          \\  elif response.get(\\\"status_code\\\") == 403:\\n\\n            if \\\"security_exception\\\"\\\n          \\ in json.dumps(response.get(\\\"response_text\\\")):\\n\\n                return\\\n          \\ generate_response(\\n\\n                    domain_name=domain_name,\\n\\n\\\n          \\                    reason_code=\\\"connection_failed_insufficient_fgac_permissions\\\"\\\n          ,\\n\\n                    connection_status_code=response.get(\\\"status_code\\\"\\\n          ),\\n\\n                    error_message=response.get(\\\"response_text\\\"),\\n\\\n          \\n                    lambda_execution_role=lambda_execution_role,\\n\\n \\\n          \\               )\\n\\n            elif \\\"is not authorized to perform\\\" in\\\n          \\ json.dumps(response.get(\\\"response_text\\\")):\\n\\n                return\\\n          \\ generate_response(\\n\\n                    domain_name=domain_name,\\n\\n\\\n          \\                    reason_code=\\\"connection_failed_insufficient_iam_permissions\\\"\\\n          ,\\n\\n                    connection_status_code=response.get(\\\"status_code\\\"\\\n          ),\\n\\n                    error_message=response.get(\\\"response_text\\\"),\\n\\\n          \\n                    lambda_execution_role=lambda_execution_role,\\n\\n \\\n          \\               )\\n\\n            return generate_response(\\n\\n         \\\n          \\       domain_name=domain_name,\\n\\n                reason_code=\\\"http_error_while_running_automation\\\"\\\n          ,\\n\\n                connection_status_code=response.get(\\\"status_code\\\"\\\n          ),\\n\\n                error_message=response.get(\\\"response_text\\\"),\\n\\n\\\n          \\            )\\n\\n        else:\\n\\n            # Any other status code.\\\n          \\ This should be unlikely.\\n\\n            return generate_response(\\n\\n\\\n          \\                domain_name=domain_name,\\n\\n                reason_code=\\\"\\\n          http_error_while_running_automation\\\",\\n\\n                connection_status_code=response.get(\\\"\\\n          status_code\\\"),\\n\\n                error_message=response.get(\\\"response_text\\\"\\\n          ),\\n\\n            )\\n\\n    except (\\n\\n        http.client.HTTPException,\\n\\\n          \\n        http.client.IncompleteRead,\\n\\n        http.client.ImproperConnectionState,\\n\\\n          \\n        http.client.CannotSendRequest,\\n\\n        http.client.CannotSendHeader,\\n\\\n          \\n        http.client.ResponseNotReady,\\n\\n        http.client.BadStatusLine,\\n\\\n          \\n        http.client.LineTooLong,\\n\\n        http.client.RemoteDisconnected,\\n\\\n          \\n        AttributeError,\\n\\n        TypeError,\\n\\n        ClientError,\\n\\\n          \\n        Exception,\\n\\n    ) as exception:\\n\\n        return generate_response(\\n\\\n          \\n            domain_name=domain_name,\\n\\n            reason_code=\\\"error_running_automation\\\"\\\n          ,\\n\\n            connection_status_code=\\\"500\\\",\\n\\n            error=str(exception),\\n\\\n          \\n        )\\n\\n\\n\\n\\n\\ndef get_cluster_health(\\n\\n    domain_endpoint,\\n\\\n          \\n    region,\\n\\n    domain_es_version,\\n\\n    domain_name,\\n\\n    desired_data_node_count,\\n\\\n          \\n    resource_utilisation,\\n\\n    cw_agent_healthy,\\n\\n):\\n\\n    \\\"\\\"\\\"\\\n          This function is used to fetch the cluster health using get request\\\"\\\"\\\"\\\n          \\n\\n    path = \\\"_cluster/health\\\"  # the OpenSearch API endpoint\\n\\n  \\\n          \\  try:\\n\\n        cluster_health = request_opensearch(domain_endpoint=domain_endpoint,\\\n          \\ region=region, path=path)\\n\\n        cluster_health_status = cluster_health.get(\\\"\\\n          response_text\\\")[\\\"status\\\"]\\n\\n        current_data_node_count = cluster_health.get(\\\"\\\n          response_text\\\")[\\\"number_of_data_nodes\\\"]\\n\\n        if cluster_health_status\\\n          \\ == \\\"green\\\":\\n\\n            return green(domain_name=domain_name, region=region,\\\n          \\ cw_agent_healthy=cw_agent_healthy)\\n\\n        elif cluster_health_status\\\n          \\ == \\\"yellow\\\":\\n\\n            return yellow(\\n\\n                domain_endpoint=domain_endpoint,\\n\\\n          \\n                region=region,\\n\\n                domain_es_version=domain_es_version,\\n\\\n          \\n                domain_name=domain_name,\\n\\n                desired_data_node_count=desired_data_node_count,\\n\\\n          \\n                current_data_node_count=current_data_node_count,\\n\\n \\\n          \\               resource_utilisation=resource_utilisation,\\n\\n         \\\n          \\   )\\n\\n        elif cluster_health_status == \\\"red\\\":\\n\\n            return\\\n          \\ red(\\n\\n                domain_endpoint=domain_endpoint,\\n\\n         \\\n          \\       region=region,\\n\\n                domain_es_version=domain_es_version,\\n\\\n          \\n                domain_name=domain_name,\\n\\n                desired_data_node_count=desired_data_node_count,\\n\\\n          \\n                current_data_node_count=current_data_node_count,\\n\\n \\\n          \\               resource_utilisation=resource_utilisation,\\n\\n         \\\n          \\   )\\n\\n    except (\\n\\n        http.client.HTTPException,\\n\\n        http.client.IncompleteRead,\\n\\\n          \\n        http.client.ImproperConnectionState,\\n\\n        http.client.CannotSendRequest,\\n\\\n          \\n        http.client.CannotSendHeader,\\n\\n        http.client.ResponseNotReady,\\n\\\n          \\n        http.client.BadStatusLine,\\n\\n        http.client.LineTooLong,\\n\\\n          \\n        http.client.RemoteDisconnected,\\n\\n        AttributeError,\\n\\n\\\n          \\        TypeError,\\n\\n        ClientError,\\n\\n        Exception,\\n\\n  \\\n          \\  ) as exception:\\n\\n        return generate_response(\\n\\n            domain_name=domain_name,\\n\\\n          \\n            reason_code=\\\"error_running_automation\\\",\\n\\n            connection_status_code=\\\"\\\n          500\\\",\\n\\n            error=str(exception),\\n\\n        )\\n\\n\\n\\n\\n\\ndef\\\n          \\ green(domain_name, region, cw_agent_healthy):\\n\\n    if not cw_agent_healthy:\\n\\\n          \\n        return generate_response(domain_name=domain_name, reason_code=\\\"\\\n          cw_agent_unhealthy\\\", connection_status_code=200)\\n\\n    return generate_response(domain_name=domain_name,\\\n          \\ reason_code=\\\"green_cluster_no_issue\\\", connection_status_code=200)\\n\\n\\\n          \\n\\n\\n\\ndef yellow(\\n\\n    domain_endpoint,\\n\\n    region,\\n\\n    domain_es_version,\\n\\\n          \\n    domain_name,\\n\\n    desired_data_node_count,\\n\\n    current_data_node_count,\\n\\\n          \\n    resource_utilisation,\\n\\n):\\n\\n    try:\\n\\n        node_drop = check_node_drop(desired_data_node_count,\\\n          \\ current_data_node_count)\\n\\n        if node_drop == \\\"nodeDrop\\\":\\n\\n\\\n          \\            if resource_utilisation == \\\"highCPUAndJVMMP\\\":\\n\\n       \\\n          \\         return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"resource_utilisation_too_high\\\",\\n\\n\\\n          \\                    connection_status_code=200,\\n\\n                   \\\n          \\ cluster_health=\\\"yellow\\\",\\n\\n                )\\n\\n            elif resource_utilisation\\\n          \\ == \\\"highCPU\\\":\\n\\n                return generate_response(\\n\\n     \\\n          \\               domain_name=domain_name,\\n\\n                    reason_code=\\\"\\\n          cpu_utilisation_too_high\\\",\\n\\n                    connection_status_code=200,\\n\\\n          \\n                    cluster_health=\\\"yellow\\\",\\n\\n                )\\n\\n\\\n          \\            elif resource_utilisation == \\\"highJVMMP\\\":\\n\\n           \\\n          \\     return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"jvm_mp_too_high\\\",\\n\\n             \\\n          \\       connection_status_code=200,\\n\\n                    cluster_health=\\\"\\\n          yellow\\\",\\n\\n                )\\n\\n        else:\\n\\n            if node_drop\\\n          \\ == \\\"nodeCountNormal\\\":\\n\\n                if current_data_node_count\\\n          \\ == 1:\\n\\n                    return generate_response(\\n\\n           \\\n          \\             domain_name=domain_name, reason_code=\\\"yellow_cluster_single_node\\\"\\\n          , connection_status_code=200\\n\\n                    )\\n\\n              \\\n          \\  elif check_extra_replica(\\n\\n                    domain_endpoint=domain_endpoint,\\\n          \\ region=region, desired_data_node_count=desired_data_node_count\\n\\n   \\\n          \\             ):\\n\\n                    return generate_response(\\n\\n  \\\n          \\                      domain_name=domain_name, reason_code=\\\"yellow_cluster_extra_replica\\\"\\\n          , connection_status_code=200\\n\\n                    )\\n\\n            processing\\\n          \\ = False\\n\\n            if node_drop == \\\"processing\\\":\\n\\n           \\\n          \\     processing = True\\n\\n            sufficient_free_storage_space = check_storage(domain_endpoint=domain_endpoint,\\\n          \\ region=region)\\n\\n            if not sufficient_free_storage_space:\\n\\n\\\n          \\                return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"insufficient_free_storage_space\\\",\\n\\\n          \\n                    connection_status_code=200,\\n\\n                  \\\n          \\  cluster_health=\\\"yellow\\\",\\n\\n                    processing=processing,\\n\\\n          \\n                )\\n\\n            else:\\n\\n                if \\\"Elasticsearch_1.5\\\"\\\n          \\ == domain_es_version or \\\"Elasticsearch_2.3\\\" == domain_es_version:\\n\\n\\\n          \\                    return generate_response(\\n\\n                     \\\n          \\   domain_name=domain_name,\\n\\n                        reason_code=\\\"allocation_explain_not_supported\\\"\\\n          ,\\n\\n                        connection_status_code=200,\\n\\n           \\\n          \\             cluster_health=\\\"yellow\\\",\\n\\n                        domain_es_version=domain_es_version,\\n\\\n          \\n                        processing=processing,\\n\\n                   \\\n          \\ )\\n\\n                else:\\n\\n                    allocation_explain =\\\n          \\ check_allocation_explain(domain_endpoint=domain_endpoint, region=region)\\n\\\n          \\n                    if \\\"shard has exceeded the maximum number of retries\\\"\\\n          \\ in json.dumps(allocation_explain):\\n\\n                        return generate_response(\\n\\\n          \\n                            domain_name=domain_name,\\n\\n             \\\n          \\               reason_code=\\\"shard_exceeded_max_retries\\\",\\n\\n        \\\n          \\                    connection_status_code=200,\\n\\n                   \\\n          \\         cluster_health=\\\"yellow\\\",\\n\\n                            processing=processing,\\n\\\n          \\n                        )\\n\\n                    else:\\n\\n           \\\n          \\             return generate_response(\\n\\n                            domain_name=domain_name,\\n\\\n          \\n                            reason_code=\\\"allocation_explain\\\",\\n\\n  \\\n          \\                          connection_status_code=200,\\n\\n             \\\n          \\               cluster_health=\\\"yellow\\\",\\n\\n                         \\\n          \\   processing=processing,\\n\\n                            allocation_explain=allocation_explain[\\\"\\\n          allocate_explanation\\\"],\\n\\n                        )\\n\\n    except (\\n\\n\\\n          \\        http.client.HTTPException,\\n\\n        http.client.IncompleteRead,\\n\\\n          \\n        http.client.ImproperConnectionState,\\n\\n        http.client.CannotSendRequest,\\n\\\n          \\n        http.client.CannotSendHeader,\\n\\n        http.client.ResponseNotReady,\\n\\\n          \\n        http.client.BadStatusLine,\\n\\n        http.client.LineTooLong,\\n\\\n          \\n        http.client.RemoteDisconnected,\\n\\n        AttributeError,\\n\\n\\\n          \\        TypeError,\\n\\n        ClientError,\\n\\n        Exception,\\n\\n  \\\n          \\  ) as exception:\\n\\n        return generate_response(\\n\\n            domain_name=domain_name,\\n\\\n          \\n            reason_code=\\\"error_running_automation\\\",\\n\\n            connection_status_code=\\\"\\\n          500\\\",\\n\\n            error=str(exception),\\n\\n        )\\n\\n\\n\\n\\n\\ndef\\\n          \\ red(\\n\\n    domain_endpoint,\\n\\n    region,\\n\\n    domain_es_version,\\n\\\n          \\n    domain_name,\\n\\n    desired_data_node_count,\\n\\n    current_data_node_count,\\n\\\n          \\n    resource_utilisation,\\n\\n):\\n\\n    try:\\n\\n        node_drop = check_node_drop(desired_data_node_count,\\\n          \\ current_data_node_count)\\n\\n        if node_drop == \\\"nodeDrop\\\":\\n\\n\\\n          \\            if resource_utilisation == \\\"highCPUAndJVMMP\\\":\\n\\n       \\\n          \\         return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"resource_utilisation_too_high\\\",\\n\\n\\\n          \\                    connection_status_code=200,\\n\\n                   \\\n          \\ cluster_health=\\\"red\\\",\\n\\n                )\\n\\n            elif resource_utilisation\\\n          \\ == \\\"highCPU\\\":\\n\\n                return generate_response(\\n\\n     \\\n          \\               domain_name=domain_name,\\n\\n                    reason_code=\\\"\\\n          cpu_utilisation_too_high\\\",\\n\\n                    connection_status_code=200,\\n\\\n          \\n                    cluster_health=\\\"red\\\",\\n\\n                )\\n\\n \\\n          \\           elif resource_utilisation == \\\"highJVMMP\\\":\\n\\n            \\\n          \\    return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"jvm_mp_too_high\\\",\\n\\n             \\\n          \\       connection_status_code=200,\\n\\n                    cluster_health=\\\"\\\n          red\\\",\\n\\n                )\\n\\n        else:\\n\\n            processing =\\\n          \\ False\\n\\n            if node_drop == \\\"processing\\\":\\n\\n             \\\n          \\   processing = True\\n\\n            sufficient_free_storage_space = check_storage(domain_endpoint=domain_endpoint,\\\n          \\ region=region)\\n\\n            if not sufficient_free_storage_space:\\n\\n\\\n          \\                return generate_response(\\n\\n                    domain_name=domain_name,\\n\\\n          \\n                    reason_code=\\\"insufficient_free_storage_space\\\",\\n\\\n          \\n                    connection_status_code=200,\\n\\n                  \\\n          \\  cluster_health=\\\"red\\\",\\n\\n                    processing=processing,\\n\\\n          \\n                )\\n\\n            else:\\n\\n                if \\\"Elasticsearch_1.5\\\"\\\n          \\ == domain_es_version or \\\"Elasticsearch_2.3\\\" == domain_es_version:\\n\\n\\\n          \\                    return generate_response(\\n\\n                     \\\n          \\   domain_name=domain_name,\\n\\n                        reason_code=\\\"allocation_explain_not_supported\\\"\\\n          ,\\n\\n                        connection_status_code=200,\\n\\n           \\\n          \\             cluster_health=\\\"red\\\",\\n\\n                        domain_es_version=domain_es_version,\\n\\\n          \\n                        processing=processing,\\n\\n                   \\\n          \\ )\\n\\n                else:\\n\\n                    allocation_explain =\\\n          \\ check_allocation_explain(domain_endpoint=domain_endpoint, region=region)\\n\\\n          \\n                    if \\\"shard has exceeded the maximum number of retries\\\"\\\n          \\ in json.dumps(allocation_explain):\\n\\n                        return generate_response(\\n\\\n          \\n                            domain_name=domain_name,\\n\\n             \\\n          \\               reason_code=\\\"shard_exceeded_max_retries\\\",\\n\\n        \\\n          \\                    connection_status_code=200,\\n\\n                   \\\n          \\         cluster_health=\\\"red\\\",\\n\\n                            processing=processing,\\n\\\n          \\n                        )\\n\\n                    else:\\n\\n           \\\n          \\             return generate_response(\\n\\n                            domain_name=domain_name,\\n\\\n          \\n                            reason_code=\\\"allocation_explain\\\",\\n\\n  \\\n          \\                          connection_status_code=200,\\n\\n             \\\n          \\               cluster_health=\\\"red\\\",\\n\\n                            processing=processing,\\n\\\n          \\n                            allocation_explain=allocation_explain[\\\"allocate_explanation\\\"\\\n          ],\\n\\n                        )\\n\\n    except (\\n\\n        http.client.HTTPException,\\n\\\n          \\n        http.client.IncompleteRead,\\n\\n        http.client.ImproperConnectionState,\\n\\\n          \\n        http.client.CannotSendRequest,\\n\\n        http.client.CannotSendHeader,\\n\\\n          \\n        http.client.ResponseNotReady,\\n\\n        http.client.BadStatusLine,\\n\\\n          \\n        http.client.LineTooLong,\\n\\n        http.client.RemoteDisconnected,\\n\\\n          \\n        AttributeError,\\n\\n        TypeError,\\n\\n        ClientError,\\n\\\n          \\n        Exception,\\n\\n    ) as exception:\\n\\n        return generate_response(\\n\\\n          \\n            domain_name=domain_name,\\n\\n            reason_code=\\\"error_running_automation\\\"\\\n          ,\\n\\n            connection_status_code=\\\"500\\\",\\n\\n            error=str(exception),\\n\\\n          \\n        )\\n\\n\\n\\n\\n\\ndef check_storage(domain_endpoint, region):\\n\\n \\\n          \\   \\\"\\\"\\\"This function is used get the storage on each node by executing\\\n          \\ the _cat/allocation api call\\\"\\\"\\\"\\n\\n    path = \\\"_cat/allocation\\\" \\\n          \\ # the OpenSearch API endpoint\\n\\n    filters = \\\"?format=json&bytes=b\\\"\\\n          \\n\\n\\n\\n    response = request_opensearch(domain_endpoint=domain_endpoint,\\\n          \\ region=region, path=path, filters=filters)\\n\\n    # When using 'bytes=b'\\\n          \\ as a query parameter, the result is a little bit off because the docs\\\n          \\ say \\\"these units use powers of 1024, so 1kb means 1024 bytes\\\". So for\\\n          \\ my node 9.7gb becomes 10434662400 bytes, which is 10.43gb.\\n\\n    # https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#byte-units\\n\\\n          \\n    # Checking if one of the nodes is low on free storage space\\n\\n  \\\n          \\  nodes_with_low_storage = 0\\n\\n    for node in response.get(\\\"response_text\\\"\\\n          ):\\n\\n        # Getting rid of the entry that contains the unassigned shards\\\n          \\ as it is not relevant for the free storage space of the nodes\\n\\n    \\\n          \\    if node[\\\"node\\\"] != \\\"UNASSIGNED\\\":\\n\\n            # Saying the storage\\\n          \\ is low if below 1gb (1073741824 bytes)\\n\\n            if int(node[\\\"disk.avail\\\"\\\n          ]) < 1073741824:\\n\\n                nodes_with_low_storage += 1\\n\\n\\n\\n\\\n          \\    if nodes_with_low_storage > 0:\\n\\n        return False\\n\\n    return\\\n          \\ True\\n\\n\\n\\n\\n\\ndef check_allocation_explain(domain_endpoint, region):\\n\\\n          \\n    \\\"\\\"\\\"This function is used to fetch the _cluster/allocation/explain\\n\\\n          \\n    to determine the cause of unassigned shards\\\"\\\"\\\"\\n\\n    path = \\\"\\\n          _cluster/allocation/explain\\\"  # the OpenSearch API endpoint\\n\\n\\n\\n   \\\n          \\ response = request_opensearch(\\n\\n        domain_endpoint=domain_endpoint,\\\n          \\ region=region, path=path\\n\\n    )  # requests.get, post, and delete have\\\n          \\ similar syntax\\n\\n\\n\\n    if response.get(\\\"response_text\\\", {}).get(\\\"\\\n          current_state\\\", \\\"\\\") == \\\"unassigned\\\":\\n\\n        return response.get(\\\"\\\n          response_text\\\")\\n\\n    return {\\\"allocate_explanation\\\": \\\"All shards are\\\n          \\ assigned.\\\"}\\n\\n\\n\\n\\n\\ndef check_extra_replica(domain_endpoint, region,\\\n          \\ desired_data_node_count):\\n\\n    \\\"\\\"\\\"This function is used to fetch\\\n          \\ the _cat/indices\\n\\n    to get the count of number of replica shards\\\"\\\n          \\\"\\\"\\n\\n    path = \\\"_cat/indices\\\"  # the OpenSearch API endpoint to find\\\n          \\ the yellow indices\\n\\n    filters = \\\"?format=json&health=yellow\\\"\\n\\n\\\n          \\n\\n    response = request_opensearch(\\n\\n        domain_endpoint=domain_endpoint,\\\n          \\ region=region, path=path, filters=filters\\n\\n    )  # requests.get, post,\\\n          \\ and delete have similar syntax\\n\\n\\n\\n    # Checking if any of the index\\\n          \\ is configured with more number of replics then the number of data nodes\\\n          \\ configured.\\n\\n    extra_replica_configured = 0\\n\\n    for index in response.get(\\\"\\\n          response_text\\\"):\\n\\n        if float(index[\\\"rep\\\"]) >= desired_data_node_count:\\n\\\n          \\n            extra_replica_configured += 1\\n\\n\\n\\n    if extra_replica_configured\\\n          \\ > 0:\\n\\n        return True\\n\\n    return False\\n\\n\\n\\n\\n\\ndef check_node_drop(desired_data_node_count,\\\n          \\ current_data_node_count):\\n\\n    \\\"\\\"\\\"This function is used to compare\\\n          \\ the desired_data_node_count which\\n\\n    is fetched from the cluster configuration\\\n          \\ and current_data_node_count\\n\\n    which is fetched from the get_cluster_health()\\\n          \\ funtion\\\"\\\"\\\"\\n\\n    if desired_data_node_count > current_data_node_count:\\n\\\n          \\n        return \\\"nodeDrop\\\"\\n\\n    elif desired_data_node_count < current_data_node_count:\\n\\\n          \\n        # Cluster is processing a b/g.\\n\\n        return \\\"processing\\\"\\\n          \\n\\n    else:\\n\\n        return \\\"nodeCountNormal\\\"\\n\\n\\n\\n\\n\\ndef generate_response(\\n\\\n          \\n    domain_name,\\n\\n    reason_code,\\n\\n    connection_status_code,\\n\\n\\\n          \\    error_message=None,\\n\\n    lambda_execution_role=None,\\n\\n    cluster_health=None,\\n\\\n          \\n    processing=False,\\n\\n    allocation_explain=None,\\n\\n    domain_es_version=None,\\n\\\n          \\n    error=\\\"\\\",\\n\\n):\\n\\n    cluster_processing = \\\"\\\"\\n\\n\\n\\n    if processing:\\n\\\n          \\n        cluster_processing = f\\\"\\\\n\\\\nIn addition to the above, your cluster's\\\n          \\ node count is higher than its target node count and currently the domain\\\n          \\ seems to be in Processing state. Please use the above advise to resolve\\\n          \\ the cluster's {cluster_health} status. Further, if you do not see the\\\n          \\ cluster in Active status after some time, and the shard migration from\\\n          \\ the cluster's old environment to its new environment is making no progress,\\\n          \\ please reach out to AWS support for assistance.\\\\n\\\\nYou can monitor the\\\n          \\ shard movement of the cluster's blue/green deployment process using the\\\n          \\ below commands:\\\\nGET /_cat/allocation - This provides a snapshot of the\\\n          \\ number of shards allocated to each data node along with their disk space\\\n          \\ details.\\\\nGET /_cat/recovery - It returns information about ongoing and\\\n          \\ completed shard recoveries.\\\\nGET _cluster/health - This API returns a\\\n          \\ simple status on the health of the cluster and it also includes information\\\n          \\ about how many shards are in active, relocating, initializing, and unassigned.\\\"\\\n          \\n\\n\\n\\n    response = {\\n\\n        \\\"connection_failed_insufficient_fgac_permissions\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Failed to establish connection because\\\n          \\ of insufficient permission at FGAC layer\\\",\\n\\n            \\\"description\\\"\\\n          : f\\\"Unfortunately, an issue occurred while running the SAW document for\\\n          \\ your OpenSearch cluster '{domain_name}'. While trying to connect with\\\n          \\ the cluster, the API returned a '{connection_status_code}' error code\\\n          \\ with the following message:\\\\n{error_message}\\\\nIt seems that the domain\\\n          \\ is configured with Fine Grained Access Control. Kindly retry the execution\\\n          \\ of the SAW Document after ensuring that the IAM role '{lambda_execution_role}'\\\n          \\ is mapped as a one of the backend roles which has at least 'cluster_monitor'\\\n          \\ permission. In case the issue persists, please contact AWS support for\\\n          \\ further assistance.\\\",\\n\\n        },\\n\\n        \\\"connection_failed_insufficient_iam_permissions\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Failed to establish connection because\\\n          \\ of insufficient IAM permissions\\\",\\n\\n            \\\"description\\\": f\\\"\\\n          Unfortunately, an issue occurred while running the SAW document for your\\\n          \\ OpenSearch cluster '{domain_name}'. While trying to connect with the cluster,\\\n          \\ the API returned a '{connection_status_code}' error code with the following\\\n          \\ message:\\\\n{error_message}\\\\nPlease review the IAM role '{lambda_execution_role}'\\\n          \\ provided as the 'LambdaExecutionRole', this role ensure that the SAW Document\\\n          \\ has the correct permissions to execute the relevant API calls to the OpenSearch\\\n          \\ cluster. Kindly retry the SAW document after modifying the permission.\\\n          \\ In case the issue persists, please contact AWS support for further assistance.\\\"\\\n          ,\\n\\n        },\\n\\n        \\\"issue_running_code\\\": {\\n\\n            \\\"root_cause\\\"\\\n          : \\\"Failed to execute the SAW document\\\",\\n\\n            \\\"description\\\"\\\n          : f\\\"Unfortunately, an issue occurred while running the SAW document for\\\n          \\ your OpenSearch cluster '{domain_name}'. The OpenSearch cluster's API\\\n          \\ returned a {connection_status_code} error code with the following message:\\\\\\\n          n{error_message}\\\\n Kindly retry the execution of the SAW document and if\\\n          \\ the issue persists, please contact AWS support for assistance.\\\",\\n\\n\\\n          \\        },\\n\\n        \\\"green_cluster_no_issue\\\": {\\n\\n            \\\"root_cause\\\"\\\n          : \\\"Cluster Currently in Green state\\\",\\n\\n            \\\"description\\\":\\\n          \\ f\\\"Your OpenSearch cluster '{domain_name}' is currently in green state\\\n          \\ which indicates that no shards are in unassigned state.\\\",\\n\\n       \\\n          \\ },\\n\\n        \\\"cw_agent_unhealthy\\\": {\\n\\n            \\\"root_cause\\\"\\\n          : \\\"Data points missing for Cloudwatch metrics\\\",\\n\\n            \\\"description\\\"\\\n          : f\\\"Your OpenSearch cluster '{domain_name}' is currently green state which\\\n          \\ indicates that no shards are in unassigned state. However the process\\\n          \\ which publishes the metrics to Amazon CloudWatch has missed reporting\\\n          \\ some of the data points. In order to resolve this issue, you can contact\\\n          \\ AWS support for further assistance. Alternatively if possible you can\\\n          \\ also initiate a blue green deployment blue-green deployment from your\\\n          \\ end during off business hours which would ideally fix this issue.\\\",\\n\\\n          \\n        },\\n\\n        \\\"yellow_cluster_single_node\\\": {\\n\\n          \\\n          \\  \\\"root_cause\\\": \\\"Single Node Cluster in Yellow state\\\",\\n\\n        \\\n          \\    \\\"description\\\": f\\\"Your OpenSearch cluster '{domain_name}' is currently\\\n          \\ in yellow state and has only one data node. A single node cluster would\\\n          \\ always be in yellow status if the indices are configured with replica\\\n          \\ shards. In order to bring the cluster in green state the cluster should\\\n          \\ have the number of data nodes greater than the maximum number of replicas\\\n          \\ configured for the indices.\\\",\\n\\n        },\\n\\n        \\\"yellow_cluster_extra_replica\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Cluster in yellow state because of\\\n          \\ more number of replicas which can be allocated\\\",\\n\\n            \\\"description\\\"\\\n          : f\\\"Your OpenSearch cluster '{domain_name}' is currently in yellow state\\\n          \\ and has more number of replicas shards configured than the available data\\\n          \\ nodes. In order to bring the cluster to green status, either you can consider\\\n          \\ adding more data nodes to the cluster or configure the replica shard count\\\n          \\ to less than the number of data nodes in the cluster. To change the number\\\n          \\ of replica shards for the index you can use the following query:\\\"\\n\\n\\\n          \\            + '\\\\nPUT <index-name>/_settings {\\\"index.number_of_replicas\\\"\\\n          \\ : <value-less-than-number-of-data-node>}',\\n\\n        },\\n\\n        \\\"\\\n          cpu_utilisation_too_high\\\": {\\n\\n            \\\"root_cause\\\": \\\"CPU Utilisation\\\n          \\ too high\\\",\\n\\n            \\\"description\\\": f\\\"Your OpenSearch cluster\\\n          \\ '{domain_name}' is currently in {cluster_health} state due to high CPU\\\n          \\ Utilization. This high CPU Utilization has caused one or more of the cluster’s\\\n          \\ nodes to become unavailable, thus causing the {cluster_health} status.\\\n          \\ \\\\nHigh CPU utilization isn't uncommon, but the sustained high usage has\\\n          \\ the potential to bring the domain to an unstable state. \\\\n To mitigate\\\n          \\ the aforementioned issue, it is advised to reduce the traffic to the cluster\\\n          \\ temporarily till the cluster is in a stable state or perform scaling of\\\n          \\ the cluster i.e by using larger node types or adding more data nodes.\\\n          \\ \\\\n Please note that reconfiguring a domain with a {cluster_health} cluster\\\n          \\ status can compound the problem and may lead the cluster getting stuck\\\n          \\ in the Processing state. With this in mind, it is best to reduce the CPU\\\n          \\ Utilization and give the cluster a chance to recover to green status before\\\n          \\ making a configuration change that requires a blue/green deployment. If\\\n          \\ you find that the cluster does not recover to green status after the CPU\\\n          \\ Utilization has been reduced for some time, please contact AWS Support.\\\"\\\n          ,\\n\\n        },\\n\\n        \\\"jvm_mp_too_high\\\": {\\n\\n            \\\"root_cause\\\"\\\n          : \\\"JVM Memory Pressure too high\\\",\\n\\n            \\\"description\\\": f\\\"\\\n          Your OpenSearch cluster '{domain_name}' is currently in {cluster_health}\\\n          \\ state due to high JVM Memory Pressure. This high JVM Memory Pressure has\\\n          \\ caused one or more of the cluster’s nodes to become unavailable, thus\\\n          \\ causing the {cluster_health} status.\\\\nThe cluster could encounter out\\\n          \\ of memory errors due to high JVM Memory usage. To mitigate the aforementioned\\\n          \\ issue, you can either delete some of the unused indices or perform scaling\\\n          \\ of the cluster i.e by using larger node types or adding more data nodes.\\\n          \\ By default, Amazon OpenSearch Service uses half of an instance's RAM for\\\n          \\ the Java heap, up to a maximum heap size of 32 GiB unless 'JVM heap size'\\\n          \\ is modified by Auto Tune. You can scale nodes vertically up to 64 GiB\\\n          \\ of RAM, after this point you can scale horizontally by adding more nodes.\\\\\\\n          n Please note that reconfiguring a domain with a {cluster_health} cluster\\\n          \\ status can compound the problem and may lead the cluster getting stuck\\\n          \\ in the Processing state. With this in mind, it is best to reduce the JVM\\\n          \\ Memory Pressure and give the cluster a chance to recover to green status\\\n          \\ before making a configuration change that requires a blue/green deployment.\\\\\\\n          nIf you find that the cluster does not recover to green status after the\\\n          \\ JVM Memory Pressure has been reduced for some time, please contact AWS\\\n          \\ Support.\\\",\\n\\n        },\\n\\n        \\\"resource_utilisation_too_high\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Resource Utilisation too high\\\",\\n\\n\\\n          \\            \\\"description\\\": f\\\"Your OpenSearch cluster '{domain_name}'\\\n          \\ is currently in {cluster_health} state due to high CPU Utilization and\\\n          \\ JVM Memory Pressure. This high CPU Utilization and JVM Memory Pressure\\\n          \\ has caused one or more of the cluster’s nodes to become unavailable, thus\\\n          \\ causing the {cluster_health} status.\\\\nHigh CPU utilization isn't uncommon,\\\n          \\ but the sustained high usage has the potential to bring the domain to\\\n          \\ an unstable state. Additionally, the cluster can also encounter out of\\\n          \\ memory errors due to high JVM Memory usage. To mitigate the aforementioned\\\n          \\ issue, it is advised to follow the below recommendations: \\\\n1. Try reducing\\\n          \\ the traffic to the cluster temporarily till the cluster is in a stable\\\n          \\ state temporarily. \\\\n2. You can also consider delete some of the unused\\\n          \\ indices. \\\\n3. In case if the resource utilisation is still high, as a\\\n          \\ last option you would need to perform scaling of the cluster i.e by using\\\n          \\ larger node types or adding more data nodes. \\\\nBy default, OpenSearch\\\n          \\ Service uses half of an instance's RAM for the Java heap, up to a heap\\\n          \\ size of 32 GiB unless 'JVM heap size' is modified by Auto Tune. \\\\nPlease\\\n          \\ note that reconfiguring a domain with a {cluster_health} cluster status\\\n          \\ can compound the problem and may lead the cluster getting stuck in the\\\n          \\ Processing state. With this in mind, it is best to reduce the CPU Utilization\\\n          \\ and JVM Memory Pressure and give the cluster a chance to recover to green\\\n          \\ status before making a configuration change that requires a blue/green\\\n          \\ deployment.\\\\nIf you find that the cluster does not recover to green status\\\n          \\ after the CPU Utilization and JVM Memory Pressure have been reduced for\\\n          \\ some time, please contact AWS Support.\\\",\\n\\n        },\\n\\n        \\\"\\\n          insufficient_free_storage_space\\\": {\\n\\n            \\\"root_cause\\\": \\\"Insufficent\\\n          \\ Free Storage Space\\\",\\n\\n            \\\"description\\\": f\\\"Your OpenSearch\\\n          \\ cluster '{domain_name}' is currently in {cluster_health} state as the\\\n          \\ cluster’s free storage space is too low. Please consider either deleting\\\n          \\ unused indices, or increase the data node storage space. Alternatively\\\n          \\ you can consider increasing the data node count to add more storage capacity.\\\n          \\ {cluster_processing}\\\",\\n\\n        },\\n\\n        \\\"allocation_explain\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Failed allocation attempt _cluster/allocation/explain\\\"\\\n          ,\\n\\n            \\\"description\\\": f\\\"Your OpenSearch cluster '{domain_name}'\\\n          \\ is currently in {cluster_health} state and has the following reason for\\\n          \\ having unassigned shard(s): \\\\n {allocation_explain} \\\\n To get the complete\\\n          \\ output for the unassigned shard, you can use the following query: \\\\nGET\\\n          \\ _cluster/allocation/explain \\\\nFor assistance in getting back the cluster\\\n          \\ to green state, kindly contact AWS Support with the above details {cluster_processing}\\\"\\\n          ,\\n\\n        },\\n\\n        \\\"shard_exceeded_max_retries\\\": {\\n\\n       \\\n          \\     \\\"root_cause\\\": \\\"Failed allocation retry attempt\\\",\\n\\n         \\\n          \\   \\\"description\\\": f\\\"Your OpenSearch cluster '{domain_name}' is currently\\\n          \\ in {cluster_health} state as it has excreted the time limit of 5000ms\\\n          \\ or maximum number of retries (5 by default) for shard allocation. To return\\\n          \\ your cluster to the green state, increase the maximum number of retries\\\n          \\ for each {cluster_health} index:\\\"\\n\\n            + '\\\\n PUT <index-name>/_settings\\\n          \\ { \\\"index.allocation.max_retries\\\" : 10 }'\\n\\n            + cluster_processing,\\n\\\n          \\n        },\\n\\n        \\\"allocation_explain_not_supported\\\": {\\n\\n    \\\n          \\        \\\"root_cause\\\": \\\"Uncompatible Version for _cluster/allocation/explain\\\"\\\n          ,\\n\\n            \\\"description\\\": f\\\"Your OpenSearch cluster '{domain_name}'\\\n          \\ is currently in {cluster_health} state as the cluster is using {domain_es_version}\\\n          \\ version, unfortunately we cannot get the reason for the shard(s) being\\\n          \\ unassigned as the engine version does not support the allocation/explain\\\n          \\ API. \\\\nFor assistance in getting back the cluster to green state, kindly\\\n          \\ contact AWS Support with the above details. {cluster_processing}\\\",\\n\\n\\\n          \\        },\\n\\n        \\\"http_error_while_running_automation\\\": {\\n\\n  \\\n          \\          \\\"root_cause\\\": \\\"Failed to execute SAW Document\\\",\\n\\n     \\\n          \\       \\\"description\\\": f\\\"Unfortunately, an issue occurred while running\\\n          \\ the automation for your OpenSearch cluster '{domain_name}'. The OpenSearch\\\n          \\ cluster's API returned a {connection_status_code} error code with the\\\n          \\ following message:\\\\n{error_message}\\\\n Kindly retry the execution of\\\n          \\ the SAW document and if the issue persists, please contact AWS support\\\n          \\ for assistance.\\\",\\n\\n        },\\n\\n        \\\"error_running_automation\\\"\\\n          : {\\n\\n            \\\"root_cause\\\": \\\"Failed to execute SAW Document\\\",\\n\\\n          \\n            \\\"description\\\": f\\\"Unfortunately, an issue occurred ({error})\\\n          \\ while running the automation for your OpenSearch cluster '{domain_name}'.\\\n          \\ Please retry the execution of the SAW document and if the issue persists,\\\n          \\ please contact AWS support for assistance.\\\",\\n\\n        },\\n\\n    }\\n\\\n          \\n\\n\\n    return {\\n\\n        \\\"connectionStatusCode\\\": connection_status_code,\\n\\\n          \\n        \\\"rootCause\\\": response.get(reason_code, {}).get(\\\"root_cause\\\"\\\n          , \\\"\\\"),\\n\\n        \\\"description\\\": response.get(reason_code, {}).get(\\\"\\\n          description\\\", \\\"\\\"),\\n\\n    }\\n\\n\\n\\n\\n\\ndef main(event, context):\\n\\n\\\n          \\    \\\"\\\"\\\"Getting the domain endpoint from the describe-domain output that\\\n          \\ will be pass to the code by SSM.\\\"\\\"\\\"\\n\\n    domain_name = \\\"\\\"\\n\\n \\\n          \\   customer_response = {}\\n\\n    try:\\n\\n        # Endpoint will either\\\n          \\ be in 'Endpoint' if the domain is public, or 'Endpoints' if the domain\\\n          \\ is VPC-based.\\n\\n        domain_endpoint = \\\"\\\"\\n\\n        if \\\"Endpoint\\\"\\\n          \\ in event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"]:\\n\\n            domain_endpoint\\\n          \\ = \\\"https://\\\" + str(event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"][\\\"Endpoint\\\"\\\n          ]) + \\\"/\\\"\\n\\n        elif \\\"Endpoints\\\" in event[\\\"DescribeOutput\\\"][\\\"\\\n          DomainStatus\\\"]:\\n\\n            domain_endpoint = \\\"https://\\\" + str(event[\\\"\\\n          DescribeOutput\\\"][\\\"DomainStatus\\\"][\\\"Endpoints\\\"][\\\"vpc\\\"]) + \\\"/\\\"\\n\\n\\\n          \\n\\n        # The version of the domain is 'EngineVersion' for OpenSearch\\\n          \\ versions, and 'ElasticsearchVersion' for Elasticsearch versions.\\n\\n \\\n          \\       domain_es_version = \\\"\\\"\\n\\n        if \\\"EngineVersion\\\" in event[\\\"\\\n          DescribeOutput\\\"][\\\"DomainStatus\\\"]:\\n\\n            domain_es_version =\\\n          \\ event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"][\\\"EngineVersion\\\"]\\n\\n   \\\n          \\     elif \\\"ElasticsearchVersion\\\" in event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"\\\n          ]:\\n\\n            domain_es_version = event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"\\\n          ][\\\"ElasticsearchVersion\\\"]\\n\\n        if \\\"ClusterConfig\\\" in event[\\\"\\\n          DescribeOutput\\\"][\\\"DomainStatus\\\"]:\\n\\n            desired_data_node_count\\\n          \\ = event[\\\"DescribeOutput\\\"][\\\"DomainStatus\\\"][\\\"ClusterConfig\\\"][\\\"InstanceCount\\\"\\\n          ]\\n\\n        elif \\\"ElasticsearchClusterConfig\\\" in event[\\\"DescribeOutput\\\"\\\n          ][\\\"DomainStatus\\\"]:\\n\\n            desired_data_node_count = event[\\\"DescribeOutput\\\"\\\n          ][\\\"DomainStatus\\\"][\\\"ElasticsearchClusterConfig\\\"][\\n\\n               \\\n          \\ \\\"InstanceCount\\\"\\n\\n            ]\\n\\n\\n\\n        domain_arn = event.get(\\\"\\\n          DescribeOutput\\\", {}).get(\\\"DomainStatus\\\", {}).get(\\\"ARN\\\", \\\"\\\")\\n\\n\\n\\\n          \\n        if domain_arn != \\\"\\\":\\n\\n            region = domain_arn.split(\\\"\\\n          :\\\")[3]\\n\\n        else:\\n\\n            region = os.environ.get(\\\"AWS_REGION\\\"\\\n          )\\n\\n\\n\\n        cw_agent_healthy = event.get(\\\"CheckCloudWatchAgent\\\",\\\n          \\ True)\\n\\n        resource_utilisation = event.get(\\\"CheckResourceUtilisationMetrics\\\"\\\n          , \\\"\\\")\\n\\n        lambda_execution_role = event.get(\\\"LambdaExecutionRole\\\"\\\n          , \\\"\\\")\\n\\n        domain_name = event.get(\\\"DescribeOutput\\\", {}).get(\\\"\\\n          DomainStatus\\\", {}).get(\\\"DomainName\\\", \\\"\\\")\\n\\n\\n\\n        customer_response\\\n          \\ = check_cluster_connectivity(\\n\\n            domain_endpoint=domain_endpoint,\\n\\\n          \\n            region=region,\\n\\n            domain_es_version=domain_es_version,\\n\\\n          \\n            domain_name=domain_name,\\n\\n            desired_data_node_count=desired_data_node_count,\\n\\\n          \\n            resource_utilisation=resource_utilisation,\\n\\n           \\\n          \\ cw_agent_healthy=cw_agent_healthy,\\n\\n            lambda_execution_role=lambda_execution_role,\\n\\\n          \\n        )\\n\\n    except (\\n\\n        http.client.HTTPException,\\n\\n  \\\n          \\      http.client.IncompleteRead,\\n\\n        http.client.ImproperConnectionState,\\n\\\n          \\n        http.client.CannotSendRequest,\\n\\n        http.client.CannotSendHeader,\\n\\\n          \\n        http.client.ResponseNotReady,\\n\\n        http.client.BadStatusLine,\\n\\\n          \\n        http.client.LineTooLong,\\n\\n        http.client.RemoteDisconnected,\\n\\\n          \\n        AttributeError,\\n\\n        TypeError,\\n\\n        ClientError,\\n\\\n          \\n        Exception,\\n\\n    ) as exception:\\n\\n        customer_response\\\n          \\ = generate_response(\\n\\n            domain_name=domain_name,\\n\\n     \\\n          \\       reason_code=\\\"error_running_automation\\\",\\n\\n            connection_status_code=\\\"\\\n          500\\\",\\n\\n            error=str(exception),\\n\\n        )\\n\\n\\n\\n    if not\\\n          \\ customer_response:\\n\\n        customer_response = {\\n\\n            \\\"\\\n          root_cause\\\": \\\"Failed to execute SAW Document\\\",\\n\\n            \\\"description\\\"\\\n          : \\\"Unfortunately, an issue occurred while running the SAW document for\\\n          \\ your OpenSearch cluster. Kindly retry the execution of the SAW document\\\n          \\ and if the issue persists, please contact AWS support for assistance.\\\"\\\n          ,\\n\\n        }\\n\\n    return customer_response\\n\\n\"\n      Runtime: python3.11\n      Timeout: 600\n      VpcConfig:\n        SubnetIds: !If\n        - UseVpc\n        - !Ref SubnetIds\n        - !Ref 'AWS::NoValue'\n        SecurityGroupIds: !If\n        - UseVpc\n        - !Ref SecurityGroupIds\n        - !Ref 'AWS::NoValue'\n",
        "TimeoutInMinutes": 10,
        "OnFailure": "DELETE",
        "ClientRequestToken": "AWSSupport-TroubleshootOpenSearchRedYellowCluster-{{ automation:EXECUTION_ID }}",
        "Parameters": [
          {
            "ParameterKey": "LambdaName",
            "ParameterValue": "Automation-RedYellowCluster-{{ automation:EXECUTION_ID }}"
          },
          {
            "ParameterKey": "VpcId",
            "ParameterValue": "{{ GetClusterConfiguration.VpcId }}"
          },
          {
            "ParameterKey": "SubnetIds",
            "ParameterValue": "{{ GetClusterConfiguration.SubnetIds }}"
          },
          {
            "ParameterKey": "SecurityGroupIds",
            "ParameterValue": "{{ GetClusterConfiguration.SecurityGroupIds }}"
          },
          {
            "ParameterKey": "LambdaExecutionRole",
            "ParameterValue": "{{ LambdaExecutionRole }}"
          }
        ],
        "Tags": [
          {
            "Key": "Name",
            "Value": "AWSSupport-TroubleshootOpenSearchRedYellowCluster-{{ automation:EXECUTION_ID }}"
          },
          {
            "Key": "AWSSupport-TroubleshootOpenSearchRedYellowCluster-AutomationExecution",
            "Value": "{{ automation:EXECUTION_ID }}"
          }
        ]
      },
      "outputs": [
        {
          "Name": "CloudFormationStackId",
          "Selector": "$.StackId",
          "Type": "String"
        },
        {
          "Name": "CloudFormationStackStatus",
          "Selector": "$.StackStatus",
          "Type": "String"
        }
      ],
      "nextStep": "WaitForAWSLambdaFunctionStack",
      "onFailure": "step:DescribeStackCreationErrors"
    },
    {
      "name": "WaitForAWSLambdaFunctionStack",
      "action": "aws:waitForAwsResourceProperty",
      "description": "Waits for the AWS CloudFormation stack to complete.",
      "isCritical": true,
      "timeoutSeconds": 600,
      "inputs": {
        "Service": "cloudformation",
        "Api": "DescribeStacks",
        "StackName": "{{ CreateAWSLambdaFunctionStack.CloudFormationStackId }}",
        "PropertySelector": "$.Stacks[0].StackStatus",
        "DesiredValues": [
          "UPDATE_COMPLETE",
          "CREATE_COMPLETE"
        ]
      },
      "nextStep": "GetClusterMetricsFromCloudWatch",
      "onFailure": "step:DescribeStackCreationErrors"
    },
    {
      "name": "GetClusterMetricsFromCloudWatch",
      "action": "aws:executeScript",
      "description": "Gets the Amazon CloudWatch `ClusterStatus`, `CPUUtilization` and `JVMMemoryPressure` OpenSearch Service Cluster related metrics and its creation date.",
      "inputs": {
        "Handler": "get_cw_metrics.fetch_cloud_watch_metric",
        "InputPayload": {
          "DomainName": "{{ DomainName }}",
          "UtilizationThreshold": "{{ UtilizationThreshold }}"
        },
        "Attachment": "artifact.zip",
        "Runtime": "python3.11"
      },
      "outputs": [
        {
          "Name": "CheckCloudWatchAgent",
          "Selector": "$.Payload.CheckCloudWatchAgent",
          "Type": "Boolean"
        },
        {
          "Name": "CheckResourceUtilisationMetrics",
          "Selector": "$.Payload.CheckResourceUtilisationMetrics",
          "Type": "String"
        }
      ],
      "onFailure": "step:DeleteAWSLambdaFunctionStack",
      "nextStep": "RunOpenSearchAPIs"
    },
    {
      "name": "RunOpenSearchAPIs",
      "action": "aws:invokeLambdaFunction",
      "description": "Use the AWS Lambda function to call the OpenSearch APIs and analyze the cluster metrics data to try to diagnose the cause for the red or yellow cluster status.",
      "maxAttempts": 1,
      "timeoutSeconds": 600,
      "inputs": {
        "FunctionName": "Automation-RedYellowCluster-{{ automation:EXECUTION_ID }}",
        "InputPayload": {
          "DescribeOutput": "{{ GetClusterConfiguration.DescribeOutput }}",
          "CheckCloudWatchAgent": "{{ GetClusterMetricsFromCloudWatch.CheckCloudWatchAgent }}",
          "CheckResourceUtilisationMetrics": "{{ GetClusterMetricsFromCloudWatch.CheckResourceUtilisationMetrics }}",
          "LambdaExecutionRole": "{{ LambdaExecutionRole }}"
        }
      },
      "outputs": [
        {
          "Name": "RootCause",
          "Selector": "$.rootCause",
          "Type": "String"
        },
        {
          "Name": "IssueDescription",
          "Selector": "$.description",
          "Type": "String"
        }
      ],
      "onFailure": "step:DeleteAWSLambdaFunctionStack",
      "nextStep": "DeleteAWSLambdaFunctionStack"
    },
    {
      "name": "DescribeStackCreationErrors",
      "action": "aws:executeScript",
      "onFailure": "Continue",
      "maxAttempts": 3,
      "description": "Describes the AWS CloudFormation stack events if the runbooks fails to create the AWS CloudFormation stack.",
      "inputs": {
        "Handler": "describe_stack_events.describe_stack_events",
        "InputPayload": {
          "StackName": "{{ CreateAWSLambdaFunctionStack.CloudFormationStackId }}",
          "ExpectedStackStatus": "CREATE_COMPLETE",
          "NonExpectedResourceStatus": "ROLLBACK_COMPLETE,CREATE_FAILED,ROLLBACK_FAILED"
        },
        "Attachment": "artifact.zip",
        "Runtime": "python3.11"
      },
      "outputs": [
        {
          "Name": "DeletionErrorsFromStackEvents",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ],
      "isCritical": false,
      "nextStep": "DeleteAWSLambdaFunctionStack"
    },
    {
      "name": "DeleteAWSLambdaFunctionStack",
      "action": "aws:deleteStack",
      "onFailure": "step:DescribeStackDeletionErrors",
      "description": "Deletes the AWS Lambda function created by this automation in your account.",
      "inputs": {
        "StackName": "{{ CreateAWSLambdaFunctionStack.CloudFormationStackId }}"
      },
      "isEnd": true
    },
    {
      "name": "DescribeStackDeletionErrors",
      "action": "aws:executeScript",
      "description": "Describes the AWS CloudFormation stack events if the runbooks fails to delete the AWS CloudFormation stack.",
      "onFailure": "Abort",
      "inputs": {
        "Handler": "describe_stack_events.describe_stack_events",
        "InputPayload": {
          "StackName": "{{ CreateAWSLambdaFunctionStack.CloudFormationStackId }}",
          "ExpectedStackStatus": "DELETE_COMPLETE",
          "NonExpectedResourceStatus": "DELETE_FAILED"
        },
        "Attachment": "artifact.zip",
        "Runtime": "python3.11"
      },
      "outputs": [
        {
          "Name": "DeletionErrorsFromStackEvents",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ],
      "isEnd": true
    }
  ],
  "outputs": [
    "RunOpenSearchAPIs.RootCause",
    "RunOpenSearchAPIs.IssueDescription"
  ],
  "files": {
    "artifact.zip": {
      "checksums": {
        "SHA256": "9738792eb3cb714ea264b1da726c23b61da7f02574dc7c2eccbad66482cce5b4"
      }
    }
  }
}
