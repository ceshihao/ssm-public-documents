{
  "description": "# AWSSupport-CalculateEBSPerformanceMetrics\n\n---\n\n## Purpose:\n\nAWSSupport-CalculateEBSPerformanceMetrics runbook helps diagnose Amazon EBS performance issues by calculating metrics published to Amazon Cloudwatch and creating Amazon Cloudwatch dashboards that display the average I/O size and total aggregate throughput and IOPS of individual Amazon EBS volumes, or the total aggregate throughput and IOPS across all Amazon EBS volumes attached to an Amazon EC2 instance by utilizing Amazon Cloudwatch metric math. The runbook outputs the link to the newly created Amazon Cloudwatch dashboard that displays the relevant calculated Amazon Cloudwatch metrics.\n\n\n **Disclaimer**: The creation of the aforementioned dashboard may result in your account incurring extra charges. For more information please consult the [Amazon CloudWatch pricing guide](https://aws.amazon.com/cloudwatch/pricing).\n\n\n ## Workflow Specifications:\n\n This workflow uses AWS Systems Manager Automation and takes in the following parameters:\n\n1. **ResourceId** - **(Required)** The ID of the Amazon EBS volume or the Amazon EC2 instance for which the statistics need to be visualized.\n2. **StartTime** - **(Required)** The start time to view the data in Amazon CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC. For example, 2021-06-09T13:30:10.\n3. **EndTime** - **(Required)** The ending time to view the data in Amazon CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC. For example, 2021-06-09T13:30:10.\n4. **Period** - **(Required)** The period (in seconds) of the Amazon CloudWatch metrics.\n5. **AutomationAssumeRole** - **(Optional)** The IAM role which AWS Systems Manager will assume to execute this automation. This role must allow these IAM actions:\n        - ssm:StartAutomationExecution\n    - ec2:DescribeVolumes\n    - ec2:DescribeInstances\n    - ec2:DescribeInstanceTypes\n    - cloudwatch:PutDashboard\n    - cloudwatch:ListMetrics\n    - ssm:GetAutomationExecution\n\n\nPlease visit the documentation on [Automation Setup](https://docs.aws.amazon.com/systems-manager/latest/userguide/automation-setup.html) for more information.",
  "schemaVersion": "0.3",
  "assumeRole": "{{AutomationAssumeRole}}",
  "parameters": {
    "ResourceId": {
      "type": "String",
      "description": "(Required) The ID of the EC2 Instance or EBS Volume you wish to observe the metrics of.",
      "allowedPattern": "^vol-[a-z0-9]{8}$|^vol-[a-z0-9]{17}$|^i-[a-z0-9]{8}$|^i-[a-z0-9]{17}$"
    },
    "StartTime": {
      "type": "String",
      "description": "(Required) The start time to view the data in CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC.",
      "allowedPattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}$"
    },
    "EndTime": {
      "type": "String",
      "description": "(Required) The end time to view the data in CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC.",
      "allowedPattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}$"
    },
    "Period": {
      "type": "String",
      "description": "(Required) The number of seconds by which observable metrics will be grouped. Select the period in seconds from the drop down list.",
      "allowedValues": [
        "60",
        "300",
        "900",
        "3600",
        "21600",
        "86400"
      ]
    },
    "AutomationAssumeRole": {
      "default": "",
      "type": "String",
      "description": "(Optional) IAM role which AWS Systems Manager will assume to execute this automation. For more information, visit - https://docs.aws.amazon.com/systems-manager/latest/userguide/automation-setup.html",
      "allowedPattern": "^$|^arn:aws:iam::[0-9]*:role/[/\\w+=,.@-]+$"
    }
  },
  "mainSteps": [
    {
      "name": "checkTimestamps",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "isEnd": "false",
      "isCritical": "true",
      "nextStep": "chooseVolumeOrInstance",
      "inputs": {
        "Runtime": "python3.8",
        "Handler": "timestamp_handler",
        "Script": "from datetime import datetime\n\ndef timestamp_handler(event, context):\n    start_time = event['start_time']\n    end_time = event['end_time']\n\n    try:\n    \tt1 = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%S\")\n    \tt2 = datetime.strptime(end_time, \"%Y-%m-%dT%H:%M:%S\")\n    \tif t1 > t2:\n    \t\traise Exception(\"[ERROR] StartTime should not be greater than EndTime\")\n    \telse:\n    \t\treturn \"Timestamps are in correct format.\"\n    except Exception as error:\n    \traise error\n",
        "InputPayload": {
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}"
        }
      }
    },
    {
      "name": "chooseVolumeOrInstance",
      "action": "aws:branch",
      "maxAttempts": 3,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "isEnd": "false",
      "isCritical": "true",
      "inputs": {
        "Choices": [
          {
            "NextStep": "getVolumeStats",
            "Variable": "{{ResourceId}}",
            "StartsWith": "vol-"
          },
          {
            "NextStep": "getInstanceStats",
            "Variable": "{{ResourceId}}",
            "StartsWith": "i-"
          }
        ]
      }
    },
    {
      "name": "getVolumeStats",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "isCritical": "true",
      "isEnd": true,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "inputs": {
        "Runtime": "python3.8",
        "Handler": "getVolumeStats",
        "Script": "import json\nimport boto3\nimport botocore\nimport urllib\nimport sys\nfrom urllib.parse import quote\n\ndef getSC1Limits(volume_size):\n    maximum_available_iops = 250\n    if volume_size < 3200:\n        max_available_throughput = volume_size * 80 / 1024\n        baseline_throughput = volume_size * 12 / 1024\n    else:\n        max_available_throughput = 250\n        baseline_throughput = volume_size * 12 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef getST1Limits(volume_size):\n    maximum_available_iops = 500\n    if volume_size > 12800:\n        max_available_throughput = 500\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size < 2048:\n            max_available_throughput = volume_size * 250 / 1024\n            baseline_throughput= volume_size * 40 / 1024 \n        else:\n            max_available_throughput = 500\n            baseline_throughput = volume_size * 40 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef getIOLimits(volume_iops):\n    if volume_iops <= 32000:\n        max_available_throughput = 500\n        calculated_throughput = volume_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    else:\n        max_available_throughput = 1000\n        calculated_throughput = volume_iops / 64\n        baseline_throughput= min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, volume_iops, volume_iops]\n\ndef getGP2Limits(volume_size):\n    calculated_iops = 3 * volume_size\n    ## calculation for volumes bigger than 1000 gb, iops increasing linearly till they hit max (16000 iops); baseline/max throughput=250 MiB/s\n    if volume_size > 1000:\n        max_available_throughput = 250\n        maximum_available_iops = 16000\n        baseline_iops = min(maximum_available_iops, calculated_iops)\n        maximum_available_iops = baseline_iops\n        baseline_throughput = max_available_throughput\n    else:\n        maximum_available_iops = 3000\n        ## calculation for volumes smaller than 170 gb, minimum iops can be 100 and max can be 3000; baseline throughput depends on number of baseline iops and can go up to a max of 128 MiB/s\n        if volume_size <= 170:\n            max_available_throughput = 128\n            baseline_iops = max(calculated_iops, 100)\n            calculated_throughput = baseline_iops / 4\n            baseline_throughput = min(max_available_throughput, calculated_throughput)\n        ## calculation for volumes larger than 170 gb and smaller than or equal to 1000 gb, max iops can be 3000 and scale with size; max throughput can go up to 250 MiB/s\n        else:\n            max_available_throughput = 250\n            baseline_iops = calculated_iops\n            calculated_throughput = baseline_iops / 4\n            baseline_throughput = min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\n\n# Picks maximum and baseline limits for the specific EBS volume based on the volume type\n# For example, if the volume type is io1 it will contact the get_IO_limits function to obtain these limits \n# Each volume type has hardcoded limits which can be found in the volume type specific functions above this comment block (except for gp3) \n\ndef get_volume_limits(volume):\n    volume_type, volume_size = volume.volume_type, volume.size\n    if volume_type == \"gp2\":\n        return getGP2Limits(volume_size)\n    elif volume_type == \"gp3\":\n        return [volume.throughput, 125, volume.iops, volume.iops]\n    elif volume_type == \"io1\" or volume_type == \"io2\":\n        return getIOLimits(volume.iops)\n    elif volume_type == \"st1\":\n        return getST1Limits(volume_size)\n    elif volume_type == \"sc1\":\n        return getSC1Limits(volume_size) \n    elif volume_type == \"standard\":\n        return [0, 0, 0, 0]\n\ndef get_all_cloudwatch_metrics(volume_id):\n    client = boto3.client('cloudwatch')\n    cloudwatch_response = client.list_metrics(\n        Namespace='AWS/EBS',\n        Dimensions=[\n            {\n                'Name': 'VolumeId',\n                'Value': '{}'.format(volume_id)\n            }\n        ]\n    )\n    return cloudwatch_response\n\n# This function builds the respective bytes and ops arrays for all metrics in th cloudwatch api call response\n\ndef build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY):\n    j = 0\n    while j < len(cloudwatch_response['Metrics']):\n        ## If bytes metrics exist, storing them in BYTES_METRIC_NAME_ARRAY[] and storing their count in bytes_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadBytes\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteBytes\"):\n            bytes_metrics_count = bytes_metrics_count+1\n            BYTES_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        ## If ops metrics exist, storing them in OPS_METRIC_NAME_ARRAY[] and storing their count in ops_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadOps\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteOps\"):\n            ops_metrics_count = ops_metrics_count+1\n            OPS_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        j = j + 1\n    return [bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY]\n\n# Sets all potential label value for either throughput or iops\n\ndef set_labels(metric_type):\n    if metric_type == \"Throughput\":\n        return \"Maximum / Baseline Throughput Limit - MiB/s\", \"Maximum Throughput Limit - MiB/s\", \"Baseline Throughput Limit - MiB/s\"\n    else:\n        return \"Maximum / Baseline IOPS Limit\", \"Maximum IOPS Limit\", \"Baseline IOPS Limit\"\n\n# Returns JSON to be used in the dashboard widgets for instances\ndef fill_jsonstring(metric_type, EXPRESSIONS_ARRAY, maximum_limit, baseline_limit, start_time, end_time, region, period, volume_type):\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"EBS Volume \" + metric_type + \"\\\"}\"\n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n        \n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n    # If the metric type is IO size or of the standard/magnetic type then no limits are plotted and the string is returned without annotations\n    if metric_type == \"IOSize\" or volume_type == \"standard\":\n        return jsonstring\n    if metric_type == \"Throughput\":\n        equal_label = \"Maximum / Baseline Throughput Limit - MiB/s\"\n        maximum_label = \"Maximum Throughput Limit - MiB/s\"\n        baseline_label = \"Baseline Throughput Limit - MiB/s\"\n    else:\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n\n    # If both the max and the baseline limits are equal we set a single annotation\n    # Otherwise we add two annotations\n    if maximum_limit == baseline_limit:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    else:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__},{\\\"label\\\": \\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\": __SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\n# This function is used to continuously build each metric array while tracking the counts\ndef get_metric_counts(volume, metrics_count, metric_name_array, array, counter, expressions_array):\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    metric_expression = metric_expression.replace(\"__VOLUME_ID__\", volume)\n                \n    # If any of the bytes metrics exist, create expressions to select those metrics and give them metrics IDs (like m1,m2)\n    i = metrics_count\n    while i > 0:\n        i = i-1\n        temp_string = metric_expression.replace(\"__METRIC_NAME__\", metric_name_array[i])\n        temp_string = temp_string.replace(\"__METRIC_ID__\", \"m{}\".format(counter))\n        array.append(\"m{}\".format(counter))\n        counter = counter+1\n        expressions_array.append(temp_string)\n    return array, counter\n\ndef create_expression(expression, local_array, volume, expression_counter, math_expressions_io_size, math_expressions_array):\n    temp_string = expression.replace(\"__METRIC_ID_LIST__\", ','.join(local_array))\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n    io_size_string = temp_string.replace(\"\\\"visible\\\":true\", \"\\\"visible\\\":false\")\n    math_expressions_io_size.append(io_size_string)\n    math_expressions_array.append(temp_string)\n    expression_counter = expression_counter+1\n    return expression_counter\n\n# This function creates a single widget according to specific parameters\ndef create_widget(widget_type, x, y, w, h, p):\n    return {\n        \"type\": widget_type,\n        \"x\":x,\n        \"y\":y,\n        \"width\":w,\n        \"height\":h,\n        \"properties\": json.loads(p)\n    }\n\ndef create_dashboard(jsonstring_throughput, jsonstring_iops, jsonstring_io_size, volume, start_time_arg, end_time_arg, volume_type, region):\n    client = boto3.client('cloudwatch')\n    markdownstring = \"{\\\"markdown\\\":\\\"### Metrics for EBS Volume __VOLUME_ID__\\\\n- Volume Type: __VOLUME_TYPE__\\\\n\\\\n[button:More details on EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html)\\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Volume calculated throughput | SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) / 1024 / 1024 / period | MiB/s |\\\\n| Volume calculated IOPS | SUM(VolumeReadOps) + SUM(VolumeWriteOps) / period | IOPS |\\\\n| Volume calculated IO size | Volume calculated throughput / Volume calculated IOPS | KiB |\\\"}\"\n    markdownstring = markdownstring.replace(\"__VOLUME_ID__\", volume)\n    markdownstring = markdownstring.replace(\"__VOLUME_TYPE__\", volume_type)\n    footer_markdownstring = \"{\\\"markdown\\\":\\\"**In order to delete the dashboard, run the CLI command** \\\\n\\\\n ```\\\\n $ aws cloudwatch delete-dashboards --dashboard-names __VOLUME_ID__-EBS-Statistics --region __REGION__ \\\\n ``` \\\\n\\\\n NOTE: You will need **cloudwatch:DeleteDashboards** IAM permission to delete the dashboard.\\\"}\"\n    footer_markdownstring = footer_markdownstring.replace(\"__VOLUME_ID__\", volume)\n    footer_markdownstring = footer_markdownstring.replace(\"__REGION__\", region)\n    if jsonstring_io_size == \"none\":\n        widget_list = [create_widget(\"text\", 0, 0, 24, 6, markdownstring),create_widget(\"metric\", 0, 5, 8, 8, jsonstring_throughput), create_widget(\"metric\", 8, 5, 8, 8, jsonstring_iops), create_widget(\"text\", 0, 13, 24, 3, footer_markdownstring)]\n    else:\n        widget_list = [create_widget(\"text\", 0, 0, 24, 6, markdownstring),create_widget(\"metric\", 0, 5, 8, 8, jsonstring_throughput), create_widget(\"metric\", 8, 5, 8, 8, jsonstring_iops), create_widget(\"metric\", 16, 5, 8, 8, jsonstring_io_size), create_widget(\"text\", 0, 13, 24, 3, footer_markdownstring)]\n    dashboard = {\n        \"start\": start_time_arg,\n        \"end\": end_time_arg,\n        \"periodOverride\": \"inherit\",\n        \"widgets\": widget_list\n    }\n    response = client.put_dashboard(DashboardName=\"{}-EBS-Statistics\".format(volume),DashboardBody=json.dumps(dashboard))\n    return response\n\ndef getVolumeStats(event, context):\n    region, volume_id, start_time, end_time, period = event['region'], event['volume_id'], event['start_time'], event['end_time'], event['period']\n    bytes_metrics_count, ops_metrics_count = 0, 0 # Used to track respective throughput and IOPS metrics\n    global_metrics_counter = 1 # Used to track total number of metrics\n    BYTES_METRIC_NAME_ARRAY, OPS_METRIC_NAME_ARRAY = [], []  \n    expression_counter_tp, expression_counter_ops = 1, 1 # Used to count the number of throughput and IOPS expressions on a widget\n    EXPRESSIONS_ARRAY_THROUGHPUT, EXPRESSIONS_ARRAY_IOPS, EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] #\n    LIMIT_ARRAY, BYTES_ARRAY, OPS_ARRAY = [], [], [] \n    MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_OPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] \n\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    \n    # Checking if volume exists\n    client = boto3.client('ec2')\n    try:\n        volume_response = client.describe_volumes(\n            VolumeIds=[\n                '{}'.format(volume_id),\n            ]\n        )\n        # Get all metrics from CloudWatch for this volume\n        cloudwatch_response = get_all_cloudwatch_metrics(volume_id)\n        client = boto3.resource(\"ec2\") \n        volume = client.Volume(volume_id)\n\n        # Decide what volume type is associated with that volume and set maximum and baseline throughput and IOPS limits\n        limits = get_volume_limits(volume)\n        maximum_throughput_limit, baseline_throughput_limit, maximum_iops_limit, baseline_iops_limit = limits[0:4]\n\n        # Get bytes and ops metric arrays and set associated counts (further explained in build_metric_arrays function)\n        arrays_and_counts = build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY)\n        bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY = arrays_and_counts[0:4]\n            \n        if (bytes_metrics_count == 0) and (ops_metrics_count == 0):\n            raise Exception(\"[ERROR] Metrics don't exist for this volume!\")\n        \n        BYTES_ARRAY, global_metrics_counter = get_metric_counts(volume_id, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, BYTES_ARRAY, global_metrics_counter, EXPRESSIONS_ARRAY_THROUGHPUT)\n        OPS_ARRAY, global_metrics_counter = get_metric_counts(volume_id, ops_metrics_count, OPS_METRIC_NAME_ARRAY, OPS_ARRAY, global_metrics_counter, EXPRESSIONS_ARRAY_IOPS)\n\n        # At this point, EXPRESSIONS_ARRAY[] will have the available bytes and ops metrics selected\n        # If bytes metrics exists, create throughput expression and update counter\n        if bytes_metrics_count > 0:\n            throughput_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            expression_counter_tp = create_expression(throughput_expression, BYTES_ARRAY, volume_id, expression_counter_tp, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_THROUGHPUT)\n    \n        # If ops metrics exists, create ops expression and update counter\n        if ops_metrics_count > 0:\n            ops_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            expression_counter_ops = create_expression(ops_expression, OPS_ARRAY, volume_id, expression_counter_ops+1, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_OPS)\n            expression_counter_ops -= 1\n\n        expression_counter_io_size = expression_counter_tp + expression_counter_ops - 1\n        # If bytes and ops both exist, create iosize expression and add to MATH_EXPRESSIONS_ARRAY_IO_SIZE[]\n        if (bytes_metrics_count > 0) and (ops_metrics_count > 0):\n            iosize_expression = \"[{\\\"expression\\\":\\\"(__THRU_DIV_OPS__)*1024\\\",\\\"label\\\":\\\"Estimated IO size - KiB\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            temp_string = iosize_expression.replace(\"__THRU_DIV_OPS__\", \"e{}\".format(expression_counter_io_size-2) + \"/\" + \"e{}\".format(expression_counter_io_size-1))\n            temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter_io_size))\n            MATH_EXPRESSIONS_ARRAY_IO_SIZE.append(temp_string)\n\n        # We create the throughput and IOPS expression arrays by adding metric math expressions to them\n        EXPRESSIONS_ARRAY_IO_SIZE = MATH_EXPRESSIONS_ARRAY_IO_SIZE + EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_IOPS\n        EXPRESSIONS_ARRAY_THROUGHPUT = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n        EXPRESSIONS_ARRAY_IOPS = MATH_EXPRESSIONS_ARRAY_OPS + EXPRESSIONS_ARRAY_IOPS\n\n        jsonstring_throughput = fill_jsonstring(\"Throughput\", EXPRESSIONS_ARRAY_THROUGHPUT, maximum_throughput_limit, baseline_throughput_limit, start_time, end_time, region, period, volume.volume_type)\n        jsonstring_iops = fill_jsonstring(\"IOPS\", EXPRESSIONS_ARRAY_IOPS, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, volume.volume_type)\n\n        # If the IO size list is not empty (so metrics exist for it), we create a new volume JSON string for this to be added as a widget in the dashboard\n        # Otherwise, we set the same string name to \"none\" and handle it later\n        if EXPRESSIONS_ARRAY_IO_SIZE != []:\n            jsonstring_io_size = fill_jsonstring(\"IOSize\", EXPRESSIONS_ARRAY_IO_SIZE, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, volume.volume_type)\n        else:\n            jsonstring_io_size = \"none\"\n        \n        response = create_dashboard(jsonstring_throughput, jsonstring_iops, jsonstring_io_size, volume_id, start_time, end_time, volume.volume_type, region)\n        if response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n            info_message = \"\\n\\nYou can copy the generated dashboard URL into your browser and you can then observe the metrics for the selected resource between the specified start and end times.\\nIf you wish to delete the CloudWatch Dashboard generated from this document, please consult the DeleteDashboard API documentation - https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_DeleteDashboards.html\"\n            return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#dashboards:name={}-EBS-Statistics\".format(region, region, volume_id) + info_message\n\n    except botocore.exceptions.ClientError as error:\n        raise error\n        \n    except Exception as error:\n        raise error\n",
        "InputPayload": {
          "volume_id": "{{ResourceId}}",
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}",
          "period": "{{Period}}",
          "region": "{{global:REGION}}"
        }
      },
      "outputs": [
        {
          "Name": "CloudWatchDashboardLink",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ]
    },
    {
      "name": "getInstanceStats",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "isCritical": "true",
      "isEnd": true,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "inputs": {
        "Runtime": "python3.8",
        "Handler": "getInstanceStats",
        "Script": "import boto3\nimport botocore\nimport json\nimport re\nimport urllib\nfrom urllib.parse import quote\n\ndef get_SC1_limits(volume_size):\n    maximum_available_iops = 250\n    if volume_size < 3200:\n        max_available_throughput = volume_size * 80 / 1024\n        baseline_throughput = volume_size * 12 / 1024\n    else:\n        max_available_throughput = 250\n        baseline_throughput = volume_size * 12 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef get_ST1_limits(volume_size):\n    maximum_available_iops = 500\n    if volume_size > 12800:\n        max_available_throughput = 500\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size < 2048:\n            max_available_throughput = volume_size * 250 / 1024\n            baseline_throughput= volume_size * 40 / 1024 \n        else:\n            max_available_throughput = 500\n            baseline_throughput = volume_size * 40 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef get_IO_limits(volume_iops):\n    if volume_iops <= 32000:\n        max_available_throughput = 500\n        calculated_throughput = volume_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    else:\n        max_available_throughput = 1000\n        calculated_throughput = volume_iops / 64\n        baseline_throughput= min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, volume_iops, volume_iops]\n\ndef get_GP2_limits(volume_size):\n    calculated_iops = 3 * volume_size\n    ## calculation for volumes bigger than 1000 gb, iops increasing linearly till they hit max (16000 iops); baseline/max throughput=250 MiB/s\n    if volume_size > 1000:\n        max_available_throughput = 250\n        maximum_available_iops = 16000\n        baseline_iops = min(maximum_available_iops, calculated_iops)\n        maximum_available_iops = baseline_iops\n        baseline_throughput = max_available_throughput\n    else:\n        maximum_available_iops = 3000\n        ## calculation for volumes smaller than 170 gb, minimum iops can be 100 and max can be 3000; baseline throughput depends on number of baseline iops and can go up to a max of 128 MiB/s\n        if volume_size <= 170:\n            max_available_throughput = 128\n            baseline_iops = max(calculated_iops, 100)\n            calculated_throughput = baseline_iops / 4\n            baseline_throughput = min(max_available_throughput, calculated_throughput)\n        ## calculation for volumes larger than 170 gb and smaller than or equal to 1000 gb, max iops can be 3000 and scale with size; max throughput can go up to 250 MiB/s\n        else:\n            max_available_throughput = 250\n            baseline_iops = calculated_iops\n            calculated_throughput = baseline_iops / 4\n            baseline_throughput = min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\n\n# Picks maximum and baseline limits for the specific EBS volume based on the volume type\n# For example, if the volume type is io1 it will contact the get_IO_limits function to obtain these limits \n# Each volume type has hardcoded limits which can be found in the volume type specific functions above this comment block (except for gp3) \n\ndef get_volume_limits(volume_id):\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n    volume_type, volume_size = volume.volume_type, volume.size\n    if volume_type == \"gp2\":\n        return get_GP2_limits(volume_size)\n    elif volume_type == \"gp3\":\n        return [volume.throughput, 125, volume.iops, volume.iops]\n    elif volume_type == \"io1\" or volume_type == \"io2\":\n        return get_IO_limits(volume.iops)\n    elif volume_type == \"st1\":\n        return get_ST1_limits(volume_size)\n    elif volume_type == \"sc1\":\n        return get_SC1_limits(volume_size) \n    elif volume_type == \"standard\":\n        return [0, 0, 0, 0]\n\n# Returns 3 string values, the string used for if the values for maximum and baseline are equal and then the maximum and baseline values are return respectively\ndef set_labels(metric_type):\n    if metric_type == \"Throughput\":\n        return \"Maximum / Baseline Throughput Limit - MiB/s\", \"Maximum Throughput Limit - MiB/s\", \"Baseline Throughput Limit - MiB/s\"\n    else:\n        return \"Maximum / Baseline IOPS Limit\", \"Maximum IOPS Limit\", \"Baseline IOPS Limit\"\n\n# Returns JSON to be used in the dashboard widgets for individual volumes\ndef fill_volume_jsonstring(metric_type, EXPRESSIONS_ARRAY, maximum_limit, baseline_limit, start_time, end_time, region, period, volume_id):\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"\" + metric_type + \"\\\"}\"\n    \n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n\n    # Substituting values in the above expression\n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n\n\n    if metric_type == \"IOSize\" or volume.volume_type == \"standard\":\n        return jsonstring\n    else:\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n    \n    # In the event the maximum and baseline limit are equal, we add a single annotation to display this\n    # Otherwise both annotations are created for maximum and baseline limits\n\n    if maximum_limit == baseline_limit:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    else:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__},{\\\"label\\\": \\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\": __SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\n# Returns JSON to be used in the dashboard widgets for instances\ndef fill_jsonstring(metric_type, EXPRESSIONS_ARRAY, start_time, end_time, region, period, ec2_info, client):\n    maximum_set, baseline_set = False, False\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"\" + metric_type + \"\\\"}\"\n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n        \n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n\n    # If the metric type is IO size no limits are plotted and the string is returned without annotations\n    if metric_type == \"IOSize\":\n        return jsonstring\n\n\n    if ec2_info.ebs_optimized:\n        ebs_optimized_response = client.describe_instance_types(\n            InstanceTypes=[\n                ec2_info.instance_type\n            ],\n            Filters=[\n                {\n                    'Name': 'ebs-info.ebs-optimized-support',\n                    'Values': [\n                        'supported','default',\n                    ]\n                },\n            ]\n        )\n        # Set labels for annotations\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n\n\n        if metric_type == \"Throughput\":\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumThroughputInMBps\"]:\n                maximum_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumThroughputInMBps\"]\n                # MB/s to MiB/s -----> (1000*1000)/1024/1024 = 0.9536743164\n                maximum_limit = round(maximum_limit * 0.9536743164, 1)\n                maximum_set = True\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineThroughputInMBps\"]:\n                baseline_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineThroughputInMBps\"]\n                # MB/s to MiB/s -----> (1000*1000)/1024/1024 = 0.9536743164\n                baseline_limit = round(baseline_limit * 0.9536743164, 1)\n                baseline_set = True\n\n        elif metric_type == \"IOPS\":\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumIops\"]:\n                maximum_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumIops\"]\n                maximum_set = True\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineIops\"]:\n                baseline_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineIops\"]\n                baseline_set = True\n                \n    # If both the max and the baseline limits have been set from the API then we set both limit annotations\n    # Otherwise we check if either of the maximum or baseline has been set and these are annotations are plotted individually\n    if (maximum_set and baseline_set):\n        if maximum_limit != baseline_limit:\n            jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__},{\\\"label\\\":\\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\":__SECOND_ANNOTATION_VALUE__}]}}\"\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n            jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n            jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n        else:\n            jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__}]}}\"\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    elif maximum_set:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    elif baseline_set:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\":__SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\ndef create_volume_expression(metric_type, expression, local_array, volume, expression_counter, math_expressions_io_size, math_expressions_array):\n    temp_string = expression.replace(\"__METRIC_ID_LIST__\", ','.join(local_array))\n    temp_string = temp_string.replace(\"__VOLUME_ID__\", volume)\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n    io_size_string = temp_string.replace(\"\\\"visible\\\":true\", \"\\\"visible\\\":false\")\n\n    if metric_type == \"IOPS\":\n        io_size_string = re.sub('e\\d{1}', \"e\"+str(expression_counter+1), io_size_string)\n    math_expressions_io_size.append(io_size_string)\n    math_expressions_array.append(temp_string)\n    expression_counter = expression_counter+1\n    return expression_counter\n\ndef create_instance_expression(metric_type, instance_id, array, math_expression_array, expression_counter, letter):\n    if metric_type == \"Throughput\":\n        expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"__INSTANCE_ID__ Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n    elif metric_type == \"IOPS\":\n        expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"__INSTANCE_ID__ Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n    temp_string = expression.replace(\"__INSTANCE_ID__\", instance_id)\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n\n    # Currently Throughput is m1,m2,m3 and IOPS are n1,n2,n3\n    final = []\n    i = 0\n    while i < len(array):\n        final.append(\"{}{}\".format(letter, i+1))\n        i += 1\n    math_expression_array.append(temp_string.replace(\"__METRIC_ID_LIST__\", ','.join(final)))\n    expression_counter = expression_counter + 1\n    return math_expression_array\n\ndef get_attached_volumes(instance_id):\n    client = boto3.client('ec2')\n    volume_response = client.describe_volumes(\n        Filters=[\n            {\n                'Name': 'attachment.instance-id',\n                'Values': [\n                    '{}'.format(instance_id),\n                ]\n            }\n        ]\n    )\n    return volume_response\n\ndef get_ec2_info(instance_id):\n    try:\n        client = boto3.client('ec2')\n        instance = client.describe_instances(InstanceIds=[instance_id])\n        ec2 = boto3.resource('ec2')\n        return client, ec2.Instance(instance_id)\n    except botocore.exceptions.ClientError:\n        raise Exception(\"[ERROR] EC2 Instance \" + instance_id + \" does not exist.\")\n \ndef get_all_cloudwatch_metrics(volume):\n    client = boto3.client('cloudwatch')\n    cloudwatch_response = client.list_metrics(\n        Namespace='AWS/EBS',\n        Dimensions=[\n            {\n                'Name': 'VolumeId',\n                'Value': '{}'.format(volume)\n            }\n        ]\n    )\n    return cloudwatch_response\n\n# This function builds the respective bytes and ops arrays for all metrics in teh cloudwatch api call response\ndef build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY):\n    j = 0\n    while j < len(cloudwatch_response['Metrics']):\n\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadBytes\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteBytes\"):\n            bytes_metrics_count = bytes_metrics_count+1\n            BYTES_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadOps\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteOps\"):\n            ops_metrics_count = ops_metrics_count+1\n            OPS_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        j = j + 1\n    return [bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY]\n\n# This function is used to continuously build each metric array while tracking the counts\ndef get_metric_counts(volume, local_array, metrics_count, metric_name_array, array, counter, expressions_array, letter):\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    metric_expression = metric_expression.replace(\"__VOLUME_ID__\", volume)\n                \n    ## If any of the metrics exist, create expressions to select those metrics and give them metrics IDs (like m1,m2)\n    j = metrics_count\n    while j > 0:\n        j = j-1\n        temp_string = metric_expression.replace(\"__METRIC_NAME__\", metric_name_array[j])\n        temp_string = temp_string.replace(\"__METRIC_ID__\", \"{}{}\".format(letter, counter))\n        # Currently Throughput is m1,m2,m3 and IOPS are n1,n2,n3\n        array.append(\"{}{}\".format(letter, counter))\n        local_array.append(\"{}{}\".format(letter, counter))\n        counter = counter+1\n        expressions_array.append(temp_string)\n    return array, counter\n\n\ndef get_markdown_contents(volume_id):\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n    markdown = \"{\\\"markdown\\\":\\\"### Metrics for __VOLUME_ID__\\\\n- Volume Type: __VOLUME_TYPE__\\\\n\\\\n[button:More details on EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html)\\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Volume calculated throughput | SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) / 1024 / 1024 / period | MiB/s |\\\\n| Volume calculated IOPS | SUM(VolumeReadOps) + SUM(VolumeWriteOps) / period | IOPS |\\\\n| Volume calculated IO size | Volume calculated throughput / Volume calculated IOPS | KiB |\\\"}\"\n    markdown = markdown.replace(\"__VOLUME_ID__\", volume_id)\n    markdown = markdown.replace(\"__VOLUME_TYPE__\", volume.volume_type)\n    return markdown\n    \n# This function builds the widget list for the dashboard body\ndef add_widgets(volume_widget_list, jsonstring_volume_throughput, jsonstring_volume_iops, jsonstring_volume_io_size, markdownstring_volume_information, x, y):\n    # Each volume widget plotted is 4x4 so each time we append to the list we move the x co-ordinate by 8\n    volume_widget_list.append(create_widget(\"text\", x, y, 24, 6, markdownstring_volume_information))\n    y += 2\n    volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_throughput))\n    x += 8\n    volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_iops))\n    x += 8\n\n    if jsonstring_volume_io_size != \"none\":\n        volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_io_size))\n        x += 8\n    # If we reach the margin then we reset the co-ordinates\n    if 24 <= x:\n        x = 0\n        y += 4\n        \n    return volume_widget_list, x, y\n\n# This function creates a single widget according to specific parameters\ndef create_widget(widget_type, x, y, w, h, p):\n    return {\n        \"type\": widget_type,\n        \"x\":x,\n        \"y\":y,\n        \"width\":w,\n        \"height\":h,\n        \"properties\": json.loads(p)\n    }\n    \n# This function creates a new dashboard \ndef create_dashboard(jsonstring_throughput, jsonstring_iops, volume_widget_list, instance_id, start_time_arg, end_time_arg, ec2_info, region):\n    client = boto3.client('cloudwatch')\n \n    markdownstring = \"{\\\"markdown\\\":\\\"# Aggregated Metrics for EC2 Instance __INSTANCE_ID__\\\\n- Instance Type: __INSTANCE_TYPE__\\\\n- EBS Optimized: __EBS_OPTIMIZED__ \\\\n\\\\n\\\\n[button: More details on EBS Optimized instances](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html)\\\\n[button: How can I use CloudWatch metrics to calculate the average throughput and average number of IOPS my EBS volume is providing?](https://aws.amazon.com/premiumsupport/knowledge-center/ebs-cloudwatch-metrics-throughput-iops/)\\\\n\\\\n--- \\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Instance calculated Throughput | SUM ( FOR ALL VOLUMES [ SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) ] ) / 1024 / 1024 / period | MiB/s |\\\\n| Instance calculated IOPS | SUM ( FOR ALL VOLUMES [ SUM(VolumeReadOps) + SUM(VolumeWriteOps) ] ) / period | IOPS |\\\\n\\\\n--- \\\"}\"\n    markdownstring = markdownstring.replace(\"__INSTANCE_ID__\", instance_id)\n    markdownstring = markdownstring.replace(\"__INSTANCE_TYPE__\", ec2_info.instance_type)\n    markdownstring = markdownstring.replace(\"__EBS_OPTIMIZED__\", str(ec2_info.ebs_optimized))\n    footer_markdownstring = \"{\\\"markdown\\\":\\\"**In order to delete the dashboard, run the CLI command** \\\\n\\\\n ```\\\\n $ aws cloudwatch delete-dashboards --dashboard-names __INSTANCE_ID__-EBS-Statistics --region __REGION__ \\\\n ``` \\\\n\\\\n NOTE: You will need **cloudwatch:DeleteDashboards** IAM permission to delete the dashboard.\\\"}\"\n    footer_markdownstring = footer_markdownstring.replace(\"__INSTANCE_ID__\", instance_id)\n    footer_markdownstring = footer_markdownstring.replace(\"__REGION__\", region)\n    widget_list = [create_widget(\"text\", 0, 0, 24, 7, markdownstring),  create_widget(\"metric\", 0, 7, 12, 8, jsonstring_throughput), create_widget(\"metric\", 12, 7, 12, 8, jsonstring_iops), create_widget(\"text\", 0, 500, 24, 3, footer_markdownstring)] + volume_widget_list\n \n    dashboard = {\n        \"start\": start_time_arg,\n        \"end\": end_time_arg,\n        \"periodOverride\": \"inherit\",\n        \"widgets\": widget_list\n    }\n\n    response = client.put_dashboard(DashboardName=\"{}-EBS-Statistics\".format(instance_id),DashboardBody=json.dumps(dashboard))\n    return response\n\ndef getInstanceStats(event, context):\n    region, instance_id, start_time, end_time, period = event['region'], event['instance_id'], event['start_time'], event['end_time'], event['period']\n    VOLUMES, METRICS_LIST = [], [] \n    counter_tp, counter_ops = 1, 1 # Used to keep track of all the metric IDs for throughput and IOPS respectively (m1,m2,m3,..., n1,n2,n3,...)\n    x, y = 0, 15 # Used to position widgets on the dashboard in terms of (x,y) co-ordinates\n    BYTES_ARRAY, OPS_ARRAY = [], [] \n    expression_counter_tp, expression_counter_iops = 1, 1 # Used to count the number of throughput and IOPS expressions on a widget\n    EXPRESSIONS_ARRAY_THROUGHPUT, EXPRESSIONS_ARRAY_IOPS = [], [] \n    MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_IOPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] \n    volume_widget_list = [] \n\n    try:\n        volume_response = get_attached_volumes(instance_id)\n        ec2_client, ec2_info = get_ec2_info(instance_id)\n\n        # Parsing volume_response from API call to extract volume IDs to an array\n        i = 0\n        while i < len(volume_response['Volumes']):\n            VOLUMES.append(volume_response['Volumes'][i]['VolumeId'])\n            i = i + 1\n            \n\n        if not volume_response['Volumes']:\n            raise Exception(\"[ERROR] There are no volume attachments for this EC2 Instance.\")\n        else:\n            # Get all available metrics for each volume\n            i = 0\n            while i < len(VOLUMES):\n                # Get all metrics from CloudWatch\n                cloudwatch_response = get_all_cloudwatch_metrics(VOLUMES[i])\n\n                limits = get_volume_limits(VOLUMES[i])\n                maximum_throughput_limit, baseline_throughput_limit, maximum_iops_limit, baseline_iops_limit = limits[0:4]\n\n                # Variables need to be re-initialized for each new volume being processed\n                EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], []\n                BYTES_METRIC_NAME_ARRAY, OPS_METRIC_NAME_ARRAY = [], []\n                bytes_metrics_count, ops_metrics_count = 0, 0\n                LOCAL_BYTES_ARRAY, LOCAL_OPS_ARRAY = [], []\n\n                # Get bytes and ops metric arrays and set associated counts (further explained in build_metric_arrays function)\n                arrays_and_counts = build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY)\n                bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY = arrays_and_counts[0:4]\n                \n                # Update metric_counts for each volume (further explained in get_metrics_counts function)\n                BYTES_ARRAY, counter_tp = get_metric_counts(VOLUMES[i], LOCAL_BYTES_ARRAY, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, BYTES_ARRAY, counter_tp, EXPRESSIONS_ARRAY_THROUGHPUT, \"m\")\n                OPS_ARRAY, counter_ops = get_metric_counts(VOLUMES[i], LOCAL_OPS_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY, OPS_ARRAY, counter_ops, EXPRESSIONS_ARRAY_IOPS, \"n\")\n\n                # If bytes metrics exists, create a unique throughput expression and pass to create_volume_expression\n                if bytes_metrics_count > 0:\n                    throughput_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"__VOLUME_ID__ Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    expression_counter_tp = create_volume_expression(\"Throughput\", throughput_expression, LOCAL_BYTES_ARRAY, VOLUMES[i], expression_counter_tp, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_THROUGHPUT)\n                    \n                # If ops metrics exists, create a unique ops expression and pass to create_volume_expression\n                if ops_metrics_count > 0:\n                    ops_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"__VOLUME_ID__ Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    expression_counter_iops = create_volume_expression(\"IOPS\", ops_expression, LOCAL_OPS_ARRAY, VOLUMES[i], expression_counter_iops, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_IOPS)\n\n                # IO Size counter is the sum of the number of throughput and IOPS counters minus the number of the current volume being processed (as i starts at 0 we +1 for the first number to be 1 and so on)\n                expression_counter_io_size = expression_counter_tp + expression_counter_iops - (i + 1)\n\n                # If bytes and ops both exist, create iosize expression and add to MATH_EXPRESSIONS_ARRAY_IO_SIZE[]\n                if (bytes_metrics_count > 0) and (ops_metrics_count > 0):\n                    iosize_string = \"[{\\\"expression\\\":\\\"(__THRU_DIV_OPS__)*1024\\\",\\\"label\\\":\\\"__VOLUME_ID__ Estimated IO Size - KiB\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    temp_string = iosize_string.replace(\"__VOLUME_ID__\", VOLUMES[i])\n                    temp_string = temp_string.replace(\"__THRU_DIV_OPS__\", \"e{}\".format(expression_counter_io_size-2) + \"/\" + \"e{}\".format(expression_counter_io_size-1))\n                    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter_io_size))\n                    MATH_EXPRESSIONS_ARRAY_IO_SIZE.append(temp_string)\n                    \n                # Create temporarily used variables for each volume \n                # Each is a list concatentation of the previously build expressions array and the metric math expressions array\n                volume_throughput = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n                volume_iops = MATH_EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IOPS\n                # volume_io_size could be empty if the IO size metrics aren't calculated due to either bytes or IOPS metrics missing\n                volume_io_size = MATH_EXPRESSIONS_ARRAY_IO_SIZE + EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IO_SIZE\n                \n\n                jsonstring_volume_throughput = fill_volume_jsonstring(\"Throughput\", volume_throughput, maximum_throughput_limit, baseline_throughput_limit, start_time, end_time, region, period, VOLUMES[i])\n                jsonstring_volume_iops = fill_volume_jsonstring(\"IOPS\", volume_iops, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, VOLUMES[i])\n                \n                # Reset metric math expression arrays after the JSON strings are generated above\n                MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_IOPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], []\n\n\n                if volume_io_size != []:\n                    jsonstring_volume_io_size = fill_volume_jsonstring(\"IOSize\", volume_io_size, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, VOLUMES[i])\n                else:\n                    jsonstring_volume_io_size = \"none\"\n\n                # Add widgets to the dashboard for the jsonstrings generated from the expression arrays\n \n                markdownstring_volume_information = get_markdown_contents(VOLUMES[i])\n                volume_widget_list, x, y = add_widgets(volume_widget_list, jsonstring_volume_throughput, jsonstring_volume_iops, jsonstring_volume_io_size, markdownstring_volume_information, x, y)\n                i = i + 1\n\n \n            if (not BYTES_ARRAY) and (not OPS_ARRAY):\n                raise Exception(\"[ERROR] Metrics don't exist for any of the volumes attached to this instance!\")\n            if BYTES_ARRAY:\n                create_instance_expression(\"Throughput\", instance_id, BYTES_ARRAY, MATH_EXPRESSIONS_ARRAY_THROUGHPUT, expression_counter_tp, \"m\")\n            if OPS_ARRAY:\n                create_instance_expression(\"IOPS\", instance_id, OPS_ARRAY, MATH_EXPRESSIONS_ARRAY_IOPS, expression_counter_iops, \"n\")\n            \n            # We create the throughput and IOPS expression arrays by adding metric math expressions to them\n            EXPRESSIONS_ARRAY_THROUGHPUT = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n            EXPRESSIONS_ARRAY_IOPS = MATH_EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IOPS\n            # After this we convert the expression arrays to JSON strings again\n            jsonstring_throughput = fill_jsonstring(\"Throughput\", EXPRESSIONS_ARRAY_THROUGHPUT, start_time, end_time, region, period, ec2_info, ec2_client)\n            jsonstring_iops = fill_jsonstring(\"IOPS\", EXPRESSIONS_ARRAY_IOPS, start_time, end_time, region, period, ec2_info, ec2_client)\n            \n\n            response = create_dashboard(jsonstring_throughput, jsonstring_iops, volume_widget_list, instance_id, start_time, end_time, ec2_info, region)\n            if response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n                info_message = \"\\n\\nYou can copy the generated dashboard URL into your browser and you can then observe the metrics for the selected resource between the specified start and end times.\\nIf you wish to delete the CloudWatch Dashboard generated from this document, please consult the DeleteDashboard API documentation - https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_DeleteDashboards.html\"\n                return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#dashboards:name={}-EBS-Statistics\".format(region, region, instance_id) + info_message\n            \n    except botocore.exceptions.ClientError as error:\n\n        raise error\n        \n    except Exception as error:\n        raise error\n\n",
        "InputPayload": {
          "instance_id": "{{ResourceId}}",
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}",
          "period": "{{Period}}",
          "region": "{{global:REGION}}"
        }
      },
      "outputs": [
        {
          "Name": "CloudWatchDashboardLink",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ]
    }
  ],
  "outputs": [
    "getVolumeStats.CloudWatchDashboardLink",
    "getInstanceStats.CloudWatchDashboardLink"
  ]
}
