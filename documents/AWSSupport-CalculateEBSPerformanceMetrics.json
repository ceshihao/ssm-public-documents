{
  "description": "# AWSSupport-CalculateEBSPerformanceMetrics\n\n---\n\n## Purpose:\n\nAWSSupport-CalculateEBSPerformanceMetrics runbook helps diagnose Amazon EBS performance issues by calculating metrics published to Amazon Cloudwatch and creating Amazon Cloudwatch dashboards that display the average I/O size and total aggregate throughput and IOPS of individual Amazon EBS volumes, or the total aggregate throughput and IOPS across all Amazon EBS volumes attached to an Amazon EC2 instance by utilizing Amazon Cloudwatch metric math. The runbook outputs the link to the newly created Amazon Cloudwatch dashboard that displays the relevant calculated Amazon Cloudwatch metrics.\n\n\n **Disclaimer**: The creation of the aforementioned dashboard may result in your account incurring extra charges. For more information please consult the [Amazon CloudWatch pricing guide](https://aws.amazon.com/cloudwatch/pricing).\n\n\n ## Workflow Specifications:\n\n This workflow uses AWS Systems Manager Automation and takes in the following parameters:\n\n1. **ResourceId** - **(Required)** The ID of the Amazon EBS volume or the Amazon EC2 instance for which the statistics need to be visualized.\n2. **StartTime** - **(Required)** The start time to view the data in Amazon CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC. For example, 2021-06-09T13:30:10.\n3. **EndTime** - **(Required)** The ending time to view the data in Amazon CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC. For example, 2021-06-09T13:30:10.\n4. **Period** - **(Required)** The period (in seconds) of the Amazon CloudWatch metrics.\n5. **AutomationAssumeRole** - **(Optional)** The IAM role which AWS Systems Manager will assume to execute this automation. This role must allow these IAM actions:\n        - ssm:StartAutomationExecution\n    - ec2:DescribeVolumes\n    - ec2:DescribeInstances\n    - ec2:DescribeInstanceTypes\n    - cloudwatch:PutDashboard\n    - cloudwatch:ListMetrics\n    - ssm:GetAutomationExecution\n\n\nPlease visit the documentation on [Automation Setup](https://docs.aws.amazon.com/systems-manager/latest/userguide/automation-setup.html) for more information.",
  "schemaVersion": "0.3",
  "assumeRole": "{{AutomationAssumeRole}}",
  "parameters": {
    "ResourceId": {
      "type": "String",
      "description": "(Required) The ID of the EC2 Instance or EBS Volume you wish to observe the metrics of.",
      "allowedPattern": "^vol-[a-z0-9]{8}$|^vol-[a-z0-9]{17}$|^i-[a-z0-9]{8}$|^i-[a-z0-9]{17}$"
    },
    "StartTime": {
      "type": "String",
      "description": "(Required) The start time to view the data in CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC.",
      "allowedPattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}$"
    },
    "EndTime": {
      "type": "String",
      "description": "(Required) The end time to view the data in CloudWatch. The time must be in the format yyyy-mm-ddThh:mm:ss and in UTC.",
      "allowedPattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}$"
    },
    "Period": {
      "type": "String",
      "description": "(Required) The number of seconds by which observable metrics will be grouped. Select the period in seconds from the drop down list.",
      "allowedValues": [
        "60",
        "300",
        "900",
        "3600",
        "21600",
        "86400"
      ]
    },
    "AutomationAssumeRole": {
      "default": "",
      "type": "String",
      "description": "(Optional) IAM role which AWS Systems Manager will assume to execute this automation. For more information, visit - https://docs.aws.amazon.com/systems-manager/latest/userguide/automation-setup.html",
      "allowedPattern": "^$|^arn:aws:iam::[0-9]*:role/[/\\w+=,.@-]+$"
    }
  },
  "mainSteps": [
    {
      "name": "checkTimestamps",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "isEnd": "false",
      "isCritical": "true",
      "nextStep": "chooseVolumeOrInstance",
      "inputs": {
        "Runtime": "python3.6",
        "Handler": "timestamp_handler",
        "Script": "from datetime import datetime\n\ndef timestamp_handler(event, context):\n    start_time = event['start_time']\n    end_time = event['end_time']\n\n    try:\n    \tt1 = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%S\")\n    \tt2 = datetime.strptime(end_time, \"%Y-%m-%dT%H:%M:%S\")\n    \tif t1 > t2:\n    \t\traise Exception(\"[ERROR] StartTime should not be greater than EndTime\")\n    \telse:\n    \t\treturn \"Timestamps are in correct format.\"\n    except Exception as error:\n    \traise error\n",
        "InputPayload": {
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}"
        }
      }
    },
    {
      "name": "chooseVolumeOrInstance",
      "action": "aws:branch",
      "maxAttempts": 3,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "isEnd": "false",
      "isCritical": "true",
      "inputs": {
        "Choices": [
          {
            "NextStep": "getVolumeStats",
            "Variable": "{{ResourceId}}",
            "StartsWith": "vol-"
          },
          {
            "NextStep": "getInstanceStats",
            "Variable": "{{ResourceId}}",
            "StartsWith": "i-"
          }
        ]
      }
    },
    {
      "name": "getVolumeStats",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "isCritical": "true",
      "isEnd": true,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "inputs": {
        "Runtime": "python3.6",
        "Handler": "getVolumeStats",
        "Script": "import json\nimport boto3\nimport botocore\nimport urllib\nimport sys\nfrom urllib.parse import quote\n\ndef getSC1Limits(volume_size):\n    maximum_available_iops = 250\n    if volume_size < 3200:\n        max_available_throughput = volume_size * 80 / 1024\n        baseline_throughput = volume_size * 12 / 1024\n    else:\n        max_available_throughput = 250\n        baseline_throughput = volume_size * 12 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef getST1Limits(volume_size):\n    maximum_available_iops = 500\n    if volume_size > 12800:\n        max_available_throughput = 500\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size < 2048:\n            max_available_throughput = volume_size * 250 / 1024\n            baseline_throughput= volume_size * 40 / 1024 \n        else:\n            max_available_throughput = 500\n            baseline_throughput = volume_size * 40 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef getIOLimits(volume_iops):\n    if volume_iops <= 32000:\n        max_available_throughput = 500\n        calculated_throughput = volume_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    else:\n        max_available_throughput = 1000\n        calculated_throughput = volume_iops / 64\n        baseline_throughput= min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, volume_iops, volume_iops]\n\ndef getGP2Limits(volume_size):\n    calculated_iops = 3 * volume_size\n    max_available_throughput = 250\n    maximum_available_iops = 3000\n    if volume_size > 1000:\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size <= 170:\n            max_available_throughput = 128\n            baseline_iops = max(calculated_iops, 100)\n        else:\n            baseline_iops = calculated_iops\n        calculated_throughput = baseline_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\n\n#Â Picks maximum and baseline limits for the specific EBS volume based on the volume type\n# For example, if the volume type is io1 it will contact the get_IO_limits function to obtain these limits \n# Each volume type has hardcoded limits which can be found in the volume type specific functions above this comment block (except for gp3) \n# Returns a single list of [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\ndef get_volume_limits(volume):\n    volume_type, volume_size = volume.volume_type, volume.size\n    if volume_type == \"gp2\":\n        return getGP2Limits(volume_size)\n    elif volume_type == \"gp3\":\n        return [volume.throughput, 125, volume.iops, volume.iops]\n    elif volume_type == \"io1\" or volume_type == \"io2\":\n        return getIOLimits(volume.iops)\n    elif volume_type == \"st1\":\n        return getST1Limits(volume_size)\n    elif volume_type == \"sc1\":\n        return getSC1Limits(volume_size) \n    elif volume_type == \"standard\":\n        # We do not divulge limits for standard/magnetic volume type, but this needs to return something\n        # Later on the standard/magnetic volume type and this information is never used\n        return [0, 0, 0, 0]\n\n# This function is used to obtain all metrics on a volume\ndef get_all_cloudwatch_metrics(volume_id):\n    client = boto3.client('cloudwatch')\n    cloudwatch_response = client.list_metrics(\n        Namespace='AWS/EBS',\n        Dimensions=[\n            {\n                'Name': 'VolumeId',\n                'Value': '{}'.format(volume_id)\n            }\n        ]\n    )\n    return cloudwatch_response\n\n# This function builds the respective bytes and ops arrays for all metrics in th cloudwatch api call response\n# Returns a single list with the [bytes_metric_count, bytes_metric_array, iops_metric_count, iops_metric_array]\ndef build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY):\n    j = 0\n    while j < len(cloudwatch_response['Metrics']):\n        ## If bytes metrics exist, storing them in BYTES_METRIC_NAME_ARRAY[] and storing their count in bytes_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadBytes\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteBytes\"):\n            bytes_metrics_count = bytes_metrics_count+1\n            BYTES_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        ## If ops metrics exist, storing them in OPS_METRIC_NAME_ARRAY[] and storing their count in ops_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadOps\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteOps\"):\n            ops_metrics_count = ops_metrics_count+1\n            OPS_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        j = j + 1\n    return [bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY]\n\n# Sets all potential label value for either throughput or iops\n# Returns 3 string values, the string used for if the values for maximum and baseline are equal and then the maximum and baseline values are return respectively\ndef set_labels(metric_type):\n    if metric_type == \"Throughput\":\n        return \"Maximum / Baseline Throughput Limit - MiB/s\", \"Maximum Throughput Limit - MiB/s\", \"Baseline Throughput Limit - MiB/s\"\n    else:\n        return \"Maximum / Baseline IOPS Limit\", \"Maximum IOPS Limit\", \"Baseline IOPS Limit\"\n\n# Returns JSON to be used in the dashboard widgets for instances\ndef fill_jsonstring(metric_type, EXPRESSIONS_ARRAY, maximum_limit, baseline_limit, start_time, end_time, region, period, volume_type):\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"EBS Volume \" + metric_type + \"\\\"}\"\n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    # The resulting string is substituted into the predefined string jsonstring\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n        \n    # Substituting values in the above expression\n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n    # If the metric type is IO size or of the standard/magnetic type then no limits are plotted and the string is returned without annotations\n    if metric_type == \"IOSize\" or volume_type == \"standard\":\n        return jsonstring\n    if metric_type == \"Throughput\":\n        equal_label = \"Maximum / Baseline Throughput Limit - MiB/s\"\n        maximum_label = \"Maximum Throughput Limit - MiB/s\"\n        baseline_label = \"Baseline Throughput Limit - MiB/s\"\n    else:\n        # Set labels for annotations\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n\n    # If both the max and the baseline limits are equal we set a single annotation\n    # Otherwise we add two annotations\n    # The jsonstring here is manipulated to include additional source for either one or two annotations where applicable\n    if maximum_limit == baseline_limit:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    else:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__},{\\\"label\\\": \\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\": __SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\n# This function is used to continuously build each metric array while tracking the counts\ndef get_metric_counts(volume, metrics_count, metric_name_array, array, counter, expressions_array):\n    ## Expression used to select required metrics for each volume\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    metric_expression = metric_expression.replace(\"__VOLUME_ID__\", volume)\n                \n    # If any of the bytes metrics exist, create expressions to select those metrics and give them metrics IDs (like m1,m2)\n    i = metrics_count\n    while i > 0:\n        i = i-1\n        temp_string = metric_expression.replace(\"__METRIC_NAME__\", metric_name_array[i])\n        temp_string = temp_string.replace(\"__METRIC_ID__\", \"m{}\".format(counter))\n        array.append(\"m{}\".format(counter))\n        counter = counter+1\n        expressions_array.append(temp_string)\n    return array, counter\n\n# This function fills in the expression for a specific volume\ndef create_expression(expression, local_array, volume, expression_counter, math_expressions_io_size, math_expressions_array):\n    # Values are substituted where applicable\n    temp_string = expression.replace(\"__METRIC_ID_LIST__\", ','.join(local_array))\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n    io_size_string = temp_string.replace(\"\\\"visible\\\":true\", \"\\\"visible\\\":false\")\n    math_expressions_io_size.append(io_size_string)\n    math_expressions_array.append(temp_string)\n    expression_counter = expression_counter+1\n    return expression_counter\n\n# This function creates a single widget according to specific parameters\n# Returns a JSON object which is appended to a widget list\ndef create_widget(widget_type, x, y, w, h, p):\n    return {\n        \"type\": widget_type,\n        \"x\":x,\n        \"y\":y,\n        \"width\":w,\n        \"height\":h,\n        \"properties\": json.loads(p)\n    }\n\n# This function creates a new dashboard \ndef create_dashboard(jsonstring_throughput, jsonstring_iops, jsonstring_io_size, volume, start_time_arg, end_time_arg, volume_type, region):\n    client = boto3.client('cloudwatch')\n    markdownstring = \"{\\\"markdown\\\":\\\"### Metrics for EBS Volume __VOLUME_ID__\\\\n- Volume Type: __VOLUME_TYPE__\\\\n\\\\n[button:More details on EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html)\\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Volume calculated throughput | SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) / 1024 / 1024 / period | MiB/s |\\\\n| Volume calculated IOPS | SUM(VolumeReadOps) + SUM(VolumeWriteOps) / period | IOPS |\\\\n| Volume calculated IO size | Volume calculated throughput / Volume calculated IOPS | KiB |\\\"}\"\n    markdownstring = markdownstring.replace(\"__VOLUME_ID__\", volume)\n    markdownstring = markdownstring.replace(\"__VOLUME_TYPE__\", volume_type)\n    footer_markdownstring = \"{\\\"markdown\\\":\\\"**In order to delete the dashboard, run the CLI command** \\\\n\\\\n ```\\\\n $ aws cloudwatch delete-dashboards --dashboard-names __VOLUME_ID__-EBS-Statistics --region __REGION__ \\\\n ``` \\\\n\\\\n NOTE: You will need **cloudwatch:DeleteDashboards** IAM permission to delete the dashboard.\\\"}\"\n    footer_markdownstring = footer_markdownstring.replace(\"__VOLUME_ID__\", volume)\n    footer_markdownstring = footer_markdownstring.replace(\"__REGION__\", region)\n    if jsonstring_io_size == \"none\":\n        widget_list = [create_widget(\"text\", 0, 0, 24, 6, markdownstring),create_widget(\"metric\", 0, 5, 8, 8, jsonstring_throughput), create_widget(\"metric\", 8, 5, 8, 8, jsonstring_iops), create_widget(\"text\", 0, 13, 24, 3, footer_markdownstring)]\n    else:\n        widget_list = [create_widget(\"text\", 0, 0, 24, 6, markdownstring),create_widget(\"metric\", 0, 5, 8, 8, jsonstring_throughput), create_widget(\"metric\", 8, 5, 8, 8, jsonstring_iops), create_widget(\"metric\", 16, 5, 8, 8, jsonstring_io_size), create_widget(\"text\", 0, 13, 24, 3, footer_markdownstring)]\n    dashboard = {\n        \"start\": start_time_arg,\n        \"end\": end_time_arg,\n        \"periodOverride\": \"inherit\",\n        \"widgets\": widget_list\n    }\n    response = client.put_dashboard(DashboardName=\"{}-EBS-Statistics\".format(volume),DashboardBody=json.dumps(dashboard))\n    return response\n\ndef getVolumeStats(event, context):\n    region, volume_id, start_time, end_time, period = event['region'], event['volume_id'], event['start_time'], event['end_time'], event['period']\n    bytes_metrics_count, ops_metrics_count = 0, 0 # Used to track respective throughput and IOPS metrics\n    global_metrics_counter = 1 # Used to track total number of metrics\n    BYTES_METRIC_NAME_ARRAY, OPS_METRIC_NAME_ARRAY = [], []  # Used to keep track of byte and IOPS metrics names per volume\n    expression_counter_tp, expression_counter_ops = 1, 1 # Used to count the number of throughput and IOPS expressions on a widget\n    EXPRESSIONS_ARRAY_THROUGHPUT, EXPRESSIONS_ARRAY_IOPS, EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] # Used to keep track of throughput IOPS amd IO size expressions respectively\n    LIMIT_ARRAY, BYTES_ARRAY, OPS_ARRAY = [], [], [] # Used to define limits and keep track of byte and IOPS values per volume\n    MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_OPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] #  Used to keep track of metric math based expressions for throughput, iops, and IO size respectively\n\n    # Will be used to create expressions to select all the relevant metrics\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    \n    # Checking if volume exists\n    client = boto3.client('ec2')\n    try:\n        volume_response = client.describe_volumes(\n            VolumeIds=[\n                '{}'.format(volume_id),\n            ]\n        )\n        # Get all metrics from CloudWatch for this volume\n        cloudwatch_response = get_all_cloudwatch_metrics(volume_id)\n        client = boto3.resource(\"ec2\") \n        volume = client.Volume(volume_id)\n\n        # Decide what volume type is associated with that volume and set maximum and baseline throughput and IOPS limits\n        # Further explained in get_volume_limits function\n        limits = get_volume_limits(volume)\n        maximum_throughput_limit, baseline_throughput_limit, maximum_iops_limit, baseline_iops_limit = limits[0:4]\n\n        # Get bytes and ops metric arrays and set associated counts (further explained in build_metric_arrays function)\n        arrays_and_counts = build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY)\n        bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY = arrays_and_counts[0:4]\n            \n        # If none of the bytes or ops metrics exist, abort\n        if (bytes_metrics_count == 0) and (ops_metrics_count == 0):\n            raise Exception(\"[ERROR] Metrics don't exist for this volume!\")\n        \n        BYTES_ARRAY, global_metrics_counter = get_metric_counts(volume_id, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, BYTES_ARRAY, global_metrics_counter, EXPRESSIONS_ARRAY_THROUGHPUT)\n        OPS_ARRAY, global_metrics_counter = get_metric_counts(volume_id, ops_metrics_count, OPS_METRIC_NAME_ARRAY, OPS_ARRAY, global_metrics_counter, EXPRESSIONS_ARRAY_IOPS)\n\n        # At this point, EXPRESSIONS_ARRAY[] will have the available bytes and ops metrics selected\n        # If bytes metrics exists, create throughput expression and update counter\n        if bytes_metrics_count > 0:\n            throughput_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            expression_counter_tp = create_expression(throughput_expression, BYTES_ARRAY, volume_id, expression_counter_tp, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_THROUGHPUT)\n    \n        # If ops metrics exists, create ops expression and update counter\n        if ops_metrics_count > 0:\n            ops_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            expression_counter_ops = create_expression(ops_expression, OPS_ARRAY, volume_id, expression_counter_ops+1, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_OPS)\n            expression_counter_ops -= 1\n\n        expression_counter_io_size = expression_counter_tp + expression_counter_ops - 1\n        # If bytes and ops both exist, create iosize expression and add to MATH_EXPRESSIONS_ARRAY_IO_SIZE[]\n        if (bytes_metrics_count > 0) and (ops_metrics_count > 0):\n            iosize_expression = \"[{\\\"expression\\\":\\\"(__THRU_DIV_OPS__)*1024\\\",\\\"label\\\":\\\"Estimated IO size - KiB\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n            temp_string = iosize_expression.replace(\"__THRU_DIV_OPS__\", \"e{}\".format(expression_counter_io_size-2) + \"/\" + \"e{}\".format(expression_counter_io_size-1))\n            temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter_io_size))\n            MATH_EXPRESSIONS_ARRAY_IO_SIZE.append(temp_string)\n\n        # We create the throughput and IOPS expression arrays by adding metric math expressions to them\n        EXPRESSIONS_ARRAY_IO_SIZE = MATH_EXPRESSIONS_ARRAY_IO_SIZE + EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_IOPS\n        EXPRESSIONS_ARRAY_THROUGHPUT = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n        EXPRESSIONS_ARRAY_IOPS = MATH_EXPRESSIONS_ARRAY_OPS + EXPRESSIONS_ARRAY_IOPS\n\n        # After this we convert the expression arrays to JSON strings\n        jsonstring_throughput = fill_jsonstring(\"Throughput\", EXPRESSIONS_ARRAY_THROUGHPUT, maximum_throughput_limit, baseline_throughput_limit, start_time, end_time, region, period, volume.volume_type)\n        jsonstring_iops = fill_jsonstring(\"IOPS\", EXPRESSIONS_ARRAY_IOPS, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, volume.volume_type)\n\n        # If the IO size list is not empty (so metrics exist for it), we create a new volume JSON string for this to be added as a widget in the dashboard\n        # Otherwise, we set the same string name to \"none\" and handle it later\n        if EXPRESSIONS_ARRAY_IO_SIZE != []:\n            jsonstring_io_size = fill_jsonstring(\"IOSize\", EXPRESSIONS_ARRAY_IO_SIZE, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, volume.volume_type)\n        else:\n            jsonstring_io_size = \"none\"\n        \n        # Pass the new instance JSON strings and create dashboard with a put_dashboard API call\n        response = create_dashboard(jsonstring_throughput, jsonstring_iops, jsonstring_io_size, volume_id, start_time, end_time, volume.volume_type, region)\n        if response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n            info_message = \"\\n\\nYou can copy the generated dashboard URL into your browser and you can then observe the metrics for the selected resource between the specified start and end times.\\nIf you wish to delete the CloudWatch Dashboard generated from this document, please consult the DeleteDashboard API documentation - https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_DeleteDashboards.html\"\n            return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#dashboards:name={}-EBS-Statistics\".format(region, region, volume_id) + info_message\n\n    except botocore.exceptions.ClientError as error:\n        raise error\n        \n    except Exception as error:\n        raise error\n",
        "InputPayload": {
          "volume_id": "{{ResourceId}}",
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}",
          "period": "{{Period}}",
          "region": "{{global:REGION}}"
        }
      },
      "outputs": [
        {
          "Name": "CloudWatchDashboardLink",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ]
    },
    {
      "name": "getInstanceStats",
      "action": "aws:executeScript",
      "maxAttempts": 3,
      "isCritical": "true",
      "isEnd": true,
      "onCancel": "Abort",
      "onFailure": "Abort",
      "inputs": {
        "Runtime": "python3.6",
        "Handler": "getInstanceStats",
        "Script": "import boto3\nimport botocore\nimport json\nimport re\nimport urllib\nfrom urllib.parse import quote\n\ndef get_SC1_limits(volume_size):\n    maximum_available_iops = 250\n    if volume_size < 3200:\n        max_available_throughput = volume_size * 80 / 1024\n        baseline_throughput = volume_size * 12 / 1024\n    else:\n        max_available_throughput = 250\n        baseline_throughput = volume_size * 12 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef get_ST1_limits(volume_size):\n    maximum_available_iops = 500\n    if volume_size > 12800:\n        max_available_throughput = 500\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size < 2048:\n            max_available_throughput = volume_size * 250 / 1024\n            baseline_throughput= volume_size * 40 / 1024 \n        else:\n            max_available_throughput = 500\n            baseline_throughput = volume_size * 40 / 1024\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, maximum_available_iops]\n\ndef get_IO_limits(volume_iops):\n    if volume_iops <= 32000:\n        max_available_throughput = 500\n        calculated_throughput = volume_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    else:\n        max_available_throughput = 1000\n        calculated_throughput = volume_iops / 64\n        baseline_throughput= min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, volume_iops, volume_iops]\n\ndef get_GP2_limits(volume_size):\n    calculated_iops = 3 * volume_size\n    max_available_throughput = 250\n    maximum_available_iops = 3000\n    if volume_size > 1000:\n        baseline_throughput = max_available_throughput\n    else:\n        if volume_size <= 170:\n            max_available_throughput = 128\n            baseline_iops = max(calculated_iops, 100)\n        else:\n            baseline_iops = calculated_iops\n        calculated_throughput = baseline_iops / 4\n        baseline_throughput = min(max_available_throughput, calculated_throughput)\n    return [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\n\n#Â Picks maximum and baseline limits for the specific EBS volume based on the volume type\n# For example, if the volume type is io1 it will contact the get_IO_limits function to obtain these limits \n# Each volume type has hardcoded limits which can be found in the volume type specific functions above this comment block (except for gp3) \n# Returns a single list of [max_available_throughput, baseline_throughput, maximum_available_iops, baseline_iops]\ndef get_volume_limits(volume_id):\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n    volume_type, volume_size = volume.volume_type, volume.size\n    if volume_type == \"gp2\":\n        return get_GP2_limits(volume_size)\n    elif volume_type == \"gp3\":\n        # These values are the only limits which can be obtain from the API call\n        return [volume.throughput, 125, volume.iops, volume.iops]\n    elif volume_type == \"io1\" or volume_type == \"io2\":\n        return get_IO_limits(volume.iops)\n    elif volume_type == \"st1\":\n        return get_ST1_limits(volume_size)\n    elif volume_type == \"sc1\":\n        return get_SC1_limits(volume_size) \n    elif volume_type == \"standard\":\n        # We do not divulge limits for standard/magnetic volume type, but this needs to return something\n        # Later on the standard/magnetic volume type and this information is never used\n        return [0, 0, 0, 0]\n\n# Sets all potential label value for either throughput or iops\n# Returns 3 string values, the string used for if the values for maximum and baseline are equal and then the maximum and baseline values are return respectively\ndef set_labels(metric_type):\n    if metric_type == \"Throughput\":\n        return \"Maximum / Baseline Throughput Limit - MiB/s\", \"Maximum Throughput Limit - MiB/s\", \"Baseline Throughput Limit - MiB/s\"\n    else:\n        return \"Maximum / Baseline IOPS Limit\", \"Maximum IOPS Limit\", \"Baseline IOPS Limit\"\n\n# Returns JSON to be used in the dashboard widgets for individual volumes\ndef fill_volume_jsonstring(metric_type, EXPRESSIONS_ARRAY, maximum_limit, baseline_limit, start_time, end_time, region, period, volume_id):\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"\" + metric_type + \"\\\"}\"\n    \n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    # The resulting string is substituted into the predefined string jsonstring\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n\n    # Substituting values in the above expression\n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n\n    # If the metric type is IO size or the standard/magnetic type volume is used then no limits are plotted and the string is returned without annotations\n    # Otherwise the labels for the annotations are set\n    if metric_type == \"IOSize\" or volume.volume_type == \"standard\":\n        return jsonstring\n    else:\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n    \n    # In the event the maximum and baseline limit are equal, we add a single annotation to display this\n    # Otherwise both annotations are created for maximum and baseline limits\n    # The jsonstring here is manipulated to include additional source for either one or two annotations where applicable\n    if maximum_limit == baseline_limit:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    else:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\": {\\\"horizontal\\\": [{\\\"label\\\": \\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\": __FIRST_ANNOTATION_VALUE__},{\\\"label\\\": \\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\": __SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\n# Returns JSON to be used in the dashboard widgets for instances\ndef fill_jsonstring(metric_type, EXPRESSIONS_ARRAY, start_time, end_time, region, period, ec2_info, client):\n    maximum_set, baseline_set = False, False\n    jsonstring = \"{\\\"metrics\\\":[__EXPRESSIONS__],\\\"view\\\":\\\"timeSeries\\\",\\\"stacked\\\":false,\\\"region\\\":\\\"__REGION__\\\",\\\"stat\\\":\\\"Sum\\\",\\\"period\\\":__PERIOD__,\\\"start\\\":\\\"__START_TIME__\\\",\\\"end\\\":\\\"__END_TIME__\\\",\\\"legend\\\":{\\\"position\\\":\\\"bottom\\\"},\\\"title\\\":\\\"\" + metric_type + \"\\\"}\"\n    # A comma delimited string is created from EXPRESSIONS_ARRAY. The string contains all the expressions we need\n    # The resulting string is substituted into the predefined string jsonstring\n    jsonstring = jsonstring.replace(\"__EXPRESSIONS__\", ','.join(EXPRESSIONS_ARRAY))\n        \n    # Substituting values in the above expression\n    jsonstring = jsonstring.replace(\"__START_TIME__\", start_time)\n    jsonstring = jsonstring.replace(\"__END_TIME__\", end_time)\n    jsonstring = jsonstring.replace(\"__REGION__\", region)\n    jsonstring = jsonstring.replace(\"__PERIOD__\", period)\n\n    # If the metric type is IO size no limits are plotted and the string is returned without annotations\n    if metric_type == \"IOSize\":\n        return jsonstring\n\n    # If the instance is EBS Optimized we make a call to the EC2 API\n    # Otherwise we continue on\n    if ec2_info.ebs_optimized:\n        # Make filtered call to EC2 API to find instance info if EBS optimized\n        ebs_optimized_response = client.describe_instance_types(\n            InstanceTypes=[\n                ec2_info.instance_type\n            ],\n            Filters=[\n                {\n                    'Name': 'ebs-info.ebs-optimized-support',\n                    'Values': [\n                        'supported','default',\n                    ]\n                },\n            ]\n        )\n        # Set labels for annotations\n        equal_label, maximum_label, baseline_label = set_labels(metric_type)\n\n        # We obtain the limits from the API for Throughput and IOPS in this block\n        # We also set booleans to indicate if they have been set so we know what to do with annotations later\n        if metric_type == \"Throughput\":\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumThroughputInMBps\"]:\n                maximum_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumThroughputInMBps\"]\n                # MB/s to MiB/s -----> (1000*1000)/1024/1024 = 0.9536743164\n                maximum_limit = round(maximum_limit * 0.9536743164, 1)\n                maximum_set = True\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineThroughputInMBps\"]:\n                baseline_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineThroughputInMBps\"]\n                # MB/s to MiB/s -----> (1000*1000)/1024/1024 = 0.9536743164\n                baseline_limit = round(baseline_limit * 0.9536743164, 1)\n                baseline_set = True\n\n        elif metric_type == \"IOPS\":\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumIops\"]:\n                maximum_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"MaximumIops\"]\n                maximum_set = True\n            if ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineIops\"]:\n                baseline_limit = ebs_optimized_response[\"InstanceTypes\"][0][\"EbsInfo\"][\"EbsOptimizedInfo\"][\"BaselineIops\"]\n                baseline_set = True\n                \n    # If both the max and the baseline limits have been set from the API then we set both limit annotations\n    # Otherwise we check if either of the maximum or baseline has been set and these are annotations are plotted individually\n    # The jsonstring here is manipulated to include additional source for either one or two annotations where applicable\n    if (maximum_set and baseline_set):\n        if maximum_limit != baseline_limit:\n            jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__},{\\\"label\\\":\\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\":__SECOND_ANNOTATION_VALUE__}]}}\"\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n            jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n            jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n        else:\n            jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__}]}}\"\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", equal_label)\n            jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    elif maximum_set:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__FIRST_ANNOTATION_LABEL__\\\",\\\"value\\\":__FIRST_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_LABEL__\", maximum_label)\n        jsonstring = jsonstring.replace(\"__FIRST_ANNOTATION_VALUE__\", str(maximum_limit))\n    elif baseline_set:\n        jsonstring = jsonstring[:-1] + \",\\\"annotations\\\":{\\\"horizontal\\\":[{\\\"label\\\":\\\"__SECOND_ANNOTATION_LABEL__\\\",\\\"value\\\":__SECOND_ANNOTATION_VALUE__}]}}\"\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_LABEL__\", baseline_label)\n        jsonstring = jsonstring.replace(\"__SECOND_ANNOTATION_VALUE__\", str(baseline_limit))\n\n    return jsonstring\n\n# This function fills in the expression for a specific volume\ndef create_volume_expression(metric_type, expression, local_array, volume, expression_counter, math_expressions_io_size, math_expressions_array):\n    # Values are substituted where applicable\n    temp_string = expression.replace(\"__METRIC_ID_LIST__\", ','.join(local_array))\n    temp_string = temp_string.replace(\"__VOLUME_ID__\", volume)\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n    io_size_string = temp_string.replace(\"\\\"visible\\\":true\", \"\\\"visible\\\":false\")\n    # If the metric is IOPS then we need to run a regex on the IO Size string to ensure we do not have any clashes with expression numbers\n    # This simply replaces the clashing e1 with e{number of expression counter+1}\n    if metric_type == \"IOPS\":\n        io_size_string = re.sub('e\\d{1}', \"e\"+str(expression_counter+1), io_size_string)\n    math_expressions_io_size.append(io_size_string)\n    math_expressions_array.append(temp_string)\n    expression_counter = expression_counter+1\n    return expression_counter\n\n# This function fills in the expression for an instances\ndef create_instance_expression(metric_type, instance_id, array, math_expression_array, expression_counter, letter):\n    # We first set the expression being used based on the metric type\n    if metric_type == \"Throughput\":\n        expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"__INSTANCE_ID__ Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n    elif metric_type == \"IOPS\":\n        expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"__INSTANCE_ID__ Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n    # Values are substituted where applicable\n    temp_string = expression.replace(\"__INSTANCE_ID__\", instance_id)\n    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter))\n    # We create an aggregated metrics array depending on the letter passed to the function\n    # Currently Throughput is m1,m2,m3 and IOPS are n1,n2,n3\n    final = []\n    i = 0\n    while i < len(array):\n        final.append(\"{}{}\".format(letter, i+1))\n        i += 1\n    math_expression_array.append(temp_string.replace(\"__METRIC_ID_LIST__\", ','.join(final)))\n    expression_counter = expression_counter + 1\n    return math_expression_array\n\n# This function is used to obtain all volumes on an instance\ndef get_attached_volumes(instance_id):\n    client = boto3.client('ec2')\n    # API call is filtered by the instance ID provided to the code\n    volume_response = client.describe_volumes(\n        Filters=[\n            {\n                'Name': 'attachment.instance-id',\n                'Values': [\n                    '{}'.format(instance_id),\n                ]\n            }\n        ]\n    )\n    return volume_response\n\n# This function is used to quickly create useful ec2 info such as the client and resource objects from boto3\ndef get_ec2_info(instance_id):\n    try:\n        client = boto3.client('ec2')\n        instance = client.describe_instances(InstanceIds=[instance_id])\n        ec2 = boto3.resource('ec2')\n        return client, ec2.Instance(instance_id)\n    except botocore.exceptions.ClientError:\n        raise Exception(\"[ERROR] EC2 Instance \" + instance_id + \" does not exist.\")\n \n# This function is used to obtain all volumes on an instance\ndef get_all_cloudwatch_metrics(volume):\n    client = boto3.client('cloudwatch')\n    cloudwatch_response = client.list_metrics(\n        Namespace='AWS/EBS',\n        Dimensions=[\n            {\n                'Name': 'VolumeId',\n                'Value': '{}'.format(volume)\n            }\n        ]\n    )\n    return cloudwatch_response\n\n# This function builds the respective bytes and ops arrays for all metrics in teh cloudwatch api call response\n# Returns a single list with the [bytes_metric_count, bytes_metric_array, iops_metric_count, iops_metric_array]\ndef build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY):\n    j = 0\n    while j < len(cloudwatch_response['Metrics']):\n        ## If bytes metrics exist, storing them in BYTES_METRIC_NAME_ARRAY[] and storing their count in bytes_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadBytes\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteBytes\"):\n            bytes_metrics_count = bytes_metrics_count+1\n            BYTES_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        ## If ops metrics exist, storing them in OPS_METRIC_NAME_ARRAY[] and storing their count in ops_metrics_count\n        if (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeReadOps\") or (cloudwatch_response['Metrics'][j]['MetricName'] == \"VolumeWriteOps\"):\n            ops_metrics_count = ops_metrics_count+1\n            OPS_METRIC_NAME_ARRAY.append(cloudwatch_response['Metrics'][j]['MetricName'])\n        j = j + 1\n    return [bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY]\n\n# This function is used to continuously build each metric array while tracking the counts\ndef get_metric_counts(volume, local_array, metrics_count, metric_name_array, array, counter, expressions_array, letter):\n    ## Expression used to select required metrics for each volume\n    metric_expression = \"[\\\"AWS/EBS\\\",\\\"__METRIC_NAME__\\\",\\\"VolumeId\\\",\\\"__VOLUME_ID__\\\",{\\\"id\\\":\\\"__METRIC_ID__\\\",\\\"visible\\\":false}]\"\n    metric_expression = metric_expression.replace(\"__VOLUME_ID__\", volume)\n                \n    ## If any of the metrics exist, create expressions to select those metrics and give them metrics IDs (like m1,m2)\n    j = metrics_count\n    while j > 0:\n        j = j-1\n        temp_string = metric_expression.replace(\"__METRIC_NAME__\", metric_name_array[j])\n        temp_string = temp_string.replace(\"__METRIC_ID__\", \"{}{}\".format(letter, counter))\n        # We create an aggregated metrics array depending on the letter passed to the function\n        # Currently Throughput is m1,m2,m3 and IOPS are n1,n2,n3\n        array.append(\"{}{}\".format(letter, counter))\n        local_array.append(\"{}{}\".format(letter, counter))\n        counter = counter+1\n        expressions_array.append(temp_string)\n    return array, counter\n\n# This function creates the markdown contents for each volume using ID and Type information\ndef get_markdown_contents(volume_id):\n    client = boto3.resource(\"ec2\") \n    volume = client.Volume(volume_id)\n    markdown = \"{\\\"markdown\\\":\\\"### Metrics for __VOLUME_ID__\\\\n- Volume Type: __VOLUME_TYPE__\\\\n\\\\n[button:More details on EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html)\\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Volume calculated throughput | SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) / 1024 / 1024 / period | MiB/s |\\\\n| Volume calculated IOPS | SUM(VolumeReadOps) + SUM(VolumeWriteOps) / period | IOPS |\\\\n| Volume calculated IO size | Volume calculated throughput / Volume calculated IOPS | KiB |\\\"}\"\n    markdown = markdown.replace(\"__VOLUME_ID__\", volume_id)\n    markdown = markdown.replace(\"__VOLUME_TYPE__\", volume.volume_type)\n    return markdown\n    \n# This function builds the widget list for the dashboard body\n# Returns the new widget list and the next co-ordinates for plotting other widgets\ndef add_widgets(volume_widget_list, jsonstring_volume_throughput, jsonstring_volume_iops, jsonstring_volume_io_size, markdownstring_volume_information, x, y):\n    # Each volume widget plotted is 4x4 so each time we append to the list we move the x co-ordinate by 8\n    # internally we call the create_widget function passing the hardcoded co-ordinates and JSON string\n    volume_widget_list.append(create_widget(\"text\", x, y, 24, 6, markdownstring_volume_information))\n    y += 2\n    volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_throughput))\n    x += 8\n    volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_iops))\n    x += 8\n    # if the string we previously set is not none then we plot the IO size in the same way we play other widgets\n    if jsonstring_volume_io_size != \"none\":\n        volume_widget_list.append(create_widget(\"metric\", x, y, 8, 4, jsonstring_volume_io_size))\n        x += 8\n    # If we reach the margin then we reset the co-ordinates\n    if 24 <= x:\n        x = 0\n        y += 4\n        \n    return volume_widget_list, x, y\n\n# This function creates a single widget according to specific parameters\n# Returns a JSON object which is appended to a widget list\ndef create_widget(widget_type, x, y, w, h, p):\n    return {\n        \"type\": widget_type,\n        \"x\":x,\n        \"y\":y,\n        \"width\":w,\n        \"height\":h,\n        \"properties\": json.loads(p)\n    }\n    \n# This function creates a new dashboard \ndef create_dashboard(jsonstring_throughput, jsonstring_iops, volume_widget_list, instance_id, start_time_arg, end_time_arg, ec2_info, region):\n    client = boto3.client('cloudwatch')\n    # We create a widget list for the instance specific metrics\n    # We concatenate the previously created volume widget list to this also\n    markdownstring = \"{\\\"markdown\\\":\\\"# Aggregated Metrics for EC2 Instance __INSTANCE_ID__\\\\n- Instance Type: __INSTANCE_TYPE__\\\\n- EBS Optimized: __EBS_OPTIMIZED__ \\\\n\\\\n\\\\n[button: More details on EBS Optimized instances](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html)\\\\n[button: How can I use CloudWatch metrics to calculate the average throughput and average number of IOPS my EBS volume is providing?](https://aws.amazon.com/premiumsupport/knowledge-center/ebs-cloudwatch-metrics-throughput-iops/)\\\\n\\\\n--- \\\\n\\\\n| Calculated Metric | Mathematical Expression | Unit |\\\\n| -------- | ------------------------- | ------ |\\\\n| Instance calculated Throughput | SUM ( FOR ALL VOLUMES [ SUM(VolumeReadBytes) + SUM(VolumeWriteBytes) ] ) / 1024 / 1024 / period | MiB/s |\\\\n| Instance calculated IOPS | SUM ( FOR ALL VOLUMES [ SUM(VolumeReadOps) + SUM(VolumeWriteOps) ] ) / period | IOPS |\\\\n\\\\n--- \\\"}\"\n    markdownstring = markdownstring.replace(\"__INSTANCE_ID__\", instance_id)\n    markdownstring = markdownstring.replace(\"__INSTANCE_TYPE__\", ec2_info.instance_type)\n    markdownstring = markdownstring.replace(\"__EBS_OPTIMIZED__\", str(ec2_info.ebs_optimized))\n    footer_markdownstring = \"{\\\"markdown\\\":\\\"**In order to delete the dashboard, run the CLI command** \\\\n\\\\n ```\\\\n $ aws cloudwatch delete-dashboards --dashboard-names __INSTANCE_ID__-EBS-Statistics --region __REGION__ \\\\n ``` \\\\n\\\\n NOTE: You will need **cloudwatch:DeleteDashboards** IAM permission to delete the dashboard.\\\"}\"\n    footer_markdownstring = footer_markdownstring.replace(\"__INSTANCE_ID__\", instance_id)\n    footer_markdownstring = footer_markdownstring.replace(\"__REGION__\", region)\n    widget_list = [create_widget(\"text\", 0, 0, 24, 7, markdownstring),  create_widget(\"metric\", 0, 7, 12, 8, jsonstring_throughput), create_widget(\"metric\", 12, 7, 12, 8, jsonstring_iops), create_widget(\"text\", 0, 500, 24, 3, footer_markdownstring)] + volume_widget_list\n    # We set the dashboard to use the specific time interval and use the instance widget list\n    dashboard = {\n        \"start\": start_time_arg,\n        \"end\": end_time_arg,\n        \"periodOverride\": \"inherit\",\n        \"widgets\": widget_list\n    }\n    # The put_dashboard API call is made and this is where the dashboard is actually created\n    response = client.put_dashboard(DashboardName=\"{}-EBS-Statistics\".format(instance_id),DashboardBody=json.dumps(dashboard))\n    return response\n\ndef getInstanceStats(event, context):\n    region, instance_id, start_time, end_time, period = event['region'], event['instance_id'], event['start_time'], event['end_time'], event['period']\n    VOLUMES, METRICS_LIST = [], [] # Used to iterate over volume IDs and gather volume specific metrics respectively\n    counter_tp, counter_ops = 1, 1 # Used to keep track of all the metric IDs for throughput and IOPS respectively (m1,m2,m3,..., n1,n2,n3,...)\n    x, y = 0, 15 # Used to position widgets on the dashboard in terms of (x,y) co-ordinates\n    BYTES_ARRAY, OPS_ARRAY = [], [] # Used to keep track of byte and IOPS values per volume\n    expression_counter_tp, expression_counter_iops = 1, 1 # Used to count the number of throughput and IOPS expressions on a widget\n    EXPRESSIONS_ARRAY_THROUGHPUT, EXPRESSIONS_ARRAY_IOPS = [], [] # Used to keep track of throughput and IOPS expressions respectively\n    MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_IOPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], [] # Used to keep track of metric math based expressions for throughput, iops, and IO size respectively\n    volume_widget_list = [] # Used to maintain the widgets created for each respective EBS volume\n\n    # Try to get all attached volumes\n    try:\n        volume_response = get_attached_volumes(instance_id)\n        ec2_client, ec2_info = get_ec2_info(instance_id)\n\n        # Parsing volume_response from API call to extract volume IDs to an array\n        i = 0\n        while i < len(volume_response['Volumes']):\n            VOLUMES.append(volume_response['Volumes'][i]['VolumeId'])\n            i = i + 1\n            \n        # Raising exception if customer enters an instance that doesn't exist or if the instance doesn't have any volumes attached. Workflow terminates\n        if not volume_response['Volumes']:\n            raise Exception(\"[ERROR] There are no volume attachments for this EC2 Instance.\")\n        else:\n            # Get all available metrics for each volume\n            i = 0\n            while i < len(VOLUMES):\n                # Get all metrics from CloudWatch\n                cloudwatch_response = get_all_cloudwatch_metrics(VOLUMES[i])\n                # Decide what volume type is associated with that volume and set maximum and baseline throughput and IOPS limits\n                # Further explained in get_volume_limits function\n                limits = get_volume_limits(VOLUMES[i])\n                maximum_throughput_limit, baseline_throughput_limit, maximum_iops_limit, baseline_iops_limit = limits[0:4]\n\n                # Variables need to be re-initialized for each new volume being processed\n                EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], []\n                BYTES_METRIC_NAME_ARRAY, OPS_METRIC_NAME_ARRAY = [], []\n                bytes_metrics_count, ops_metrics_count = 0, 0\n                LOCAL_BYTES_ARRAY, LOCAL_OPS_ARRAY = [], []\n\n                # Get bytes and ops metric arrays and set associated counts (further explained in build_metric_arrays function)\n                arrays_and_counts = build_metric_arrays(cloudwatch_response, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY)\n                bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY = arrays_and_counts[0:4]\n                \n                # Update metric_counts for each volume (further explained in get_metrics_counts function)\n                BYTES_ARRAY, counter_tp = get_metric_counts(VOLUMES[i], LOCAL_BYTES_ARRAY, bytes_metrics_count, BYTES_METRIC_NAME_ARRAY, BYTES_ARRAY, counter_tp, EXPRESSIONS_ARRAY_THROUGHPUT, \"m\")\n                OPS_ARRAY, counter_ops = get_metric_counts(VOLUMES[i], LOCAL_OPS_ARRAY, ops_metrics_count, OPS_METRIC_NAME_ARRAY, OPS_ARRAY, counter_ops, EXPRESSIONS_ARRAY_IOPS, \"n\")\n\n                # If bytes metrics exists, create a unique throughput expression and pass to create_volume_expression\n                if bytes_metrics_count > 0:\n                    throughput_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/1024/1024/__PERIOD__\\\",\\\"label\\\":\\\"__VOLUME_ID__ Throughput - MiB/s\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    expression_counter_tp = create_volume_expression(\"Throughput\", throughput_expression, LOCAL_BYTES_ARRAY, VOLUMES[i], expression_counter_tp, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_THROUGHPUT)\n                    \n                # If ops metrics exists, create a unique ops expression and pass to create_volume_expression\n                if ops_metrics_count > 0:\n                    ops_expression = \"[{\\\"expression\\\":\\\"SUM([__METRIC_ID_LIST__])/__PERIOD__\\\",\\\"label\\\":\\\"__VOLUME_ID__ Average IOPS\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    expression_counter_iops = create_volume_expression(\"IOPS\", ops_expression, LOCAL_OPS_ARRAY, VOLUMES[i], expression_counter_iops, MATH_EXPRESSIONS_ARRAY_IO_SIZE, MATH_EXPRESSIONS_ARRAY_IOPS)\n\n                # IO Size counter is the sum of the number of throughput and IOPS counters minus the number of the current volume being processed (as i starts at 0 we +1 for the first number to be 1 and so on)\n                expression_counter_io_size = expression_counter_tp + expression_counter_iops - (i + 1)\n\n                # If bytes and ops both exist, create iosize expression and add to MATH_EXPRESSIONS_ARRAY_IO_SIZE[]\n                if (bytes_metrics_count > 0) and (ops_metrics_count > 0):\n                    iosize_string = \"[{\\\"expression\\\":\\\"(__THRU_DIV_OPS__)*1024\\\",\\\"label\\\":\\\"__VOLUME_ID__ Estimated IO Size - KiB\\\",\\\"id\\\":\\\"__EXP_ID__\\\",\\\"visible\\\":true}]\"\n                    temp_string = iosize_string.replace(\"__VOLUME_ID__\", VOLUMES[i])\n                    temp_string = temp_string.replace(\"__THRU_DIV_OPS__\", \"e{}\".format(expression_counter_io_size-2) + \"/\" + \"e{}\".format(expression_counter_io_size-1))\n                    temp_string = temp_string.replace(\"__EXP_ID__\", \"e{}\".format(expression_counter_io_size))\n                    MATH_EXPRESSIONS_ARRAY_IO_SIZE.append(temp_string)\n                    \n                # Create temporarily used variables for each volume \n                # Each is a list concatentation of the previously build expressions array and the metric math expressions array\n                volume_throughput = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n                volume_iops = MATH_EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IOPS\n                # volume_io_size could be empty if the IO size metrics aren't calculated due to either bytes or IOPS metrics missing\n                volume_io_size = MATH_EXPRESSIONS_ARRAY_IO_SIZE + EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IO_SIZE\n                \n                # Generate the JSON used for the widgets in the dashboard\n                # Utilise the above lists which are converted into strings\n                jsonstring_volume_throughput = fill_volume_jsonstring(\"Throughput\", volume_throughput, maximum_throughput_limit, baseline_throughput_limit, start_time, end_time, region, period, VOLUMES[i])\n                jsonstring_volume_iops = fill_volume_jsonstring(\"IOPS\", volume_iops, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, VOLUMES[i])\n                \n                # Reset metric math expression arrays after the JSON strings are generated above\n                MATH_EXPRESSIONS_ARRAY_THROUGHPUT, MATH_EXPRESSIONS_ARRAY_IOPS, MATH_EXPRESSIONS_ARRAY_IO_SIZE = [], [], []\n\n                # If the IO size list is not empty (so metrics exist for it), we create a new volume JSON string for this to be added as a widget in the dashboard\n                # Otherwise, we set the same string name to \"none\" and handle it later in the add_widgets function\n                if volume_io_size != []:\n                    jsonstring_volume_io_size = fill_volume_jsonstring(\"IOSize\", volume_io_size, maximum_iops_limit, baseline_iops_limit, start_time, end_time, region, period, VOLUMES[i])\n                else:\n                    jsonstring_volume_io_size = \"none\"\n\n                # Add widgets to the dashboard for the jsonstrings generated from the expression arrays\n                # Returns the updated widget list for volumes along with new values for current co-ordinates when plotting next widget (x,y)\n                markdownstring_volume_information = get_markdown_contents(VOLUMES[i])\n                volume_widget_list, x, y = add_widgets(volume_widget_list, jsonstring_volume_throughput, jsonstring_volume_iops, jsonstring_volume_io_size, markdownstring_volume_information, x, y)\n                i = i + 1\n\n            # If neither metrics for bytes or IOPS exist for any volume then we tell the customer this\n            # Otherwise, for both bytes and iops, we create the aggregated instance expressions for both throughput and IOPS\n            if (not BYTES_ARRAY) and (not OPS_ARRAY):\n                raise Exception(\"[ERROR] Metrics don't exist for any of the volumes attached to this instance!\")\n            if BYTES_ARRAY:\n                create_instance_expression(\"Throughput\", instance_id, BYTES_ARRAY, MATH_EXPRESSIONS_ARRAY_THROUGHPUT, expression_counter_tp, \"m\")\n            if OPS_ARRAY:\n                create_instance_expression(\"IOPS\", instance_id, OPS_ARRAY, MATH_EXPRESSIONS_ARRAY_IOPS, expression_counter_iops, \"n\")\n            \n            # We create the throughput and IOPS expression arrays by adding metric math expressions to them\n            EXPRESSIONS_ARRAY_THROUGHPUT = MATH_EXPRESSIONS_ARRAY_THROUGHPUT + EXPRESSIONS_ARRAY_THROUGHPUT\n            EXPRESSIONS_ARRAY_IOPS = MATH_EXPRESSIONS_ARRAY_IOPS + EXPRESSIONS_ARRAY_IOPS\n            # After this we convert the expression arrays to JSON strings again\n            jsonstring_throughput = fill_jsonstring(\"Throughput\", EXPRESSIONS_ARRAY_THROUGHPUT, start_time, end_time, region, period, ec2_info, ec2_client)\n            jsonstring_iops = fill_jsonstring(\"IOPS\", EXPRESSIONS_ARRAY_IOPS, start_time, end_time, region, period, ec2_info, ec2_client)\n            \n            # Pass the new instance JSON strings along with the list of previously created widgets for the separate EBS volumes and create dashboard with a put_dashboard API call\n            response = create_dashboard(jsonstring_throughput, jsonstring_iops, volume_widget_list, instance_id, start_time, end_time, ec2_info, region)\n            if response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n                info_message = \"\\n\\nYou can copy the generated dashboard URL into your browser and you can then observe the metrics for the selected resource between the specified start and end times.\\nIf you wish to delete the CloudWatch Dashboard generated from this document, please consult the DeleteDashboard API documentation - https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_DeleteDashboards.html\"\n                return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#dashboards:name={}-EBS-Statistics\".format(region, region, instance_id) + info_message\n            \n    except botocore.exceptions.ClientError as error:\n        ## Catching any general exceptions that may happen during making the API call. For example, API rate limit exceeded\n        raise error\n        \n    except Exception as error:\n        raise error\n\n",
        "InputPayload": {
          "instance_id": "{{ResourceId}}",
          "start_time": "{{StartTime}}",
          "end_time": "{{EndTime}}",
          "period": "{{Period}}",
          "region": "{{global:REGION}}"
        }
      },
      "outputs": [
        {
          "Name": "CloudWatchDashboardLink",
          "Selector": "$.Payload",
          "Type": "String"
        }
      ]
    }
  ],
  "outputs": [
    "getVolumeStats.CloudWatchDashboardLink",
    "getInstanceStats.CloudWatchDashboardLink"
  ]
}
